<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>人生如逆旅，我亦是行人。</title>
    <link>https://xiking.win/</link>
    <description>Recent content on 人生如逆旅，我亦是行人。</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <copyright>yongman</copyright>
    <lastBuildDate>Wed, 15 Jan 2020 17:53:38 +0000</lastBuildDate>
    
        <atom:link href="https://xiking.win/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>数据仓库Snowflake论文</title>
      <link>https://xiking.win/2020/01/15/snowflake-data-warehouse/</link>
      <pubDate>Wed, 15 Jan 2020 17:53:38 +0000</pubDate>
      
      <guid>https://xiking.win/2020/01/15/snowflake-data-warehouse/</guid>
      
        <description>&lt;p&gt;数据仓库和数据库的区别就是：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;数据库：OLTP，数据操作会包含读写，并且要求时延较低，操作结果会是决定上层操作成功与否的关键。数据量一般有限。&lt;/li&gt;
&lt;li&gt;数据仓库或数据湖：OLAP，数据操作以读为主，极少update操作，对时延不是很敏感，一般查询比较复杂并且数据量大。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;大数据场景下，Hadoop或Spark是社区比较活跃的解决方案，但是snowflake认为，它们并不高效，并且系统的维护和使用成本也很高。&lt;/p&gt;

&lt;p&gt;分布式存储存储经典的两种架构：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;shared-disk：数据存储到相同位置，大家用同样的资源，Oracal Exadata，延展性和并发性不行。&lt;/li&gt;
&lt;li&gt;shared-nothing：近年来的主流做法，系统通过策略将资源分摊到多个结点，每个节点之间的数据不共享，但是实现上可能会用来保存其他节点的高可用副本数据，对于高并发或者大量的查询工作负载会分发到各个节点进行执行，所以延展性和并发性不受限制。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;但是snowflake的架构图如下，在Shared-nothing基础上提出的Multi-Cluster, Shared Data Architecture，完全实现了计算存储分离。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/yongman/i/img/picgo/20200116163848.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;1.架构的最上层是服务化组件，包括查询优化器、元数据存储、鉴权、资源管理和事务管理等。&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;查询优化器：实现查询的管理和优化，将对应的查询计划分发Virtual Warehouse中特定的计算节点，为了提高cache效率和性能，优化器会对其中的节点进行类似一致性hash的管理。&lt;/li&gt;
&lt;li&gt;事务管理：采用SI和MVCC进行的并发控制，整体的存储思想类似于LSM，数据不会原地修改，数据只能读取修改后整块写入，历史版本可以保留，SI的实现也是基于MVCC来实现的。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;2.中间是计算层Virtual Warehouse&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;本质就是vm计算资源，多个vm虚拟机资源加速本地的磁盘做cache就构成了逻辑上的一个虚拟的warehouse，其中做了cache命中率优化和类似的文件p2p分发，减轻存储层访问压力，提升性能。&lt;/p&gt;

&lt;p&gt;最下层是存储层&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;3.存储层&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;存储层使用的云上的对象存储，aws的s3，azure的blob和google的cloud storage。对象存储系统的接口很简单，基本上都是GET/DELETE/PUT三种，s3支持部分数据获取。snowflake数据chunk的存储也是采用range-based来存储，元数据依赖cloud service保存。&lt;/p&gt;

&lt;p&gt;数据的安全性完全交给底层的对象存储，计算层不需要关心数据高可用和水平扩展能力。&lt;/p&gt;

&lt;p&gt;snowflake提供了Pure-saas用户体验，与传统的DBaas相比，用户完全不用关心数据库高可用、数据库调优等。&lt;/p&gt;

&lt;p&gt;论文中还对snowflake是如何对数据进行加密来保证数据安全性的做了大量工作，在我看来，还是比较吃惊的，他们对数据的安全性做了这么复杂的设计，而不仅仅是一个固定的密钥进行加密。其中包括key rotation、rekeying，并且传输的过程也实现端到端加密。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/yongman/i/img/picgo/20200116172045.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>etcd raft lib使用示例分析</title>
      <link>https://xiking.win/2019/09/22/etcd-raft-example-analysis/</link>
      <pubDate>Sun, 22 Sep 2019 21:00:38 +0000</pubDate>
      
      <guid>https://xiking.win/2019/09/22/etcd-raft-example-analysis/</guid>
      
        <description>

&lt;p&gt;此前使用hashicorp raft库简单实现了一个redis协议的kv存储&lt;a href=&#34;https://github.com/yongman/leto&#34;&gt;Leto&lt;/a&gt;，&lt;a href=&#34;https://xiking.win/2018/07/30/implement-key-value-store-using-raft/&#34;&gt;介绍文章&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;当时选择hashicorp raft库，包装好，对用户暴露的细节较少，上手使用简单；而看了etc的raft库的实例，对外暴露的细节较多，多个channel交互，只提供核心的raft算法，其余的操作需要自己动手实现，包括网络传输、存储等，在使用上也更方便需求定制实现。&lt;/p&gt;

&lt;p&gt;看到很多raft库的工程实现或者库的引用，选择etcd raft库的占多数。比如k8s，tikv等。&lt;/p&gt;

&lt;h4 id=&#34;如何使用etcd-raft库&#34;&gt;如何使用etcd raft库&lt;/h4&gt;

&lt;p&gt;raftexample就是一个最简单的使用示例，它实现的是一个简单的内存kv存储，通过HTTP API访问。&lt;/p&gt;

&lt;h5 id=&#34;1-初始化&#34;&gt;1. 初始化&lt;/h5&gt;

&lt;p&gt;由于raft库只实现核心逻辑，所以需要与应用进行交互。其交互采用4个channel：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;proposeC：用户代码向raft提交写请求Propose&lt;/li&gt;
&lt;li&gt;confChangeC：用户代码向raft提交配置变更请求ProposeConfChange&lt;/li&gt;
&lt;li&gt;commitC：用于raft向用户代码传输已经提交的entries，用户raft库暴露具体业务逻辑，将数据写入&lt;code&gt;State Machine&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;errorC：向用户代码暴露raft库的处理异常&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;其中proposeC和confChangeC是在开始手动创建，作为参数传递给raft组件。&lt;/p&gt;

&lt;p&gt;commitC和errorC是用户代码手动封装raftNode时创建的channel，并在raft组件中使用。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func newRaftNode(id int, peers []string, join bool, getSnapshot func() ([]byte, error), proposeC &amp;lt;-chan string,
	confChangeC &amp;lt;-chan raftpb.ConfChange) (&amp;lt;-chan *string, &amp;lt;-chan error, &amp;lt;-chan *snap.Snapshotter) {

	commitC := make(chan *string)
	errorC := make(chan error)

	rc := &amp;amp;raftNode{
		proposeC:    proposeC,
		confChangeC: confChangeC,
		commitC:     commitC,
		errorC:      errorC,
		id:          id,
		peers:       peers,
		join:        join,
		waldir:      fmt.Sprintf(&amp;quot;raftexample-%d&amp;quot;, id),
		snapdir:     fmt.Sprintf(&amp;quot;raftexample-%d-snap&amp;quot;, id),
		getSnapshot: getSnapshot,
		snapCount:   defaultSnapshotCount,
		stopc:       make(chan struct{}),

		snapshotterReady: make(chan *snap.Snapshotter, 1),
	}
	go rc.startRaft()
	return commitC, errorC, rc.snapshotterReady
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h5 id=&#34;2-启动raftnode&#34;&gt;2. 启动raftNode&lt;/h5&gt;

&lt;p&gt;在初始化的时候通过&lt;code&gt;rc.startRaft()&lt;/code&gt;启动raft组件。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func (rc *raftNode) startRaft() {
	rc.snapshotter = snap.New(zap.NewExample(), rc.snapdir)
	rc.snapshotterReady &amp;lt;- rc.snapshotter

	oldwal := wal.Exist(rc.waldir)
	rc.wal = rc.replayWAL()

	rpeers := make([]raft.Peer, len(rc.peers))
	for i := range rpeers {
		rpeers[i] = raft.Peer{ID: uint64(i + 1)}
	}
	c := &amp;amp;raft.Config{
		ID:                        uint64(rc.id),
		ElectionTick:              10,
		HeartbeatTick:             1,
		Storage:                   rc.raftStorage,
		MaxSizePerMsg:             1024 * 1024,
		MaxInflightMsgs:           256,
		MaxUncommittedEntriesSize: 1 &amp;lt;&amp;lt; 30,
	}

	if oldwal {
		rc.node = raft.RestartNode(c)
	} else {
		startPeers := rpeers
		if rc.join {
			startPeers = nil
		}
		rc.node = raft.StartNode(c, startPeers)
	}

	rc.transport = &amp;amp;rafthttp.Transport{
		Logger:      zap.NewExample(),
		ID:          types.ID(rc.id),
		ClusterID:   0x1000,
		Raft:        rc,
		ServerStats: stats.NewServerStats(&amp;quot;&amp;quot;, &amp;quot;&amp;quot;),
		LeaderStats: stats.NewLeaderStats(strconv.Itoa(rc.id)),
		ErrorC:      make(chan error),
	}

	rc.transport.Start()
	for i := range rc.peers {
		if i+1 != rc.id {
			rc.transport.AddPeer(types.ID(i+1), []string{rc.peers[i]})
		}
	}

	go rc.serveRaft()
	go rc.serveChannels()
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;启动raft组件、创建网络传输、开始监听连接、监听channel数据。&lt;/p&gt;

&lt;p&gt;其中serverChannel完成了核心逻辑，读取用户提交数据，提交给raft node处理，并且将entries持久化、同步给peer节点，然后将已经commit成功的entries写入commitC。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func (rc *raftNode) serveChannels() {
	snap, err := rc.raftStorage.Snapshot()
	if err != nil {
		panic(err)
	}
	rc.confState = snap.Metadata.ConfState
	rc.snapshotIndex = snap.Metadata.Index
	rc.appliedIndex = snap.Metadata.Index

	defer rc.wal.Close()

	ticker := time.NewTicker(100 * time.Millisecond)
	defer ticker.Stop()

	// send proposals over raft
	go func() {
		confChangeCount := uint64(0)

		for rc.proposeC != nil &amp;amp;&amp;amp; rc.confChangeC != nil {
			select {
			case prop, ok := &amp;lt;-rc.proposeC:
				if !ok {
					rc.proposeC = nil
				} else {
					// blocks until accepted by raft state machine
					rc.node.Propose(context.TODO(), []byte(prop))
				}

			case cc, ok := &amp;lt;-rc.confChangeC:
				if !ok {
					rc.confChangeC = nil
				} else {
					confChangeCount++
					cc.ID = confChangeCount
					rc.node.ProposeConfChange(context.TODO(), cc)
				}
			}
		}
		// client closed channel; shutdown raft if not already
		close(rc.stopc)
	}()

	// event loop on raft state machine updates
	for {
		select {
		case &amp;lt;-ticker.C:
			rc.node.Tick()

		// store raft entries to wal, then publish over commit channel
		case rd := &amp;lt;-rc.node.Ready():
			rc.wal.Save(rd.HardState, rd.Entries)
...
			rc.raftStorage.Append(rd.Entries)
			rc.transport.Send(rd.Messages)
			if ok := rc.publishEntries(rc.entriesToApply(rd.CommittedEntries)); !ok {
				rc.stop()
				return
			}
			rc.maybeTriggerSnapshot()
			rc.node.Advance()

		case err := &amp;lt;-rc.transport.ErrorC:
			rc.writeError(err)
			return

		case &amp;lt;-rc.stopc:
			rc.stop()
			return
		}
	}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;通过监听commitC中的数据，最后完成数据写入状态机。&lt;/p&gt;

&lt;h5 id=&#34;3-数据写入&#34;&gt;3. 数据写入&lt;/h5&gt;

&lt;p&gt;整个的数据写入过程：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;http api请求写入proposeC，监听到proposeC中有数据，将数据提交给raft&lt;/li&gt;
&lt;li&gt;当raft处理完成后通过Ready chan将请求交给用户代码继续处理，完成wal、entries持久化和entries发送给peer，查找是否有已经commit的entries，将commit的entries写入commitC&lt;/li&gt;
&lt;li&gt;用户代码通过从commitC中读取已经提交成功的数据，可以放心的将数据写入状态机。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;raftexample中kvstore的具体写入逻辑：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func (s *kvstore) readCommits(commitC &amp;lt;-chan *string, errorC &amp;lt;-chan error) {
	for data := range commitC {
		...
		var dataKv kv
		dec := gob.NewDecoder(bytes.NewBufferString(*data))
		if err := dec.Decode(&amp;amp;dataKv); err != nil {
			log.Fatalf(&amp;quot;raftexample: could not decode message (%v)&amp;quot;, err)
		}
		s.mu.Lock()
		s.kvStore[dataKv.Key] = dataKv.Val
		s.mu.Unlock()
	}
	if err, ok := &amp;lt;-errorC; ok {
		log.Fatal(err)
	}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;至此完成数据写入。这里只是etcd raft库的简单使用，后续会深入阅读raft库的实现。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;参考&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://xiking.win/2018/07/30/implement-key-value-store-using-raft/&#34;&gt;https://xiking.win/2018/07/30/implement-key-value-store-using-raft/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/etcd-io/etcd/tree/master/contrib/raftexample&#34;&gt;https://github.com/etcd-io/etcd/tree/master/contrib/raftexample&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://studygolang.com/articles/10287&#34;&gt;https://studygolang.com/articles/10287&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
      
    </item>
    
    <item>
      <title>hexo迁移hugo并配置ci自动部署github pages</title>
      <link>https://xiking.win/2019/07/18/hexo-to-hugo-with-gitlab-ci-github-pages/</link>
      <pubDate>Thu, 18 Jul 2019 16:28:13 +0800</pubDate>
      
      <guid>https://xiking.win/2019/07/18/hexo-to-hugo-with-gitlab-ci-github-pages/</guid>
      
        <description>&lt;p&gt;最近一直收到github pages的通知，由hexo生成的静态站存在安全风险，要求升级，升级hexo会升级一大堆依赖node_modules，对于node小白来说一直没有进行升级。&lt;/p&gt;

&lt;p&gt;&lt;em&gt;npm install可以说很形象了&lt;/em&gt;
&lt;img src=&#34;https://raw.githubusercontent.com/yongman/i/img/picgo/output.gif&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;还是决定转hugo了，对比hexo来说真是太省事了，没有依赖，一个bin文件就能全部搞定，并且静态资源生成的速度和hexo不在一个量级。&lt;/p&gt;

&lt;p&gt;hugo下用了xianmin的&lt;a href=&#34;https://github.com/xianmin/hugo-theme-jane&#34;&gt;jane主题&lt;/a&gt;，一如既往的简洁清爽，专注阅读。&lt;/p&gt;

&lt;p&gt;对于托管在github pages的静态网站，当突然想写几句话的时候，要从上一次的源文件环境或者是同步过的环境中继续，否则就导致文章丢失，所以用hexo和hugo写文章的体验最差的就是环境的同步。&lt;/p&gt;

&lt;p&gt;为了不用再担心环境的同步和备份，直接采用gitlab的持续集成。在nas上跑的gitlab环境，docker跑一个gitlab-runner，executor采用shell方式，在gitlab上配置完成后在源repo中增加.gitlab-ci.yml文件。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;stages:
  - build
  - deploy

job 1:
  stage: build
  script:
    - hugo version

job 2:
  stage: deploy
  script:
    - hugo
    - echo -e &amp;quot;Deploying updates to GitHub...&amp;quot;
    - pwd
    - cd public
    - git init
    - git config core.sshCommand &#39;ssh -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no&#39; 
    - git add -A
    - git config user.name &amp;quot;name&amp;quot;
    - git config user.email &amp;quot;name@gmail.com&amp;quot;
    - git commit -m &amp;quot;rebuilding site `TZ=&amp;quot;Asia/Shanghai&amp;quot; date +&amp;quot;%Y-%m-%d %H:%M:%S&amp;quot;`&amp;quot;
    - git remote add origin git@github.com:your-repo.git
    - git push --force -u origin master
    - cd ..
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在执行之前，需要将该docker中对应用户的ssh rsa.pub添加到github的ssh中。&lt;/p&gt;

&lt;p&gt;但是上述gitlab-ci.yml配置的ci就是每次都是全量force push，当文章过多或者静态文件过多，每次小的改动进行全量push会非常浪费时间，并且没有commit log可以追溯。所以又修改了一版gitlab-ci.yml配置。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;stages:
  - build
  - deploy

build:
  stage: build
  artifacts:
    paths:
      - public
  script:
    - hugo version
    - hugo

deploy:
  stage: deploy
  dependencies:
    - build
  cache:
    paths:
      - yourname.github.io
  script:
    - if [ ! -d &amp;quot;yourname.github.io&amp;quot; ];then git clone git@github.com:yourname/yourname.github.io.git;else cd yourname.github.io &amp;amp;&amp;amp; git pull &amp;amp;&amp;amp; cd -;fi
    - echo &amp;quot;Deploying updates to GitHub...&amp;quot;
    - pwd
    - rm yourname.github.io/* -r
    - cp public/* yourname.github.io/ -r
    - cd yourname.github.io
    - git config core.sshCommand &#39;ssh -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no&#39; 
    - git add -A
    - git config user.name &amp;quot;yourname&amp;quot;
    - git config user.email &amp;quot;youremail@gmail.com&amp;quot;
    - git commit -m &amp;quot;rebuilding site `TZ=&amp;quot;Asia/Shanghai&amp;quot; date +&amp;quot;%Y-%m-%d %H:%M:%S&amp;quot;`&amp;quot; || true
    - git push --force -u origin master
    - cd ..
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这样会在runner的本地环境缓存github pages的repo信息，每次将hugo生成的public内容全量替换进去，git提交的时候只会提交相应的变动，即节省时间也节省github的资源。&lt;/p&gt;

&lt;p&gt;随时随地在gitlab的WebIDE中新建markdown，保存后会自动更新到github pages，终于不再受终端限制了。&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>一个glibc内存分配场景分析</title>
      <link>https://xiking.win/2019/04/25/a-glibc-malloc-scenario/</link>
      <pubDate>Thu, 25 Apr 2019 10:53:38 +0000</pubDate>
      
      <guid>https://xiking.win/2019/04/25/a-glibc-malloc-scenario/</guid>
      
        <description>&lt;p&gt;最近看到了2014年关于twemproxy中的issue中有人提到采用pipeline方式大量请求会导致twemproxy占用大量内存的讨论，这个问题在几年前也曾经尝试解决，未果而终。不妨深入了解一下。&lt;/p&gt;

&lt;p&gt;因为twemproxy自己对内存池管理来避免频繁申请内存，并且内存池只能增长不能自动缩小，缺乏一定的健壮性和防攻击性。并且看了代码后，知道主要的内存占用就是mbuf内存块，一个mbuf大小默认是16384，于是尝试直接将mbuf入池的操作改为释放mbuf，按理说，在压力过后，mbuf会全部释放，但是测试结果并没有，内存还是被大量占用，操作系统看来内存根本没有释放。&lt;/p&gt;

&lt;p&gt;当尝试把msg缓存池也一并释放，结果是内存被完全释放了。后来有尝试mbuf不释放，只释放msg，结果也是内存不释放，只有msg和mbuf一并释放，内存才会被操作系统回收。&lt;/p&gt;

&lt;p&gt;因为默认采用glibc中的malloc，malloc会调用brk或mmap系统调用来分配内存，默认大于128k的会通过mmap来申请，其他的会采用brk来申请。内部也通过arena来进行内存的管理，并且有main arena和thread arena。当调用free时，内存也不是直接交还操作系统，而是交给glic进行管理，arena就是管理的原信息。&lt;/p&gt;

&lt;p&gt;在twemproxy中mbuf的申请和msg的申请是间隔申请的，并且都不会大于128k，所以内存都是通过brk申请的堆内存，当只尝试释放掉所有的mbuf内存后，在操作系统看来是通过brk申请的内存中出现了非常多的空洞，而这些空洞无法被操作系统回收，因为brk是单向增长或递减，高地址内存不释放，低地址空间无法被回收，这就导致malloc产生内存碎片。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;参考&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/twitter/twemproxy/issues/203&#34;&gt;https://github.com/twitter/twemproxy/issues/203&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://wooyun.js.org/drops/深入理解 glibc malloc.html&#34;&gt;https://wooyun.js.org/drops/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%20glibc%20malloc.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.cnblogs.com/zhaoyl/p/3820852.html&#34;&gt;https://www.cnblogs.com/zhaoyl/p/3820852.html&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
      
    </item>
    
    <item>
      <title>imgur图床迁移github图床</title>
      <link>https://xiking.win/2019/03/28/imgur-to-github-images-bed/</link>
      <pubDate>Thu, 28 Mar 2019 15:58:20 +0000</pubDate>
      
      <guid>https://xiking.win/2019/03/28/imgur-to-github-images-bed/</guid>
      
        <description>

&lt;p&gt;因为&lt;a href=&#34;https://xiking.win/2019/03/27/dns-cache-pollution/&#34;&gt;imgur被dns劫持&lt;/a&gt;，所以blog图片都裂了，没有好的办法，只能找其他的替代图床。之前也一直不忍心使用github在用作图床，毕竟github是用作代码托管和IT社区，不以代码分享的使用就是滥用。&lt;/p&gt;

&lt;p&gt;但是在&lt;a href=&#34;https://www.v2ex.com/t/299197&#34;&gt;V2EX&lt;/a&gt;上看到几年前有个使用github做图床的repo作者询问了github官方，给出的答复这种使用方式不属于滥用，是允许的。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt; Thanks for your question! We&#39;ve reviewed your project and, in addition to uploading files, it appears to assist in generating rawgit URLs. Is that correct? 
&amp;gt; 
&amp;gt; If that&#39;s the case, your project doesn&#39;t appear to violate GitHub&#39;s Terms of Service, though you may want to check in with the owner of rawgit if you haven&#39;t already done so. 
&amp;gt; 
&amp;gt; Of course, any individual who decided to use your code would be responsible for making sure their usage and content didn&#39;t violate our Terms. 
&amp;gt; 
&amp;gt; Please let me know if you have any other questions.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;既然官方给的回复是这种方式是合理的，那就将图床迁移到github了。&lt;/p&gt;

&lt;h3 id=&#34;0-创建github-repo用做图床&#34;&gt;0. 创建github repo用做图床&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;创建repo，命名&lt;code&gt;i&lt;/code&gt;，尽量简短url长度&lt;/li&gt;
&lt;li&gt;设置token&lt;/li&gt;
&lt;li&gt;配置PicGo，分支使用非master分支，避免让github统计成contribution，点亮小绿星。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/yongman/i/img/picgo/20190328174823.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;1-下载原图&#34;&gt;1. 下载原图&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;修改hosts&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;由于i.imgur.com被dns污染，通过未污染的dns查询正确的地址，加入hosts文件。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;dig @8.8.8.8 i.imgur.com

; &amp;lt;&amp;lt;&amp;gt;&amp;gt; DiG 9.10.3-P4-Ubuntu &amp;lt;&amp;lt;&amp;gt;&amp;gt; @8.8.8.8 i.imgur.com
; (1 server found)
;; global options: +cmd
;; Got answer:
;; -&amp;gt;&amp;gt;HEADER&amp;lt;&amp;lt;- opcode: QUERY, status: NOERROR, id: 16557
;; flags: qr rd ra; QUERY: 1, ANSWER: 2, AUTHORITY: 0, ADDITIONAL: 1

;; OPT PSEUDOSECTION:
; EDNS: version: 0, flags:; udp: 512
;; QUESTION SECTION:
;i.imgur.com.			IN	A

;; ANSWER SECTION:
i.imgur.com.		8577	IN	CNAME	prod.imgur.map.fastlylb.net.
prod.imgur.map.fastlylb.net. 27	IN	A	151.101.24.193

;; Query time: 43 msec
;; SERVER: 8.8.8.8#53(8.8.8.8)
;; WHEN: Thu Mar 28 17:51:58 CST 2019
;; MSG SIZE  rcvd: 97
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在hosts文件中添加记录&lt;/p&gt;

&lt;p&gt;&lt;code&gt;151.101.24.193 i.imgur.com&lt;/code&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;下载图片&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;code&gt;grep &amp;quot;i.imgur.com&amp;quot; ../posts/* | cut -d &#39;(&#39; -f2 | cut -d &#39;)&#39; -f1 | xargs wget&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;批量将imgur图片下载，并保留原文件名，这样后面更新图片链接方便了。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/yongman/i/img/picgo/20190328172912.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;上传github&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;将图片commit后push到刚刚创建的repo。&lt;/p&gt;

&lt;h3 id=&#34;2-markdown链接更新&#34;&gt;2. markdown链接更新&lt;/h3&gt;

&lt;p&gt;因为图片的文件名保持不变，只需要更新url的路径前缀即可，使用如下命令完成。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;sed -i &#39;s/i.imgur.com/raw.githubusercontent.com\/yongman\/i\/img\/picgo\//g&#39; *&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&#34;3-生成静态页面&#34;&gt;3. 生成静态页面&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;hexo g&lt;/code&gt;大功告成。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;参考&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://www.jianshu.com/p/87ea6603a824&#34;&gt;https://www.jianshu.com/p/87ea6603a824&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.v2ex.com/t/299197&#34;&gt;https://www.v2ex.com/t/299197&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
      
    </item>
    
    <item>
      <title>DNS劫持和污染原理</title>
      <link>https://xiking.win/2019/03/27/dns-cache-pollution/</link>
      <pubDate>Wed, 27 Mar 2019 10:30:23 +0000</pubDate>
      
      <guid>https://xiking.win/2019/03/27/dns-cache-pollution/</guid>
      
        <description>&lt;p&gt;之前一直用的imgur图床最近几天突然打不开了，浏览器打开提示证书不对，证书是facebook的证书，看来是dns把域名解析到facebook的服务器了，因为facebook的地址已经被封锁，这就实现了间接封锁imgur。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/yongman/i/img/picgo/qDckBa8.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/yongman/i/img/picgo/KKbOFfj.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/yongman/i/img/picgo/18Hs8hf.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/yongman/i/img/picgo/xwYrFe8.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/yongman/i/img/picgo/pvTO32c.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;可以看到国内的dns解析都指向了facebook服务器地址，而国外的dns解析都是正常的。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;DNS劫持是DNS服务器中的记录真正的被修改为错误记录。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;DNS污染是DNS服务器中的记录是正确的，但是在链路上有其他的设备会应答回复错误的DNS数据包，导致查询结果被污染。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;DNS劫持实现&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;网络运营商处于某些目的或者应政府要求，对DNS服务器进行了某些人为操作，就导致了使用ISP提供的DNS服务器无法将域名正确解析到IP地址。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;DNS污染实现&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;因为DNS使用的UDP实现，并且传输的都是未加密的数据包，所以在客户端向DNS服务器发送查询报文，中间的路由器、交换机和网关等设备是可以进行数据包解析，旁路设备可以立刻发送一个回复报文，而报文的内容是可以任意伪造，并非是DNS服务器的正确结果，这就是DNS污染。客户端可能会收到多个回复报文，而先到达的报文被接受，晚到的报文被丢弃，由于延迟，而往往被丢弃的才是正确的结果，从而导致DNS污染的发生。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;解决方法&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;对于DNS劫持，只需要将本机的dns服务器指向权威的dns即可，比如谷歌的8.8.8.8。&lt;/p&gt;

&lt;p&gt;对于DNS污染就是将DNS报文加密传输，采用代理将dns请求通过加密链路转发到国外的主机，然后在主机上的解析结果再加密传输回客户端。&lt;/p&gt;

&lt;p&gt;上面的两种方式也都是对个人来说是很容易解决的，但是如果像这种公共资源被dns劫持，因为广大的用户不可能全部都自己配置dns或者使用代理访问，这就没有很好的解决办法了，对于这种imgur图床被劫持，貌似也只能进行图床迁移了。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;参考&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/DNS_spoofing&#34;&gt;https://en.wikipedia.org/wiki/DNS_spoofing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://baike.baidu.com/item/DNS%E6%B1%A1%E6%9F%93&#34;&gt;https://baike.baidu.com/item/DNS污染&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://pxx.io/2014/08/24/is-a-domain-polluted.html&#34;&gt;https://pxx.io/2014/08/24/is-a-domain-polluted.html&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
      
    </item>
    
    <item>
      <title>IP MTU和TCP MSS</title>
      <link>https://xiking.win/2019/01/21/ip-mtu-and-tcp-mss/</link>
      <pubDate>Mon, 21 Jan 2019 11:04:19 +0000</pubDate>
      
      <guid>https://xiking.win/2019/01/21/ip-mtu-and-tcp-mss/</guid>
      
        <description>&lt;p&gt;使用群晖的vmm虚拟lede软路由几个月，在nas下载流量较大的时候会出现lede掉线，多拨不稳定掉线，但是又想使用lede的插件中心，方便配置ss。&lt;/p&gt;

&lt;p&gt;所以采用了双软路由，ikuai来进行pppoe多拨，lede用作旁路路由，群晖网络配置ikuai为默认网关，因为nas下载流量较大，直接挂在一级路由下，减少数据包的多一次转发。&lt;/p&gt;

&lt;p&gt;使用ikuai提供dhcp服务，dhcp服务中配置默认网关是lede地址，这样其他的设备都会用lede做默认网关，可以利用到lede的多种插件。&lt;/p&gt;

&lt;p&gt;简单的拓扑图&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/yongman/i/img/picgo/n0EKgbH.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;在配置完ikuai后，在系统设置中修改了tcp最大包长度，默认是1400，手动修改成了1500，因为其他设备默认的IP MTU设置的是1500，就出现了很怪异的现象，就是ikuai后台本身能够进去，但是经常不稳定，nas、lede的https和ssh都会出现卡死的情况。ssh登录nas，tcpdump抓包。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/yongman/i/img/picgo/dp8TcPI.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/yongman/i/img/picgo/dlzT2OV.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;IP MTU配置了1500，数据包的格式如下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/yongman/i/img/picgo/fIMPvfy.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;在tcpdump抓包可以看到很多这种回复的数据包，并且ack是同一个报文，一直在进行重传，并且长度1436，在ikuai中将MSS设置成了1500，这样在ikuai向外转发时，数据包的IP MTU长度为：1500+20+20=1540，因为网络设置PPPOE默认MTU是1480，所以数据包大小超过MTU，导致了丢包。&lt;/p&gt;

&lt;p&gt;解决方式就是将ikuai中的TCP MSS设置成默认值1400，或者取消该设置。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;参考&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://blog.apnic.net/2014/12/15/ip-mtu-and-tcp-mss-missmatch-an-evil-for-network-performance/&#34;&gt;https://blog.apnic.net/2014/12/15/ip-mtu-and-tcp-mss-missmatch-an-evil-for-network-performance/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://blog.perterpon.com/2017/09/12/why-MTU-equals-1500/&#34;&gt;http://blog.perterpon.com/2017/09/12/why-MTU-equals-1500/&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
      
    </item>
    
    <item>
      <title>LRU算法和LRU变种</title>
      <link>https://xiking.win/2018/12/26/lru-and-lru-variants/</link>
      <pubDate>Wed, 26 Dec 2018 16:57:53 +0000</pubDate>
      
      <guid>https://xiking.win/2018/12/26/lru-and-lru-variants/</guid>
      
        <description>

&lt;h3 id=&#34;1-lru&#34;&gt;1. LRU&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/yongman/i/img/picgo/BNFQTNg.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;实现最简单的lru实现，其中保存的是最近一段时间访问的数据，当一个新数据被访问，数据会被加入队列头，如果队列超过长度限制，就在尾部淘汰；如果访问的数据在队列，则将其重新移到队头。&lt;/p&gt;

&lt;p&gt;因为LRU的核心思想是：如果数据最近被访问过，那么将来被访问的几率也更高。&lt;/p&gt;

&lt;p&gt;实现简单，但是存在LRU污染，偶发性或批量的操作会导致LRU命中率急剧下降。&lt;/p&gt;

&lt;h3 id=&#34;2-lru-k&#34;&gt;2. LRU-K&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/yongman/i/img/picgo/HCzEKyR.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;与LRU不同的是，LRU-K是在数据访问达到K后，将访问历史队列中的数据移动到LRU队列中。&lt;/p&gt;

&lt;p&gt;LRU-K可以避免偶发性访问带来的LRU污染，能够提高LRU命中率。&lt;/p&gt;

&lt;p&gt;需要额外维护一份最近访问数据的被访问次数的历史队列。&lt;/p&gt;

&lt;p&gt;LRU-2在实际应用中验证效果最优。&lt;/p&gt;

&lt;h3 id=&#34;3-双队列&#34;&gt;3. 双队列&lt;/h3&gt;

&lt;p&gt;类似LRU-2，但是实现上比LRU-2简单，将访问历史计数队列改成了一个FIFO的队列，实现上成本更低。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/yongman/i/img/picgo/CPZKUzV.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;4-多队列&#34;&gt;4. 多队列&lt;/h3&gt;

&lt;p&gt;根据数据访问频率划分多个队列，不同队列具有不同优先级。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/yongman/i/img/picgo/0aR1hdL.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;新数据访问，会插入Q0队列。&lt;/li&gt;
&lt;li&gt;每个队列按LRU算法管理。&lt;/li&gt;
&lt;li&gt;数据访问达到一定次数，会提升优先级，数据从低一级队列删除，加入高一级队列头。&lt;/li&gt;
&lt;li&gt;数据特定时间内没有被访问，会降低优先级，数据从高一级队列移动到低一级队列头。&lt;/li&gt;
&lt;li&gt;数据会被定时扫描。&lt;/li&gt;
&lt;li&gt;Q-history中的数据历史访问频率信息被清空，重新加入队列时要重新计数。&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;总结&#34;&gt;总结&lt;/h3&gt;

&lt;p&gt;复杂度：LRU-2 &amp;gt; MQ(2) -&amp;gt; 2Q &amp;gt; LRU&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>群晖nas软路由实现全站https</title>
      <link>https://xiking.win/2018/12/05/synology-lede-to-https/</link>
      <pubDate>Wed, 05 Dec 2018 23:08:37 +0000</pubDate>
      
      <guid>https://xiking.win/2018/12/05/synology-lede-to-https/</guid>
      
        <description>&lt;p&gt;家用宽带从移动转向电信，体验果然不一样了，从此可以告别移动大内网，告别了frp内网穿透，有了公网ip。原来一直在用的http突然完全暴露在公网下，个人nas虽然一般不会被盯上，但是还是感觉不安全，决定将全面https化。&lt;/p&gt;

&lt;p&gt;要https化的主要有LEDE软路由、群晖NAS和NAS上的docker服务。&lt;/p&gt;

&lt;p&gt;软路由：外网的入口，然后做端口转发，所以LEDE路由器首先要https。&lt;/p&gt;

&lt;p&gt;LEDE自带的酷软中心，已经内置了Let&amp;rsquo;s Encrypt自动签发证书，采用的aliddns的api实现。由于路由器上实现了多拨，所以会有多个公网ip，申请证书的时候申请了通配符子域名证书。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/yongman/i/img/picgo/W2HEfj4.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;自动签发后生成的证书和key文件最后会生成/etc/uhttpd.key和/etc/uhttpd.crt，由于家用宽带基本上都屏蔽了80和443端口，会自动给配置一条路由转发规则，很是贴心。&lt;/p&gt;

&lt;p&gt;群晖：将路由上生成的证书和key文件，通过dsm中的安全性中的&lt;code&gt;证书&lt;/code&gt;选项中新增证书和key，然后导入证书。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/yongman/i/img/picgo/AN829Wc.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;然后配置系统默认使用新证书。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/yongman/i/img/picgo/SYJSatv.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Docker中运行的home assistant: 复制生成的证书到docker的挂载目录下，修改home assistant的configuration.yaml文件，在http下面添加配置：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/yongman/i/img/picgo/KtOEps9.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;后续：
由于Let&amp;rsquo;s Encrypt证书有效期90天，所以3个月后需要重新renew证书，有时间写个定时任务，renew证书后自动分发给nas和ha。&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>RocksDB参数调优</title>
      <link>https://xiking.win/2018/12/05/rocksdb-tuning/</link>
      <pubDate>Wed, 05 Dec 2018 17:58:49 +0000</pubDate>
      
      <guid>https://xiking.win/2018/12/05/rocksdb-tuning/</guid>
      
        <description>&lt;p&gt;RocksDB对比LevelDB暴露了很多参数来适应更多的应用场景，带来的好处就是可以通过tuning使系统性能达到最大，当然，如果tuning不合理会有相反的后果。在Facebook内部，RocksDB既能用在普通机械盘，生产环境也有跑在SSD和全内存的场景下。&lt;/p&gt;

&lt;p&gt;当决定在生产环境使用RocksDB的话需要对RocksDB的原理和对应参数的含义非常清楚，修改参数之前要知道修改这个参数所带来的后果。&lt;/p&gt;

&lt;p&gt;官方github &lt;a href=&#34;https://github.com/facebook/rocksdb/wiki/RocksDB-Tuning-Guide&#34;&gt;wiki&lt;/a&gt;有专门的RocksDB调优的页面，可以对调优方面有更深入的理解。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Amplification factors&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;其实对数据库系统的调优很大一部分工作是在写放大、读放大和空间放大这三个放大因子之间做取舍。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;写放大&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;平均写入1个字节，引擎中在数据的声明周期内实际会写入n个字节，其写放大率是n。也就是如果在业务方写入速度是10MB/s，在引擎端或者操作系统层面能观察到的数据写入速度是30MB/s，这时，系统的写放大率就是3。写放大过大会制约系统的实际吞吐。并且对于SSD来说，越大的写放大，也会导致SSD寿命缩短。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;读放大&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;一个小的读请求，系统所需要读去n个页面来完成查询，其读放大率是n。逻辑上的读操作可能会命中引擎内部的cache或者文件系统cache，命中不了cache就会进行实际的磁盘IO，命中cache的读取操作的代价虽然很低，但是也会消耗cpu。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;空间放大&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;就是平均存储1个字节的数据，在存储引擎内部所占用的磁盘空间n和字节，其空间放大是n。比如刚刚写入10MB的数据，大小在磁盘上实际占用了100MB，这是空间放大率就是10。空间放大和写放大在调优的时候往往是排斥的，空间放大越大，那么数据可能不需要频繁的compaction，其写放大就会降低；如果空间放大率设置的小，那么数据就需要频繁的compaction来释放存储空间，导致写放大增大。&lt;/p&gt;

&lt;p&gt;所以调优就是根据实际应用场景进行多方面权衡的一个过程。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Statistics&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;statistics是RocksDB用来统计系统性能和吞吐信息的功能，开启它可以更直接的提供性能观测数据，能快速发现系统的瓶颈或系统运行状态，由于统计信息在引擎内的各类操作都会设置很多的埋点，用来更新统计信息，但是开启statistics会增加5%到10%的额外开销。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    ** Compaction Stats **
    Level Files  Size(MB) Score Read(GB)  Rn(GB) Rnp1(GB) Write(GB) Wnew(GB) Moved(GB) W-Amp Rd(MB/s) Wr(MB/s) Comp(sec) Comp(cnt) Avg(sec) Stall(sec) Stall(cnt) Avg(ms)     KeyIn   KeyDrop
    -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
    L0      2/0        15   0.5     0.0     0.0      0.0      32.8     32.8       0.0   0.0      0.0     23.0    1457      4346    0.335       0.00          0    0.00             0        0
    L1     22/0       125   1.0   163.7    32.8    130.9     165.5     34.6       0.0   5.1     25.6     25.9    6549      1086    6.031       0.00          0    0.00    1287667342        0
    L2    227/0      1276   1.0   262.7    34.4    228.4     262.7     34.3       0.1   7.6     26.0     26.0   10344      4137    2.500       0.00          0    0.00    1023585700        0
    L3   1634/0     12794   1.0   259.7    31.7    228.1     254.1     26.1       1.5   8.0     20.8     20.4   12787      3758    3.403       0.00          0    0.00    1128138363        0
    L4   1819/0     15132   0.1     3.9     2.0      2.0       3.6      1.6      13.1   1.8     20.1     18.4     201       206    0.974       0.00          0    0.00      91486994        0
    Sum  3704/0     29342   0.0   690.1   100.8    589.3     718.7    129.4      14.8  21.9     22.5     23.5   31338     13533    2.316       0.00          0    0.00    3530878399        0
    Int     0/0         0   0.0     2.1     0.3      1.8       2.2      0.4       0.0  24.3     24.0     24.9      91        42    2.164       0.00          0    0.00      11718977        0
    Flush(GB): accumulative 32.786, interval 0.091
    Stalls(secs): 0.000 level0_slowdown, 0.000 level0_numfiles, 0.000 memtable_compaction, 0.000 leveln_slowdown_soft, 0.000 leveln_slowdown_hard
    Stalls(count): 0 level0_slowdown, 0 level0_numfiles, 0 memtable_compaction, 0 leveln_slowdown_soft, 0 leveln_slowdown_hard
    
    ** DB Stats **
    Uptime(secs): 128748.3 total, 300.1 interval
    Cumulative writes: 1288457363 writes, 14173030838 keys, 357293118 batches, 3.6 writes per batch, 3055.92 GB user ingest, stall micros: 7067721262
    Cumulative WAL: 1251702527 writes, 357293117 syncs, 3.50 writes per sync, 3055.92 GB written
    Interval writes: 3621943 writes, 39841373 keys, 1013611 batches, 3.6 writes per batch, 8797.4 MB user ingest, stall micros: 112418835
    Interval WAL: 3511027 writes, 1013611 syncs, 3.46 writes per sync, 8.59 MB written
&lt;/code&gt;&lt;/pre&gt;

&lt;ol&gt;
&lt;li&gt;Parallelism options&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;LSM架构的引擎，后台主要有两种线程，flush和compaction。在RocksDB中，两种线程有不同的优先级，flush优先级高，compaction优先级低。为了充分利用多核，RocksDB中的两种线程可以配置线程数。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;max_background_flushes&lt;/strong&gt; 是后台memtable dump成sstable的并发线程数。默认是1，但是当使用多个&lt;code&gt;column family&lt;/code&gt;时，内部会存在多个memtable，可能会同时发生flush，如果线程是1，在写入量大的情况下，可能会导致flush不及时，出现无法写入的情况。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;max_background_compactions&lt;/strong&gt; 是后台sstable flush线程，因为一般RocksDB会有多层，涉及多个sstable文件，并发compaction会加快compaction的速度，如果compaction过慢，达到&lt;code&gt;soft_pending_compaction_bytes_limit&lt;/code&gt;会发生阻塞，达到&lt;code&gt;hard_pending_compaction_bytes&lt;/code&gt;会停写。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;General options&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;filter_policy&lt;/strong&gt; 这个就是每个sstable的bloom filter，使用bloom filter可以大幅减少不必要的磁盘IO。在bits_per_key为10的情况下，bloom filter错误率估计为1%，也就是存在如下情况：有1%的概率出现错误，key实际上不存在，但是在bloom filter查询的结果是存在的。这种情况导致会有1%的不必要的磁盘IO。&lt;/p&gt;

&lt;p&gt;当然bits_per_key越大，bloom filter误判率越低，但是占用的内存和写放大会相应增加。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;block_cache&lt;/strong&gt; 可以配置大小的LRU cache，用来缓存未经过压缩的block。由于访问cache需要加锁访问，当大部分数据都在cache中时，多线程并发访问cache可能会出现锁竞争的瓶颈，所以LRU cache还有一个shard_bits参数，将LRU cache分片，其实就是对锁进行拆分，不同分片的cache不会出现竞争。默认shard_bits是6，那么cache的shard数目就是&lt;code&gt;2^6=64&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;allow_os_buffer&lt;/strong&gt; 操作系统buffer是用来缓存sstable文件的cache，sstable在文件中是压缩的，所以操作系统buffer是对磁盘上的sstable文件block的cache。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;max_open_files&lt;/strong&gt; 最大打开文件数。RocksDB对于打开文件的句柄也会放在cache中，当sstable文件过多，超过max_open_files限制后，会将cache中淘汰的文件句柄强制关闭，下次读取文件的时候再次打开。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;table_cache_numshardbits&lt;/strong&gt; 和block_cache中的shard_bits作用一致，主要是为了拆分互斥锁。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;block_size&lt;/strong&gt; RocksDB中sstable文件的由block组成，block也是文件读写的最小逻辑单位，当读取一个很小的key，其实会读取一个block到内存，然后查找数据。默认的block_size大小为4KB。每个sstable文件都会包含索引的block，用来加快查找。所以block_size越大，index就会越少，也会相应的节省内存和存储空间，降低空间放大率，但是会加剧读放大，因为读取一个key实际需要读取的文件大小随之增加了。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Sharing cache and thread pool&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;在一个进程中启动多个RocksDB实例，可以共享cache和线程池，暂时没有这方面需求。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Flushing options&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;RocksDB中的写入在写WAL后会先写入memtable，memtable达到特定大小后会转换成immutable membtale，immutable会flush成sstable。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;write_buffer_size&lt;/strong&gt; 配置单个memtable的大小，当memtable达到指定大小，会自动转换成immutable memtable并且新创建一个memtable。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;max_write_buffer_number&lt;/strong&gt; 指定一个RocksDB中memtable和immutable memtable总的数量。当写入速度过快，或者flush线程速度较慢，出现memtable数量超过了指定大小，请求会无法写入。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;min_write_buffer_number_to_merge&lt;/strong&gt; immutable memtable在flush之前先进行合并，比如参数设置为2，当一个memtable转换成immutable memtable后，RocksDB不会进行flush操作，等到至少有2个后才进行flush操作。这个参数调大能够减少磁盘写的次数，因为多个memtable中可能有重复的key，在flush之前先merge后就避免了旧数据刷盘；但是带来的问题是每次数据查找，当memtable中没有对应数据，RocksDB可能需要遍历所有的immutable memtable，会影响读取性能。&lt;/p&gt;

&lt;p&gt;下面是官方wiki配置的一个例子：&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;write_buffer_size = 512MB;&lt;/p&gt;

&lt;p&gt;max_write_buffer_number = 5;&lt;/p&gt;

&lt;p&gt;min_write_buffer_number_to_merge = 2;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;按上面的配置，如果数据写入速度是16MB/s，每32秒会生成一个新的memtable，每64秒会生成两个memtable进行merge和flush操作。如果flush速度很快，memtable占用的内存应该小于1.5G，当磁盘IO繁忙，flush速度慢，最多会有5个memtable，占用内存达到2.5G，后续就无法写入。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Level Style Compaction&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;具体的compaction逻辑查看代码实现或者自行搜索。下面主要看一下涉及到compaction的配置项。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;level0_file_num_compaction_trigger&lt;/strong&gt; L0达到指定个数的sstable后，触发compaction L0-&amp;gt;L1。所以L0稳定状态下大小为&lt;code&gt;write_buffer_size*min_write_buffer_number_to_merge*level0_file_num_compaction_trigger&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;max_bytes_for_level_base&lt;/strong&gt; L1的总大小，L1的大小建议设置成和L0大小一致，提升L0-&amp;gt;L1的compaction效率。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;max_bytes_for_level_multiplier&lt;/strong&gt; L(n+1)总大小=L(n) * max_bytes_for_level_multiplier，默认值为10，下一层是上一层容量的10倍。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;target_file_size_base&lt;/strong&gt; L1层单个sstable文件的大小。建议该参数设置为&lt;code&gt;max_bytes_for_level_base/10&lt;/code&gt;，能够保证L1层的sstable文件数量为10个。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;target_file_size_multiplier&lt;/strong&gt; 下一层文件大小是上一层文件大小的倍数，默认值为1，也就是不同层的单个sstable文件大小一致，调大这个值可以减少每层的文件数量。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;compression_per_level&lt;/strong&gt; 配置各Level的压缩模式，由于L0的特殊性，L0的merge操作可能涉及L1的全部sstable，为了提高性能，L0和L1不要启用压缩，在其他更高层上启用压缩。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;num_levels&lt;/strong&gt; RocksDB中的层次数量，默认是7。如果L0大小有512MB，6层能容纳&lt;code&gt;512M+512M+5G+50G+500G+5T&lt;/code&gt;，如果配置是7，在数据量少于前面计算的5T+的数据之前，最后一层是不会被使用的。如果num_levels配置为6，那么最下面一层数据量会大于5T。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Write stalls&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;RocksDB在flush或compaction速度来不及处理新的写入，会启动自我保护机制，延迟写或者禁写。主要有几种情况：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Too many memtables&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;写限速&lt;/strong&gt;：如果max_write_buffer_number大于3，将要flush的memtables大于等于max_write_buffer_number-1，write会被限速。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;禁写&lt;/strong&gt;：memtable个数大于等于max_write_buffer_number，触发禁写，等到flush完成后允许写入。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Stopping writes because we have 5 immutable memtables (waiting for flush), max_write_buffer_number is set to 5&lt;br /&gt;
Stalling writes because we have 4 immutable memtables (waiting for flush), max_write_buffer_number is set to 5&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
&lt;li&gt;Too many level-0 SST files&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;写限速&lt;/strong&gt;：L0文件数量达到level0_slowdown_writes_trigger，触发写限速。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;禁写&lt;/strong&gt;：L0文件数量达到level0_stop_writes_trigger，禁写。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Stalling writes because we have 4 level-0 files&lt;/p&gt;

&lt;p&gt;Stopping writes because we have 20 level-0 files&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
&lt;li&gt;Too many pending compaction bytes&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;写限速&lt;/strong&gt;：等待compaction的数据量达到soft_pending_compaction_bytes，触发写限速。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;禁写&lt;/strong&gt;：等待compaction的数据量达到hard_pending_compaction_bytes，触发禁写。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Stalling writes because of estimated pending compaction bytes 500000000&lt;/p&gt;

&lt;p&gt;Stopping writes because of estimated pending compaction bytes 1000000000&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;当出现write stall时，可以按具体的系统的状态调整如下参数：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;调大max_background_flushes&lt;/li&gt;
&lt;li&gt;调大max_write_buffer_number&lt;/li&gt;
&lt;li&gt;调大max_background_compactions&lt;/li&gt;
&lt;li&gt;调大write_buffer_size&lt;/li&gt;
&lt;li&gt;调大min_write_buffer_number_to_merge&lt;/li&gt;
&lt;/ul&gt;

&lt;ol&gt;
&lt;li&gt;Bloom filters and index&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;RocksDB中使用bloom filter来尽可能避免不必要的sstable访问，在RocksDB中bloom filter有两种：block-based filter和full filter。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;block-based filter&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;这种filter是保存在每个block内部，一个sstable file有多个block。所以每次访问sstable需要先访问一次block索引，找到对应的block后加载bloom filter或者是在cache中获取对应的filter查询。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;full filter&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;每个sstable文件只有一个filter，在访问sstable之前可以事先判断key的存在性，能够避免不存在key的索引访问。&lt;/p&gt;

&lt;p&gt;一个典型的256MB的SST文件的index/filter的大小在0.5/5MB，比系统内默认的block大很多倍，这种场景对于block cache不友好，LRU cache是按block来进行置换，一部分block失效会导致重复读取多次SST加载index和filter。&lt;/p&gt;

&lt;p&gt;对于上面大SST文件的index或者filter block，RocksDB支持两级index，切分index/filter。每次读取和cache的粒度变小，cache更高效。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;bloom_bits_per_key&lt;/strong&gt; 平均每个key需要的bloom filter空间。配置bloom filter的容量，默认是10，存在1%的判错概率。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;cache_index_and_filter_blocks_with_high_priority&lt;/strong&gt; 可以配置RocksDB高优先cache index和filter，优先剔除数据block。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;pin_l0_filter_and_index_blocks_in_cache&lt;/strong&gt; 使level 0中的SST的index和filter常驻cache。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;配置实例&lt;/li&gt;
&lt;/ol&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;存储介质flash&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;thread_pool 4
options.options.compaction_style = kCompactionStyleLevel;
options.write_buffer_size = 67108864; // 64MB
options.max_write_buffer_number = 3;
options.target_file_size_base = 67108864; // 64MB
options.max_background_compactions = 4;
options.level0_file_num_compaction_trigger = 8;
options.level0_slowdown_writes_trigger = 17;
options.level0_stop_writes_trigger = 24;
options.num_levels = 4;
options.max_bytes_for_level_base = 536870912; // 512MB
options.max_bytes_for_level_multiplier = 8;
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;全内存&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;options.allow_mmap_reads = true;
BlockBasedTableOptions table_options;
table_options.filter_policy.reset(NewBloomFilterPolicy(10, true));
table_options.no_block_cache = true;
table_options.block_restart_interval = 4;
options.table_factory.reset(NewBlockBasedTableFactory(table_options));
options.level0_file_num_compaction_trigger = 1;
options.max_background_flushes = 8;
options.max_background_compactions = 8;
options.max_subcompactions = 4;
options.max_open_files = -1;
ReadOptions.verify_checksums = false
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
    <item>
      <title>玩转Home Assistant - 集成小米空气净化器、米家智能家居、broadlink设备、dueros、google assistant等</title>
      <link>https://xiking.win/2018/11/15/home-assistant-with-xiaomi-airpurifier/</link>
      <pubDate>Thu, 15 Nov 2018 01:27:53 +0000</pubDate>
      
      <guid>https://xiking.win/2018/11/15/home-assistant-with-xiaomi-airpurifier/</guid>
      
        <description>

&lt;p&gt;Home Assistant是一个开源智能自动化平台，python语言编写，支持多种平台，官方支持树莓派、普通linux主机和docker方式，支持的外围设备和平台也非常多，当然小米智能家居的产品也是支持的。(持续更新中&amp;hellip;)&lt;/p&gt;

&lt;h3 id=&#34;docker环境准备&#34;&gt;Docker环境准备&lt;/h3&gt;

&lt;p&gt;前段时间搞的黑群晖DS918+，放在角落里只用来跑vm软路由和nas心有不甘，加上docker的支持，可以很方便的运行多种服务。
&lt;img src=&#34;https://raw.githubusercontent.com/yongman/i/img/picgo/VVnaj6R.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;目前已经在跑的docker有：aria2、迅雷远程、人人影视和home assistant。&lt;/p&gt;

&lt;h3 id=&#34;hass环境安装&#34;&gt;Hass环境安装&lt;/h3&gt;

&lt;p&gt;官方文档的docker安装方式也有专门的群晖nas教程：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;群晖上安装docker套件&lt;/li&gt;
&lt;li&gt;点击注册表&lt;/li&gt;
&lt;li&gt;搜索homeassistant/home-assistant&lt;/li&gt;
&lt;li&gt;下载docker镜像&lt;/li&gt;
&lt;li&gt;点击镜像，选中后点击启动镜像&lt;/li&gt;
&lt;li&gt;填docker实例名&lt;/li&gt;
&lt;li&gt;点击高级设置&lt;/li&gt;
&lt;li&gt;设置自动启动&lt;/li&gt;
&lt;li&gt;网络，使用宿主机网络&lt;/li&gt;
&lt;li&gt;添加TZ环境变量&lt;/li&gt;
&lt;li&gt;增加卷，挂载/docker/homeassistant到/conf&lt;/li&gt;
&lt;li&gt;确认下一步。&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;接入小米空气净化器&#34;&gt;接入小米空气净化器&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;查找小米空气净化器地址和token&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;miio是小米智能家居通信协议的库，这里使用miio来进行局域网发现。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;安装miio&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;npm install -g miio

miio &amp;lt;command&amp;gt;

Commands:
miio configure &amp;lt;idOrIp&amp;gt;                   Control a device by invoking the
                                        given method
miio control &amp;lt;idOrIp&amp;gt; &amp;lt;method&amp;gt;            Control a device by invoking the
[params..]                                given method
miio discover                             Discover devices on the local
                                        network
miio inspect &amp;lt;idOrIp&amp;gt;                     Inspect a device
miio protocol &amp;lt;command&amp;gt;                   Inspect and test raw miIO-commands
miio tokens &amp;lt;command&amp;gt;                     Manage tokens of devices
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;发现&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/yongman/i/img/picgo/GSFJzPt.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;路由器配置mac地址静态地址分配&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/yongman/i/img/picgo/BJapq5m.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;增加homeassistant配置&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;修改配置文件夹中的configuration.yaml配置，增加：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;fan:
  - platform: xiaomi_miio
    host: 192.168.31.137
    token: 3bbd8a71d60bf6d507ab54e8c******
    model: zhimi.airpurifier.v6
    name: airpurifier
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;重启home assistant后就可以对小米空气净化器进行控制。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/yongman/i/img/picgo/iuPASEO.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/yongman/i/img/picgo/fhSO9RN.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;这种虽然可以控制，但是空气净化器中的aqi、温度、湿度等信息不能直接的展示，还需要查看fan的属性。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# Sensors
sensor:
  - platform: template
    sensors:
      airpurifier_aqi:
        friendly_name: 卧室AQI
        value_template: &#39;{{ states.fan.airpurifier.attributes.aqi }}&#39;
        unit_of_measurement: &#39;idx&#39;
      airpurifier_temp:
        friendly_name: 卧室温度
        value_template: &#39;{{ states.fan.airpurifier.attributes.temperature }}&#39;
        unit_of_measurement: &#39;C&#39;
      airpurifier_humidity:
        friendly_name: 卧室湿度
        value_template: &#39;{{ states.fan.airpurifier.attributes.humidity }}&#39;
        unit_of_measurement: &#39;%&#39;
      airpurifier_mode:
        friendly_name: 空净模式
        value_template: &#39;{{ states.fan.airpurifier.attributes.mode }}&#39;
      airpurifier_mode:
        friendly_name: 空净转速
        value_template: &#39;{{ states.fan.airpurifier.attributes.motor_speed }}&#39;
        unit_of_measurement: &#39;r/m&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;上面是通过取实体中对应的属性来当作传感器信息，直接显示在主页上。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/yongman/i/img/picgo/deye51x.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/yongman/i/img/picgo/YWkP8rb.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;上面的图中也增加了caiyun的天气信息，最后的几个是小米空气净化器中的数据。&lt;/p&gt;

&lt;p&gt;因为家里只有这一个可以接入的设备，所以主页信息很简陋，也没有进行页面展示的定制。&lt;/p&gt;

&lt;p&gt;后续：
1. 会尝试接入多种智能家居设备
2. &lt;del&gt;通过homebridge对接home assistant来实现和ios的HomeKit交互&lt;/del&gt;
3. 通过HAdashboard更形象的展示和进行控制
4. &lt;del&gt;通过传感器数据实现各种自动化&lt;/del&gt;
5. &lt;del&gt;尝试接入小度音箱(因为我只有一个小度音箱)&lt;/del&gt;
6. &lt;del&gt;接入google assistant&lt;/del&gt;
7. 更多玩法有待探索&amp;hellip;(探索中)&lt;/p&gt;

&lt;p&gt;==========
&lt;strong&gt;更新&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;2019-08-12: homeassistant可以完美的通过ios的家庭应用接入，android平台下的google home也可以通过类似dueros的方式免费接入，可以提供系统级的操控体验。参考文档：&lt;a href=&#34;https://www.home-assistant.io/components/google_assistant/&#34;&gt;homeassistant官方文档&lt;/a&gt;和&lt;a href=&#34;https://www.smarthomebeginner.com/configure-google-assistant-for-home-assistant/&#34;&gt;ha接入google assistant几种方式&lt;/a&gt;。上个截图。&lt;img src=&#34;https://raw.githubusercontent.com/yongman/i/img/picgo/20190812230541.png&#34; alt=&#34;&#34; /&gt;&lt;img src=&#34;https://raw.githubusercontent.com/yongman/i/img/picgo/20190812230612.png&#34; alt=&#34;&#34; /&gt;&lt;/li&gt;
&lt;li&gt;2019-05-28: 很久没有折腾了，已经是稳定状态，上个截图。&lt;img src=&#34;https://raw.githubusercontent.com/yongman/i/img/picgo/20190528090105.png&#34; alt=&#34;&#34; /&gt;&lt;/li&gt;
&lt;li&gt;2019-03-17: HA直接通过小度音箱DLNA和百度的TTS实现了TTS输出，不需要有线或蓝牙连接其他输出设备。不过看到有人说升级了小度的最新固件后即使播放完成，media_player的状态无法自动恢复到idle，&lt;a href=&#34;https://github.com/yongman/homeassistant-components/commit/1bd0bfcb3eb0efa94064cb2ceb712ca2d2aa16e0&#34;&gt;这里&lt;/a&gt;通过在更新状态的时候判断播放位置是否达到最后来强制结束设备播放状态，可以完成更多的自动化语音提醒功能。&lt;/li&gt;
&lt;li&gt;2019-03-17: 改装双控墙壁开关，增加客厅和餐厅灯的控制，并接入小度音箱，在没有测电笔的情况下通过试验，搞清楚了双控两路负载线、火线和其他多个灯负载线的分布，并重新排了墙壁开关的顺序。&lt;/li&gt;
&lt;li&gt;2019-03-06: 支持小度查询房间温湿度，&lt;a href=&#34;https://github.com/yongman/homeassistant-dueros/commit/80a200b299ccb944007cdbb830bb7bfc69f5a5f6&#34;&gt;插件修改&lt;/a&gt; ，dueros的文档非常齐全，各种类型设备控制查询接入简单，小度音箱app中的小度训练师，能够实现对话的自然流畅，以你习惯的方式对话，而不是让人机械的适应机器。&lt;/li&gt;
&lt;li&gt;2019-03-03: HA接入BroadLink rm3 mini，实现对空调和电视机顶盒的红外遥控。&lt;img src=&#34;https://raw.githubusercontent.com/yongman/i/img/picgo/z89K5T6.png&#34; alt=&#34;&#34; /&gt;&lt;/li&gt;
&lt;li&gt;2019-01-01: HA在配置了https的synology camera后疑似存在内存泄露，运行一天，HA占用内存高达1G，修改成http，继续观察。前段时间群晖出现过几次无法响应，高度怀疑是HA内存耗尽的原因。&lt;/li&gt;
&lt;li&gt;2018-12-16: HA接入BroadLink智能插座和BroadLink万能遥控，智能插座比小米的智能插座更开放，不需要想办法获取token，直接ip和mac地址就可以了，只要能接入HA的设备就能互相联动，比如通过HA实现了小度音箱控制BroadLink的智能插座。&lt;/li&gt;
&lt;li&gt;2018-12-11: HA接入小度智能音箱，HA的设备可以和小度音箱联动，能动口就绝不动手，完美控制家里的各种电器，可以考虑每个房间一个小度音箱了。&lt;/li&gt;
&lt;li&gt;2018-11-17: 接入homekit
homekit的接入非常简单，home assistant已经内置home bridge，直接在配置文件中添加&lt;code&gt;homekit:&lt;/code&gt;项，即可自动添加homekit支持，不再需要额外安装homebridge和各种配置。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;参考&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://www.home-assistant.io/&#34;&gt;Home Assistant&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.home-assistant.io/docs/installation/docker/&#34;&gt;Installation on Docker - Home Assistant&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.home-assistant.io/components/sensor.template/&#34;&gt;Template Sensor - Home Assistant&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://bbs.hassbian.com/thread-4625-1-1.html&#34;&gt;ha 接入设备汇总 -『HomeAssistant』智能硬件讨论区&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://mou.science/2018/07/22/homeassistant-2/&#34;&gt;HomeAssistant联动HomeKit | 某不科学的博客&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.home-assistant.io/components/homekit/&#34;&gt;HomeKit - Home Assistant&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://bbs.hassbian.com/thread-5417-1-1.html&#34;&gt;小度音箱接入HomeAssistant 采用自带OAuth访问控制&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/zhkufish/homeassistant-dueros&#34;&gt;GitHub - zhkufish/homeassistant-dueros&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/home-assistant/home-assistant/issues/9352&#34;&gt;Memory leak - camera/synology&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://bbs.hassbian.com/thread-4734-1-1.html&#34;&gt;微改虫子DLNA，让小度上岗&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://bbs.hassbian.com/thread-6260-2-1.html&#34;&gt;小度使用baidu的tts，输入文字后无法自动播放，必须点播放&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
      
    </item>
    
    <item>
      <title>反向二进制迭代(Reverse Binary Iteration)算法</title>
      <link>https://xiking.win/2018/11/07/reverse-binary-iteration/</link>
      <pubDate>Wed, 07 Nov 2018 15:01:01 +0000</pubDate>
      
      <guid>https://xiking.win/2018/11/07/reverse-binary-iteration/</guid>
      
        <description>&lt;p&gt;redis中一个db就是一个大dict，也就是实现的可伸缩hash表。其操作支持遍历scan类操作，按stl容器中场景的逻辑，如果一个迭代器在迭代过程中被修改(插入或删除)元素，迭代器可能失效。&lt;/p&gt;

&lt;p&gt;redis中，由于在scan操作时，整个dict会有大量的增加和删除操作，如果失效迭代器重新遍历可能永远无法完成scan操作，所以其实现的scan遍历操作使用了Reverse Binary Iteration算法，意思是遍历的顺序递增操作是二进制反向的，也就是该数字递增是二进制高位加1，向低位进位。&lt;/p&gt;

&lt;p&gt;因为dict的具体实现是通过索引找到bucket，bucket中可以容纳多个key，并且会进行rehash操作，要实现的目标是：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;在迭代开始时刻起，没有被删除的key都能被遍历。&lt;/li&gt;
&lt;li&gt;在迭代器rehash操作后，没有被删除的key尽可能少的被重复遍历。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;dict的rehash长度是都是2倍增加或半数减少，在遍历过程中cursor的变化是采用反向二进制增加的，在hash长度为8和16时，cursor的增长如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;8: 000 --&amp;gt; 100 --&amp;gt; 010 --&amp;gt; 110 --&amp;gt; 001 --&amp;gt; 101 --&amp;gt; 011 --&amp;gt; 111 --&amp;gt; 000   
16: 0000 --&amp;gt; 1000 --&amp;gt; 0100 --&amp;gt; 1100 --&amp;gt; 0010 --&amp;gt; 1010 --&amp;gt; 0110 --&amp;gt; 1110 --&amp;gt; 0001 --&amp;gt; 1001 --&amp;gt; 0101 --&amp;gt; 1101 --&amp;gt; 0011 --&amp;gt; 1011 --&amp;gt; 0111 --&amp;gt; 1111 --&amp;gt; 0000   
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;rehash增长&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;如果cursor是2，在长度8的hash表中下标是010，在长度16的hash表中下标是0010和1010，这两个是相邻的，这个特性很重要，能够保证在rehash之后，0010之前的bucket都是已经遍历过的，不需要再重复遍历。在增长到16后，下次迭代的cursor为0110，所以不会漏掉也不会重复遍历。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;rehash缩小&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;在16缩小成8的情况下，当在长度16时，在迭代完成1010后，rehash成8大小，cursor变成010。在大小为16时已经完成0000，1000，0100，1100，0010和1010迭代，大小变为8后，为了防止漏掉bucket，下次迭代从010开始，0010和1010已经迭代过，所以会出现重复。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;链接&lt;/strong&gt;
1. &lt;a href=&#34;https://github.com/antirez/redis/pull/579#issuecomment-16871583&#34;&gt;Add SCAN command by pietern · Pull Request #579 · antirez/redis · GitHub&lt;/a&gt;
2. &lt;a href=&#34;https://blog.csdn.net/gqtcgq/article/details/50533336&#34;&gt;Redis源码解析：04字典的遍历dictScan&lt;/a&gt;&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>了解负载均衡</title>
      <link>https://xiking.win/2018/11/06/load-balancer-learn/</link>
      <pubDate>Tue, 06 Nov 2018 19:43:23 +0000</pubDate>
      
      <guid>https://xiking.win/2018/11/06/load-balancer-learn/</guid>
      
        <description>

&lt;h3 id=&#34;种类&#34;&gt;种类&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;硬件负载均衡

&lt;ul&gt;
&lt;li&gt;F5
&lt;img src=&#34;https://raw.githubusercontent.com/yongman/i/img/picgo/PwcW9y7.png&#34; alt=&#34;&#34; /&gt;&lt;/li&gt;
&lt;li&gt;TP-Link
&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;硬件一般都是定制化，价格比较贵，不太符合互联网公司的价值观，要使用普通pc来完成专业硬件的工作。
&lt;img src=&#34;https://raw.githubusercontent.com/yongman/i/img/picgo/BZSD9rv.png&#34; alt=&#34;&#34; /&gt;
Nginx Plus和F5 BIG-IP 11050价格对比。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;软件负载均衡

&lt;ul&gt;
&lt;li&gt;四层交换&lt;/li&gt;
&lt;li&gt;七层交换&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;软件负载均衡&#34;&gt;软件负载均衡&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/yongman/i/img/picgo/YP8n8uw.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;软件负载均衡按工作的层次可以分为四层和七层，四层就是工作在OSI的四层，工作在TCP，通过三层IP和四层端口号来进行负载均衡；七层交换处理支持四层负载均衡外，只要分析应用层的信息，比如HTTP协议的URI或者cookie等信息来进行负载。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/yongman/i/img/picgo/0eBnupo.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h4 id=&#34;常见的四层均衡&#34;&gt;常见的四层均衡&lt;/h4&gt;

&lt;p&gt;四层均衡通过报文中的目标地址和端口，根据配置的负载均衡策略，选择目标服务器。&lt;/p&gt;

&lt;p&gt;以tcp为例，负载均衡在收到第一个赖在客户端的SYN请求时，通过修改报文中的地址修改，直接转发给该服务器。tcp连接的建立，是客户端和服务端直接建立的。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;LVS&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/yongman/i/img/picgo/W6aFSwK.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;LVS架构图能看到LVS由三层组成：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;流量入口&lt;/li&gt;
&lt;li&gt;后端server集群&lt;/li&gt;
&lt;li&gt;共享存储&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;LVS的几种工作模式：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/yongman/i/img/picgo/YLB3I0f.png&#34; alt=&#34;&#34; /&gt;
&lt;strong&gt;LVS-NAT&lt;/strong&gt;：工作机制类似D-NAT，这种模式下所有的流量都需要经过Balancer，容易成为瓶颈。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/yongman/i/img/picgo/f97NV67.png&#34; alt=&#34;&#34; /&gt;
&lt;strong&gt;LVS-DR&lt;/strong&gt;：Direct Routing，直接路由，要求Balancer和后端集群在同一个网络环境，需要修改报文中目标的mac地址，然后重新封装，报文中的源ip和目标ip都没有被修改，后端server直接相应客户端，将数据返回，流量不需要经过Balancer，降低Balancer负载。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/yongman/i/img/picgo/o8KWtPm.png&#34; alt=&#34;&#34; /&gt;
&lt;strong&gt;LVS-TUN&lt;/strong&gt;：类似DR模式，但是后端server和Balancer不在同一个网络，使用IP隧道封装，通过公网发送给后端server，后端server解析报文后直接相应客户端。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/yongman/i/img/picgo/wikQxan.png&#34; alt=&#34;&#34; /&gt;
LVS的高可用是通过主备来实现的，当主挂掉后会进行主备切换，达到高可用效果。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Nginx&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Nginx即可作为四层转发，也可以作为七层转发。四层转发tcp配置示例：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;stream {
  upstream tcp_backend {
    server srv1.example.com:3306;
    server srv2.example.com:3306;
  }
  server {
    listen 3306;
    proxy_pass tcp_backend;
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;Seesaw&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;基于LVS的负载均衡平台。开源版本非google内部使用版本。&lt;/p&gt;

&lt;h4 id=&#34;常见七层均衡&#34;&gt;常见七层均衡&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;HAProxy&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;listen MaxCDN-HAProxy 10.10.10.10:80
mode http
stats enable
stats uri /haproxy?status
balance roundrobin
server Server01 10.10.10.1:80 check
server Server02 10.10.10.2:80 check
server Backup   10.10.10.3:80 backup
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;有多种负载均衡策略，rr、uri、uri parameter等。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Nginx&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;upstream backend1 {
# list of servers
}

upstream backend2 {
# list of servers
}

location /shop {
proxy_pass http://backend1;
}

location /blog {
proxy_pass http://backend2;
}
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;nginx典型通过uri来进行负载均衡。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;各种应用层proxy，eg. MySQL Proxy&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;各种数据库分布式proxy服务，mysql proxy、redis proxy等应用层proxy，通过特定请求数据的进行hash计算，定位后端server，请求对应后端server获取数据后返回给客户端。&lt;/p&gt;

&lt;p&gt;上面的这些负载均衡方式都是有流量单点，如果单点负载达到极限，就需要进行水平扩展，可以使用DNS或者类似的命名服务水平扩展Balancer。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;参考链接&lt;/strong&gt;
1. &lt;a href=&#34;https://www.nginx.com/blog/5-reasons-switch-f5-big-ip-to-nginx-plus/&#34;&gt;5 Reasons to Switch from F5 BIG-IP to NGINX Plus | NGINX&lt;/a&gt;
2. &lt;a href=&#34;https://www.nginx.com/blog/nginx-plus-vs-f5-big-ip-a-price-performance-comparison/&#34;&gt;NGINX Plus vs. F5 BIG‑IP: A Price‑Performance Comparison&lt;/a&gt;
3. &lt;a href=&#34;https://www.digitalocean.com/community/tutorials/what-is-load-balancing&#34;&gt;What is Load Balancing? | DigitalOcean&lt;/a&gt;
4. &lt;a href=&#34;https://geekflare.com/open-source-load-balancer/&#34;&gt;10 Open Source Load Balancer for HA and Improved Performance&lt;/a&gt;
5. &lt;a href=&#34;http://www.linuxvirtualserver.org/architecture.html&#34;&gt;General Architecture of LVS Server Clusters&lt;/a&gt;
6. &lt;a href=&#34;https://blog.csdn.net/qq_37595946/article/details/77919018&#34;&gt;负载均衡集群 LVS 详解（Loadbalancer &amp;amp; LVS）&lt;/a&gt;
7. &lt;a href=&#34;https://www.nginx.com/resources/glossary/layer-4-load-balancing/&#34;&gt;What Is Layer 4 Load Balancing? | NGINX Load Balancer&lt;/a&gt;&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>黑群晖Synology DS918&#43;打造个人网络媒体中心</title>
      <link>https://xiking.win/2018/11/05/synology-nas-diy-network/</link>
      <pubDate>Mon, 05 Nov 2018 23:53:38 +0000</pubDate>
      
      <guid>https://xiking.win/2018/11/05/synology-nas-diy-network/</guid>
      
        <description>

&lt;p&gt;还记得几年前，一个机缘巧合，碰到有同学利用台式机安装了一个黑群晖，当时自己也将废弃在角落08年的联想笔记本成功跑了黑群晖，然后继续被仍在房间的角落。&lt;/p&gt;

&lt;p&gt;当时就被群晖的软件生态吸引了，各种app涵盖了文件管理、照片、视频、各种数据同步等场景。&lt;/p&gt;

&lt;p&gt;趁着房子装修，现在局域网起码也要千兆网络，目前在使用的小米路由器R2D虽然也是千兆，但是网络延迟抖动比较严重，是时候升级了。&lt;/p&gt;

&lt;h3 id=&#34;diy&#34;&gt;DIY&lt;/h3&gt;

&lt;p&gt;和前同事咨询了一番，也在tg交流群和youtube上了解了一番，决定自己DIY硬件，具体的使用的硬件：
- 华擎J4105主板
&lt;img src=&#34;https://raw.githubusercontent.com/yongman/i/img/picgo/lviGPA8.jpg&#34; alt=&#34;&#34; /&gt;
- 迎广MS04机箱 自带电源
&lt;img src=&#34;https://raw.githubusercontent.com/yongman/i/img/picgo/kTfBhtX.png&#34; alt=&#34;&#34; /&gt;
&lt;img src=&#34;https://raw.githubusercontent.com/yongman/i/img/picgo/lx45AQQ.jpg&#34; alt=&#34;&#34; /&gt;
- 三星DDR4 8G内存
&lt;img src=&#34;https://raw.githubusercontent.com/yongman/i/img/picgo/SmAX52G.png&#34; alt=&#34;&#34; /&gt;
- PCIex1双网口千兆网卡
&lt;img src=&#34;https://raw.githubusercontent.com/yongman/i/img/picgo/FewkC7q.jpg&#34; alt=&#34;&#34; /&gt;
- 西数红盘4T
预算有限，先上一块盘，后续再上
&lt;img src=&#34;https://raw.githubusercontent.com/yongman/i/img/picgo/8GWerbS.jpg&#34; alt=&#34;&#34; /&gt;
- 闪迪酷豆8G U盘引导（真的很小，插到主板上，还真不易被发现）&lt;/p&gt;

&lt;p&gt;硬件就是这样。NAS系统选择还是群晖，安装的是最新版DSM6.2.1。
&lt;img src=&#34;https://raw.githubusercontent.com/yongman/i/img/picgo/Dfe0xIV.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;有Virtual Machine Manager和docker支持，可以虚拟机运行其他系统，考虑到后续升级16G内存的可能，先上单条8G。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/yongman/i/img/picgo/oAc5z2W.png&#34; alt=&#34;&#34; /&gt;
网络拓扑图&lt;/p&gt;

&lt;p&gt;如果让NAS只用作存储有点浪费资源，内存和CPU性能过剩，所以干脆来跑软路由吧。&lt;/p&gt;

&lt;p&gt;在VMM中运行的LEDE软路由，破解移动光猫，设置光猫为桥接模式，光猫负责光纤入户桥接，拨号交给LEDE，拨号成功。
&lt;img src=&#34;https://raw.githubusercontent.com/yongman/i/img/picgo/cYUuDj7.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;移动宽带支持多拨，100M宽带在4拨的情况下，测试能达到300M的带宽。
&lt;img src=&#34;https://raw.githubusercontent.com/yongman/i/img/picgo/4astvzq.png&#34; alt=&#34;&#34; /&gt;
&lt;img src=&#34;https://raw.githubusercontent.com/yongman/i/img/picgo/IDNDFfl.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;LEDE自带软件中心，可以直接配置ss相关客户端，实现智能科学上网，不需要再自己折腾脚本。&lt;/p&gt;

&lt;h3 id=&#34;遇到的问题&#34;&gt;遇到的问题&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;无法启用第三个网卡&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;由于DS918+只有两个千兆网卡，所以黑群晖的DS918+系统中对于网卡数据有一定限制，具体表现是ifconfig能看到所有的物理网卡设备eth0、eth1、eth2，启动后只有两个网卡是enable状态，eth2没有启用。&lt;/p&gt;

&lt;p&gt;通过查看/etc/rc.network网络初始化脚本，发现三个网卡其实是都识别的，新插入的网卡会在/etc/sysconfig/network-scripts下生成默认配置文件，每次开机会发现eth2相关的配置总会莫名其妙的被删除，导致无法对eth2网卡初始化。
&lt;img src=&#34;https://raw.githubusercontent.com/yongman/i/img/picgo/DQgCkGL.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;通过&lt;code&gt;dmesg&lt;/code&gt;查看，发现奇怪日志：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;2018-11-05T00:35:41+08:00 DiskStation synochecknetworkcfg: synochecknetworkcfg.c:50 unlink [/etc/sysconfig/network-scripts/ifcfg-eth2], max LAN id is [1]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ifcfg-eth2被unlink，最大id是1??? synochecknetworkcfg这个bin文件是c编译的，没有源码也没办法看内部的逻辑，索性想办法把这个check过程去掉。&lt;/p&gt;

&lt;p&gt;找到在文件&lt;code&gt;/etc/init/network.conf&lt;/code&gt;中会调用该命令，注释掉。
&lt;img src=&#34;https://raw.githubusercontent.com/yongman/i/img/picgo/QyT1xiI.png&#34; alt=&#34;&#34; /&gt;
重启验证，成功识别。
&lt;img src=&#34;https://raw.githubusercontent.com/yongman/i/img/picgo/nvfBGE8.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;lede多拨稳定性&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;初次设置多拨成功概率大，重启路由器有一定概率存在部分虚拟wan口拨号失败，未解决。
&lt;img src=&#34;https://raw.githubusercontent.com/yongman/i/img/picgo/6p9bDWo.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;i915显卡驱动加载失败&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;dmesg -T看到有kernel panic输出：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[Wed Dec 12 12:44:30 2018] Call Trace:
[Wed Dec 12 12:44:30 2018]  [&amp;lt;ffffffff8140c409&amp;gt;] ? i2c_transfer+0x79/0x90
[Wed Dec 12 12:44:30 2018]  [&amp;lt;ffffffffa0515da2&amp;gt;] drm_do_probe_ddc_edid+0xc2/0x130 [drm]
[Wed Dec 12 12:44:30 2018]  [&amp;lt;ffffffffa0517360&amp;gt;] drm_get_edid+0x300/0x390 [drm]
[Wed Dec 12 12:44:30 2018]  [&amp;lt;ffffffffa06768bf&amp;gt;] intel_dp_init_connector+0xa7f/0xf00 [i915]
[Wed Dec 12 12:44:30 2018]  [&amp;lt;ffffffffa066b533&amp;gt;] intel_ddi_init+0x383/0x4f0 [i915]
[Wed Dec 12 12:44:30 2018]  [&amp;lt;ffffffffa064952a&amp;gt;] intel_modeset_init+0x15da/0x1a70 [i915]
[Wed Dec 12 12:44:30 2018]  [&amp;lt;ffffffffa0683507&amp;gt;] ? intel_setup_gmbus+0x2e7/0x310 [i915]
[Wed Dec 12 12:44:30 2018]  [&amp;lt;ffffffffa05beccf&amp;gt;] i915_driver_load+0xa0f/0xe00 [i915]
[Wed Dec 12 12:44:30 2018]  [&amp;lt;ffffffffa05c9797&amp;gt;] i915_pci_probe+0x27/0x40 [i915]
[Wed Dec 12 12:44:30 2018]  [&amp;lt;ffffffff812fc85c&amp;gt;] pci_device_probe+0x8c/0x100
[Wed Dec 12 12:44:30 2018]  [&amp;lt;ffffffff813842d1&amp;gt;] driver_probe_device+0x1f1/0x310
[Wed Dec 12 12:44:30 2018]  [&amp;lt;ffffffff81384472&amp;gt;] __driver_attach+0x82/0x90
[Wed Dec 12 12:44:30 2018]  [&amp;lt;ffffffff813843f0&amp;gt;] ? driver_probe_device+0x310/0x310
[Wed Dec 12 12:44:30 2018]  [&amp;lt;ffffffff81382361&amp;gt;] bus_for_each_dev+0x61/0xa0
[Wed Dec 12 12:44:30 2018]  [&amp;lt;ffffffff81383d69&amp;gt;] driver_attach+0x19/0x20
[Wed Dec 12 12:44:30 2018]  [&amp;lt;ffffffff81383993&amp;gt;] bus_add_driver+0x1b3/0x230
[Wed Dec 12 12:44:30 2018]  [&amp;lt;ffffffffa06fa000&amp;gt;] ? 0xffffffffa06fa000
[Wed Dec 12 12:44:30 2018]  [&amp;lt;ffffffff81384c7b&amp;gt;] driver_register+0x5b/0xe0
[Wed Dec 12 12:44:30 2018]  [&amp;lt;ffffffff812fb337&amp;gt;] __pci_register_driver+0x47/0x50
[Wed Dec 12 12:44:30 2018]  [&amp;lt;ffffffffa06fa03e&amp;gt;] i915_init+0x3e/0x45 [i915]
[Wed Dec 12 12:44:30 2018]  [&amp;lt;ffffffff810003b6&amp;gt;] do_one_initcall+0x86/0x1b0
[Wed Dec 12 12:44:30 2018]  [&amp;lt;ffffffff810dfdd8&amp;gt;] do_init_module+0x56/0x1be
[Wed Dec 12 12:44:30 2018]  [&amp;lt;ffffffff810b61ad&amp;gt;] load_module+0x1ded/0x2070
[Wed Dec 12 12:44:30 2018]  [&amp;lt;ffffffff810b3510&amp;gt;] ? __symbol_put+0x50/0x50
[Wed Dec 12 12:44:30 2018]  [&amp;lt;ffffffff810b65b9&amp;gt;] SYSC_finit_module+0x79/0x80
[Wed Dec 12 12:44:30 2018]  [&amp;lt;ffffffff810b65d9&amp;gt;] SyS_finit_module+0x9/0x10
[Wed Dec 12 12:44:30 2018]  [&amp;lt;ffffffff81567444&amp;gt;] entry_SYSCALL_64_fastpath+0x18/0x8c
[Wed Dec 12 12:44:30 2018] Code:  Bad RIP value.
[Wed Dec 12 12:44:30 2018] RIP  [&amp;lt;          (null)&amp;gt;]           (null)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;表现就是视频解码无法启用硬件加速，找到的解决方案是：&lt;a href=&#34;https://bbs.archlinux.org/viewtopic.php?id=198852&#34;&gt;https://bbs.archlinux.org/viewtopic.php?id=198852&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;在内核启动时增加参数i915.enable_execlists=0，验证有效，重启内核无panic输出。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[Sun Dec 30 16:20:51 2018] [drm] Finished loading DMC firmware i915/glk_dmc_ver1_04.bin (v1.4)
[Sun Dec 30 16:20:52 2018] [drm] failed to retrieve link info, disabling eDP
[Sun Dec 30 16:20:52 2018] [drm] Initialized i915 1.6.0 20180514 for 0000:00:02.0 on minor 0
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;使用感受&#34;&gt;使用感受&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;2018-11-05&lt;/code&gt; 系统已经稳定运行一周，网速有改善明显，一个NAS+多个AP完美实现上网，性能堪比专业路由。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;2019-01-20&lt;/code&gt; 使用一段时间LEDE软路由，在多拨的情况下存在bug，在大流量下载的时候会出现wan口拨号失败掉线的情况，只能重启lede恢复，所以增加了ikuai做多拨主路由，lede做旁路路由，避免出现拨号失败导致的断网问题，跑一段时间看看ikuai稳定性，毕竟ikuai是商用的系统，稳定性应该比lede好得多。双软路网络拓扑图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/yongman/i/img/picgo/n0EKgbH.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;2019-04-10&lt;/code&gt; 使用过程中出现了几次ikuai拨号在大流量的情况下断网的情况，表现是群晖物理网卡正常，但是ikuai的虚拟wan口网络不通，断网情况下ikuai依然会重试拨号，但是出现超时。和之前lede拨号表现一致，只能重启虚拟机恢复。由于lan口和wan口对应的物理网卡是自己插入的pcie双网口网卡，怀疑是pcie网卡虚拟驱动等导致的虚拟网卡停止工作。将ikuai的wan口重新桥接群晖的第三个物理网卡，使用板载网卡进行wan口拨号，后续没再出现断网的情况。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;2019-05-11&lt;/code&gt;老问题再次复现，添加了下载任务后，出现了ikuai无法拨号的情况，这就说明不是物理网卡驱动的问题。决定升级dsm 6.2.2，最新版本更新了virtual machine manager，都说稳定优先，没有大问题黑群升级大概率会出点问题的。升级后出现的问题：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;依旧无法正常关机。&lt;/li&gt;
&lt;li&gt;开机必须插着vga显示器，显示器可以是关闭状态，不插显示器无法启动。&lt;/li&gt;
&lt;li&gt;i915驱动panic再次出现，添加启动参数方式失效。&lt;/li&gt;
&lt;li&gt;J4105板载网卡无法使用。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;得出了结论就是：等这些问题有了解决方案后，以后无特殊情况以后还是不升级了吧，稳定优先。逃&amp;hellip;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;2019-05-25&lt;/code&gt; 先说一下半年以来遇到的软路由断网情况没有复现，改动就是去掉了多拨，采用的普通的单拨形式。&lt;/p&gt;

&lt;p&gt;上一周没忍住更新了dsm6.2.2，过了一周终于决定回退6.2.1，回退方式就是格式化&lt;code&gt;/dev/md0&lt;/code&gt;分区，然后重启安装。具体步骤：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;1. 创建ubuntu启动盘
2. 将群晖的loader拔出，插入刚做好的启动盘
3. 启动ubuntu live
4. sudo -i
5. mdadm -Asf &amp;amp;&amp;amp; vgchange -ay
6. mdadm -AU byteorder /dev/md0 /dev/sda1 /dev/sdb1(具体看自己的raid方式)
7. mkfs.ext4 /dev/md0
8. 拔下u盘，插入重新做好的群晖loader
9. 开始重新安装，这样安装后设置和安装的软件丢失，但是数据不会丢失。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;安装后发现以前使用的sn和mac无效了，估计被封了，主要是使用ds video的硬件转码加速功能，所以还是需要个合法的sn来开启硬件转码功能。这里使用的是复制ddsm中的序列号到grub中，修改grub重启，硬件转码功能正常。以后坚决不做小白鼠！！！&lt;/p&gt;

&lt;p&gt;&lt;code&gt;2019-10-08&lt;/code&gt; 关于群晖虚拟机跑软路由的问题基本上定位到只VMM的驱动问题，最后还是将网络方案和NAS分开了，软路由采用了3205U工控机+8G内存+64G SSD，软件采用PVE+ikuai+lede双软路由组合，支持网卡直通，再也不怕大流量下载了。
&lt;img src=&#34;https://raw.githubusercontent.com/yongman/i/img/picgo/20191016201159.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>Redis冷热数据分离混合存储实现 - IO任务异步处理</title>
      <link>https://xiking.win/2018/10/24/redis-bot-cold-data-seperation-new-bio/</link>
      <pubDate>Wed, 24 Oct 2018 16:33:03 +0000</pubDate>
      
      <guid>https://xiking.win/2018/10/24/redis-bot-cold-data-seperation-new-bio/</guid>
      
        <description>&lt;p&gt;在demo实现中，第一版的异步化处理中，采用的是类似redis中对list的BLOCK类型操作，但是与list BLOCK操作不同的是，list的BLOCK操作是全部在主线程完成，不会涉及多线程的资源竞争，实现起来也比较容易，访问发生磁盘IO时，需要BIO线程处理，根据BIO线程的操作结果来修改内存的db。&lt;/p&gt;

&lt;p&gt;上一版的实现没有充分考虑到多线程对临界资源保护，key和client的block状态维护比较复杂，导致频繁core，内存写飞，所以对实现进行了重新梳理和重构。&lt;/p&gt;

&lt;p&gt;重构后的思路：&lt;/p&gt;

&lt;p&gt;所有的内存数据操作严格交给主线程，BIO线程只是单独的进行磁盘读写和内存对象的序列化和反序列化，绝不涉及修改主线程中的db或其他的状态。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/yongman/i/img/picgo/GFI1bu3.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;主线程和BIO线程通过队列进行通信，主线程创建异步IO任务，通知IO线程，IO线程会将任务执行结果按顺序加入结果队列，主线程会处理结果返回队列，真正完成IO任务。&lt;/p&gt;

&lt;p&gt;所以主线程和异步IO线程只需要对通信队列进行加锁就可以防止产生竞争。&lt;/p&gt;

&lt;p&gt;如果压力过大，或者磁盘IO抖动，会导致任务队列堆积，占用大量内存，加剧server对数据的强制淘汰，进而引发雪崩，所以需要对任务队列进行控制。&lt;/p&gt;

&lt;p&gt;当任务队列大于特定大小后，主线程会等待IO线程处理任务，这时主线程会进行等待，阻塞客户端，在保护自身的同时，进行了客户端限流。&lt;/p&gt;

&lt;p&gt;db中需要两个dict用来保存load和save任务中的key所阻塞的客户端列表，客户端需要保存被哪些key阻塞，主线程在收到异步线程的执行结果后，将key从客户端中阻塞key中移除，检查客户端中是否还有被阻塞的key，如果没有主线程会再次对客户端进行处理。&lt;/p&gt;

&lt;p&gt;对于RocksDB，删除操作就是写入操作，所以将删除也当作写入来对待，异步任务交给BIO SAVE线程处理。&lt;/p&gt;

&lt;p&gt;这样对于阻塞状态管理和多线程竞争的处理，降低逻辑复杂度。&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>Redis冷热数据分离混合存储实现 - 读写任务异步化</title>
      <link>https://xiking.win/2018/09/30/redis-hot-cold-data-seperation-bio/</link>
      <pubDate>Sun, 30 Sep 2018 17:59:14 +0000</pubDate>
      
      <guid>https://xiking.win/2018/09/30/redis-hot-cold-data-seperation-bio/</guid>
      
        <description>&lt;p&gt;redis的单线程处理模型，对于客户端请求都会变成串行处理，所以也不存在数据竞争的问题。对于冷数据需要的经过磁盘IO，这对于redis的高并发模型影响非常大。如果采用同步处理方式，磁盘IO由主线程处理，在进行磁盘IO的时候，后续的所有客户端请求会全部pending，无法进行处理，带来的问题就是单个磁盘IO影响整个服务的吞吐。&lt;/p&gt;

&lt;p&gt;redis本身也有bio后台线程任务，主要是处理aof落盘、lazyfree逻辑和关闭大文件fd。要实现bio线程任务不会和主线程产生竞争，才能避免由于低频率的后台任务导致高频率的主线程数据访问竞争引入的开销。&lt;/p&gt;

&lt;p&gt;对于aof，主线程写入内存buffer，按策略将buffer数据写入文件fd，提交异步任务对fd刷盘。&lt;/p&gt;

&lt;p&gt;对于大的内存对象，redis也采用了lazyfree机制，在删除对象的时候，首先将对象从dict中unlink，客户端就无法访问这块内存了，unlink的操作是在主线程中完成的，将unlink的内存对象交给bio线程执行释放操作，不会存在资源竞争。&lt;/p&gt;

&lt;p&gt;冷数据从磁盘load和dump操作也采用bio的操作方式。为了记录客户端和在执行bio操作的key的对应关系，需要引入几个变量。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;db-&amp;gt;swapping_keys&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;dict类型，key是正在load或dump的的key，value是一个list，记录想要访问这个key的客户端连接，用于key就绪后处理响应客户端。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;client-&amp;gt;bpop.swapping_keys&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;dict类型，仅仅用来记录该client阻塞的key， value是NULL，当有一个客户端同时阻塞在多个key上，dict记录的所有key全部就绪后才会将客户端就绪。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;db-&amp;gt;ready_swap_keys&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;dict类型，用于记录db-&amp;gt;swapping_keys中的在bio线程中处理完成就绪的key，处理完成后将key加入dict，加快就绪key查询速度。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;server.ready_swap_key&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;list类型，bio线程处理完成的任务在增加db-&amp;gt;ready_swap_keys同时，会将db和key封装成readyList，加入list列表，后续在beforeSleep中对就绪key进行处理。&lt;/p&gt;

&lt;p&gt;为了避免竞争，要能够保证所有对dict的更新操作需要在主线程完成，bio线程只做耗时的读写磁盘。&lt;/p&gt;

&lt;p&gt;一个key在swap过程中，所有的客户端访问到这个key都会block，所以相当于对这个key进行了加锁，保证key不会被访问，load的过程中，主线程会将这个key和空的对象增加到主dict，将dict中的value的地址交给bio线程，bio线程更value的内容。dump的过程类似，主线程将key和value对象引用加一，防止内存释放，然后交给bio线程对内存数据落盘，然后将引用减一。&lt;/p&gt;

&lt;p&gt;访问冷数据过程：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;查看key是冷热数据，热数据直接返回内存数据；&lt;/li&gt;
&lt;li&gt;如果key正在swap操作，直接block客户端；&lt;/li&gt;
&lt;li&gt;key没有在swap的后台任务列表，并且是冷数据，从call命理返回，将key加入bio任务BLOCKED_LOAD队列；&lt;/li&gt;
&lt;li&gt;后台任务处理完成，加入ready_keys，交给主线程处理；&lt;/li&gt;
&lt;li&gt;主线程判断就绪key所阻塞的客户端，并且对于的客户端没有其他block的key，需要将客户端unblock，重新进入call，进行命令处理。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;上面过程中，bio线程和主线程对于ready_keys等几个变量的操作需要防止竞争访问需要加锁，但这部分开销不大，尽量保证bio线程中的临界区小，不会对主线程产生影响。&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>Redis冷热数据分离混合存储实现 - index存储</title>
      <link>https://xiking.win/2018/09/20/redis-hot-cold-data-seperation-index/</link>
      <pubDate>Thu, 20 Sep 2018 18:04:45 +0000</pubDate>
      
      <guid>https://xiking.win/2018/09/20/redis-hot-cold-data-seperation-index/</guid>
      
        <description>

&lt;p&gt;为了实现冷热数据分离，热数据在内存，冷数据会置换到持久化存储，但是为了保证内存检索高效，会将所有key和频率统计信息保存在内存。冷数据的选择采用的选择算法和redis本身的数据淘汰选择算法一致，使用采样最优的方式。&lt;/p&gt;

&lt;p&gt;为了将冷数据和热数据区分，方便冷数据采样，所以在每个db里增加了一个名为index的dict，用于保存key的index和频率统计信息。
&lt;img src=&#34;https://raw.githubusercontent.com/yongman/i/img/picgo/DhBmufM.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;换出策略&#34;&gt;换出策略&lt;/h3&gt;

&lt;p&gt;什么时候会触发冷数据的持久化来释放内存？需要根据应用场景定义不同的置换策略。&lt;/p&gt;

&lt;p&gt;置换策略可以采用多种可配置方式：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;maxhotmemory&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;增加一项配置项，在内存数据达到阈值，触发数据强制置换，策略类似maxmemory删除策略，为了不影响原有数据淘汰逻辑，maxhotmemory要小于maxmemory，当达阈值后从db-&amp;gt;dict采样key，根据访问的频率，选择最适合置换的key，然后持久化，逻辑如下：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;将对于的redis object decode成rawstring，调用RocksDB PUT接口，将数据存储到磁盘；&lt;/li&gt;
&lt;li&gt;将key和初始的频率访问信息添加到db-&amp;gt;index;&lt;/li&gt;
&lt;li&gt;将key从db-&amp;gt;dict清理掉，释放内存。&lt;/li&gt;
&lt;/ol&gt;

&lt;ul&gt;
&lt;li&gt;冷热数据百分比&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;根据冷热数据比例，在内存使用率到一定比例的前提下，由定时任务周期性的选择合适的key进行持久化，定时任务只是生成置换任务，交给IO线程异步处理，IO操作不阻塞主线程。持久化逻辑同上。&lt;/p&gt;

&lt;h3 id=&#34;冷数据加载&#34;&gt;冷数据加载&lt;/h3&gt;

&lt;p&gt;冷数据加载采用lazy的处理方式，在读写key之前，会先去db-&amp;gt;index中进行查询，如果在index中，则阻塞客户端，将key加入阻塞任务中，异步IO线程进行数据加载。加载逻辑：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;读取RockDB，生成redis object对象；&lt;/li&gt;
&lt;li&gt;从db-&amp;gt;index中删除key；&lt;/li&gt;
&lt;li&gt;将新生成的value对象加入db-&amp;gt;dict。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;其中存在的问题就是当采用maxhotmemory策略，当usedmemory大于maxhotmemory，在进行写入操作会产生频繁的swap操作，所以还需要增加定时任务策略，尽量保证使usedmemory小于maxhotmemory；
当内存中全部存放的是key的index时，持续写入会使usedmemory达到maxmemory，触发数据淘汰逻辑，当配置了allkeys淘汰逻辑，server会按概率从dict或index中获取要淘汰的key。&lt;/p&gt;

&lt;h3 id=&#34;rocksdb-api&#34;&gt;RocksDB API&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;/*
 * decode robj from key and value to rawstring
 * call rocksdb_put to save key-value pair
 */
int rocksAdd(rocksdb_t *rdb, rocksdb_writeoptions_t *options, robj *key, robj *val) {
    robj *dec;
    char *err = NULL;
    sds key_ptr, val_ptr;
    dec = getDecodedObject(val);


    key_ptr = key-&amp;gt;ptr;
    val_ptr = dec-&amp;gt;ptr;
    rocksdb_put(rdb, options, key_ptr, sdslen(key_ptr), val_ptr, sdslen(val_ptr), &amp;amp;err);
    decrRefCount(dec);

    if (err != NULL) {
        serverLog(LL_WARNING, &amp;quot;rocksAdd failed, %s&amp;quot;, err);
        return C_ERR;
    }

    return C_OK;
}

/*
 * decode robj from key to rawstring
 * call rocksdb_get to get value from rocksdb of the key
 * encode the value to robj
 * */
robj *rocksGet(rocksdb_t *rdb, rocksdb_readoptions_t *options, robj *key) {
    robj *val;
    char *err = NULL;
    size_t vallen;
    sds key_ptr;
    char *val_raw;

    key_ptr = key-&amp;gt;ptr;
    val_raw = rocksdb_get(rdb, options, key_ptr, sdslen(key_ptr), &amp;amp;vallen, &amp;amp;err);
    if (err != NULL) {
        serverLog(LL_WARNING, &amp;quot;rocksGet failed, %s&amp;quot;, err);
        return NULL;
    }
    if (val_raw == NULL) {
        // not found
        return NULL;
    } else {
        val = createRawStringObject(val_raw, vallen);
        // try encoding obj
        val = tryObjectEncoding(val);

        free(val_raw);
    }

    return val;
}

int rocksDel(rocksdb_t *rdb, rocksdb_writeoptions_t *options, robj *key) {
    char *err = NULL;
    sds key_ptr;

    key_ptr = key-&amp;gt;ptr;

    rocksdb_delete(rdb, options, key_ptr, sdslen(key_ptr), &amp;amp;err);
    if (err != NULL) {
        serverLog(LL_WARNING, &amp;quot;rocksDel failed, %s&amp;quot;, err);
        return C_ERR;
    }

    return C_OK;

}

void rocksOpen() {
    if (server.rdb) return;


    server.r_options = rocksdb_options_create();
    server.r_read_options = rocksdb_readoptions_create();
    server.r_write_options = rocksdb_writeoptions_create();
    // default config
    .....
    
    /* rocksdb block based options */
    rocksdb_block_based_table_options_t *b_options = rocksdb_block_based_options_create();
    rocksdb_block_based_options_set_cache_index_and_filter_blocks(b_options, 0);

    rocksdb_options_set_block_based_table_factory(server.r_options, b_options);

    char *err = NULL;
    server.rdb = rocksdb_open(server.r_options, &amp;quot;/tmp/rocksdb_redis&amp;quot;, &amp;amp;err);
    if (err != NULL) {
        serverLog(LL_WARNING, &amp;quot;open rocksdb failed, %s&amp;quot;, err);
    }
}

void rocksClose() {
    if (!server.r_options) {
        rocksdb_options_destroy(server.r_options);
    }
    if (!server.r_read_options) {
        rocksdb_readoptions_destroy(server.r_read_options);
    }
    if (!server.r_write_options) {
        rocksdb_writeoptions_destroy(server.r_write_options);
    }
    if (!server.rdb) {
        rocksdb_close(server.rdb);
    }
}
&lt;/code&gt;&lt;/pre&gt;
</description>
      
    </item>
    
    <item>
      <title>冷热数据分离调研和概要方案</title>
      <link>https://xiking.win/2018/09/13/data-hot-cold-auto-management/</link>
      <pubDate>Thu, 13 Sep 2018 11:36:47 +0000</pubDate>
      
      <guid>https://xiking.win/2018/09/13/data-hot-cold-auto-management/</guid>
      
        <description>

&lt;h2 id=&#34;一-背景&#34;&gt;一. 背景&lt;/h2&gt;

&lt;p&gt;随着硬件的发展，持久化存储的速度得以提升，但是硬件成本相比内存单位的成本会有大幅度下降，并且全内存缓存存储理想应用场景是随机高速访问，而实际的应用场景中，数据访问频率不一致，数据存在冷热区分，热数据放在内存能加速访问，冷数据理应通过一定置换算法，在合适的情况下置换到持久化存储，节省成本。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/yongman/i/img/picgo/CFkzyQJ.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;二-数据冷热分离目标&#34;&gt;二. 数据冷热分离目标&lt;/h2&gt;

&lt;p&gt;对数据按访问频率进行统计，有效标记冷热数据，后续访问过程中，根据数据冷热变化，将数据在内存和持久化存储之间移动。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;大幅提升实例容量&lt;/li&gt;
&lt;li&gt;降低单位容量成本&lt;/li&gt;
&lt;li&gt;大部分应用场景可以保证性能&lt;/li&gt;
&lt;li&gt;客户端连接在冷热数据交换时不会互相影响&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;三-现有系统调研&#34;&gt;三. 现有系统调研&lt;/h2&gt;

&lt;h3 id=&#34;3-1-ssdb&#34;&gt;3.1 SSDB&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://camo.githubusercontent.com/6f3243b32deae6f762859f3ee91eeeb36f291518/687474703a2f2f737364622e696f2f737364622e706e67&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;无冷热数据分离&lt;/li&gt;
&lt;li&gt;底层采用LevelDB或RocksDB引擎&lt;/li&gt;
&lt;li&gt;实现了多种数据结构&lt;/li&gt;
&lt;li&gt;C++实现&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;3-2-ledisdb&#34;&gt;3.2 LedisDB&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;无冷热数据分离&lt;/li&gt;
&lt;li&gt;底层采用LevelDB或RocksDB等&lt;/li&gt;
&lt;li&gt;实现了多种数据结构&lt;/li&gt;
&lt;li&gt;Golang实现&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;3-3-pika&#34;&gt;3.3 Pika&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://camo.githubusercontent.com/01d7f1a580446132eacaca2889c8184279254f89/68747470733a2f2f692e696d6775722e636f6d2f334564646374422e706e67&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;无冷热数据分离&lt;/li&gt;
&lt;li&gt;底层采用RocksDB引擎&lt;/li&gt;
&lt;li&gt;使用第三方模块实现多种数据结构&lt;/li&gt;
&lt;li&gt;C++实现&lt;/li&gt;
&lt;li&gt;支持多主模式，无数据一致性保证&lt;/li&gt;
&lt;li&gt;360内部大规模使用&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;3-4-tidis&#34;&gt;3.4 Tidis&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://github.com/yongman/tidis/raw/master/docs/tidis-arch.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;无冷热数据分离&lt;/li&gt;
&lt;li&gt;底层存储tikv，存储引擎为RocksDB&lt;/li&gt;
&lt;li&gt;支持多种数据结构&lt;/li&gt;
&lt;li&gt;golang实现&lt;/li&gt;
&lt;li&gt;计算存储分离&lt;/li&gt;
&lt;li&gt;水平自动扩展、高可用&lt;/li&gt;
&lt;li&gt;数据更新乐观锁，热点数据更新冲突需要重试&lt;/li&gt;
&lt;li&gt;分布式事务，latancy较高&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;3-5-swapdb&#34;&gt;3.5 swapdb&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://github.com/JingchengLi/swapdb/raw/master/docs/fundamental.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;有冷热数据分离&lt;/li&gt;
&lt;li&gt;定制redis和ssdb服务组合&lt;/li&gt;
&lt;li&gt;ssdb和redis通过socket通信，每次数据调度需要两次网络交互&lt;/li&gt;
&lt;li&gt;冷热数据LFU算法统计&lt;/li&gt;
&lt;li&gt;无规模化应用&lt;/li&gt;
&lt;li&gt;无人维护状态&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;3-6-阿里redis混合存储&#34;&gt;3.6 阿里redis混合存储&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/yongman/i/img/picgo/6h7yH3c.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;后端采用定制的rocksdb存储和用户态文件系统，压榨性能&lt;/li&gt;
&lt;li&gt;超过内存阈值，尝试进行持久化key&lt;/li&gt;
&lt;li&gt;异步线程IO处理&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;3-7-redis-enterprise&#34;&gt;3.7 redis enterprise&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://redislabs.com/wp-content/uploads/2016/07/redis_flash_px.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;两年前提供，官方文档描述的实现和阿里redis混合存储总体一致。&lt;/p&gt;

&lt;h3 id=&#34;3-8-anna&#34;&gt;3.8 Anna&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/yongman/i/img/picgo/jXFN7Tn.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;伯克利出品&lt;/li&gt;
&lt;li&gt;冷热数据分离&lt;/li&gt;
&lt;li&gt;不同层次节点相互独立&lt;/li&gt;
&lt;li&gt;通过监控的策略组件对数据进行冷热迁移&lt;/li&gt;
&lt;li&gt;只支持kv&lt;/li&gt;
&lt;li&gt;基于aws部署&lt;/li&gt;
&lt;li&gt;支持热点key流量打散，CRDT数据结构冲突解决&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;3-8-小结&#34;&gt;3.8 小结&lt;/h3&gt;

&lt;p&gt;持久化存储容量一般是内存容量的10倍以上，将部分冷数据从内存置换到持久化存储，可以提升单实例所能承载数据量的上限。在存储引擎的计划选择上选择经过大量工程验证的RocksDB，其特性如下：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;暴露参数多，tuning空间大&lt;/li&gt;
&lt;li&gt;LSM Tree，顺序写，对写操作优化&lt;/li&gt;
&lt;li&gt;对SSD友好，避免频繁GC&lt;/li&gt;
&lt;li&gt;大量工程验证，稳定可靠&lt;/li&gt;
&lt;li&gt;写性能很好，并且稳定&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;四-冷热分离实现概要&#34;&gt;四. 冷热分离实现概要&lt;/h2&gt;

&lt;p&gt;虽然都是快速设备+慢速设备，冷热数据分离与cache场景不同在于：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;冷热数据分离：快设备为主，慢速设备是对快速的设备的扩展。读写都是直接访问快速设备，后台任务将数据部分置换到慢速设备，热数据读取写入速度快。&lt;/li&gt;
&lt;li&gt;cache场景：慢速设备为主，快速设备是对慢速设备中小部分数据的缓存，数据的每次更新需要更新慢速设备和快速设备，热数据只能覆盖读取操作，写入操作慢。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;冷热数据分离整体实现逻辑与redis商业版和阿里混合存储类似。&lt;/p&gt;

&lt;h3 id=&#34;4-1-整体模型&#34;&gt;4.1 整体模型&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/yongman/i/img/picgo/AUbxmS9.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;所有的key保存在内存，每个key都保存LFU信息，key的置换策略主要依赖LFU统计信息，将冷数据的value持久化到RocksDB，冷数据通过后台IO线程与RocksDB交互，不阻塞主线程。&lt;/p&gt;

&lt;h3 id=&#34;4-2-线程模型&#34;&gt;4.2 线程模型&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/yongman/i/img/picgo/3K4Ky4c.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h4 id=&#34;4-2-1-换出冷数据过程&#34;&gt;4.2.1 换出冷数据过程：&lt;/h4&gt;

&lt;ol&gt;
&lt;li&gt;server中增加一个maxhotmemory参数，当内存使用占用超过该配置，server会根据LFU或LRU等信息置换出合适的key；&lt;/li&gt;
&lt;li&gt;将value decode成raw string，封装成异步IO任务，加入任务队列；&lt;/li&gt;
&lt;li&gt;IO线程取出异步任务，将key value存储到RocksDB；&lt;/li&gt;
&lt;li&gt;处理完成后通知主线程，如果在异步线程未处理完成时，访问该key的客户端将加入等待队列；&lt;/li&gt;
&lt;li&gt;主线程收到完成的通知后释放内存中value的内存；&lt;/li&gt;
&lt;li&gt;唤醒等待该key的客户端。&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&#34;4-2-2-加载冷数据过程&#34;&gt;4.2.2 加载冷数据过程：&lt;/h4&gt;

&lt;ol&gt;
&lt;li&gt;客户端访问的key在置换队列中，需要将客户端加入等待队列；&lt;/li&gt;
&lt;li&gt;访问的数据不在内存中，但是客户端命令类型不需要查询原有value，正常执行；&lt;/li&gt;
&lt;li&gt;否则生成异步IO请求，放入IO队列；&lt;/li&gt;
&lt;li&gt;IO线程取出异步任务，从RocksDB中查询对应的value；&lt;/li&gt;
&lt;li&gt;主线程将value加载到内存；&lt;/li&gt;
&lt;li&gt;唤醒等待该key的客户端。&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;4-3-淘汰机制&#34;&gt;4.3 淘汰机制&lt;/h3&gt;

&lt;p&gt;增加maxcoldmemory参数，统计冷数据占用的空间，当maxmemory或maxcoldmemory达到阈值，就执行淘汰策略，与现有保持一致。&lt;/p&gt;

&lt;h3 id=&#34;4-4-持久化&#34;&gt;4.4 持久化&lt;/h3&gt;

&lt;p&gt;和原生的redis对比，持久化数据部分分为热数据和冷数据，热数据采用传统的aof或者rdb方式，冷数据采用RocksDB的checkpoint功能。&lt;/p&gt;

&lt;p&gt;Checkpoint功能可以创建一个满足数据一致性的快照。如果snapshot所在的文件系统和DB file所在的文件系统相同的话，SST files会被硬链接，否则，就要全部拷贝过去，manifest和CURRENT files也会被拷贝过去。&lt;/p&gt;

&lt;p&gt;RocksDB中的checkpoint的原理：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;如果snapshot所在的文件系统和DB file所在的文件系统相同的话，SST files被硬链接；&lt;/li&gt;
&lt;li&gt;否则需要进行文件拷贝；&lt;/li&gt;
&lt;li&gt;拷贝manifest文件和CURRETN文件。&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;4-5-同步&#34;&gt;4.5 同步&lt;/h3&gt;

&lt;p&gt;同步过程也分为全量数据+增量数据过程。&lt;/p&gt;

&lt;h4 id=&#34;4-5-1-全量同步&#34;&gt;4.5.1 全量同步&lt;/h4&gt;

&lt;p&gt;全量数据又有热数据和冷数据，热数据采用原有RDB加载逻辑进行同步，冷数据需要使用RocksDB的checkpoint功能，采用本地盘情况下，需要对checkpoint的文件进行物理拷贝。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;从对主发起全量同步请求；&lt;/li&gt;
&lt;li&gt;master收到收创建rdb快照和RocksDB checkpoint；&lt;/li&gt;
&lt;li&gt;创建完成后传输rdb和RocksDB checkpoint文件；&lt;/li&gt;
&lt;li&gt;从收到文件后先打开RocksDB，然后加载rdb；&lt;/li&gt;
&lt;li&gt;加载完成后同步增量数据。&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&#34;4-5-2-增量同步&#34;&gt;4.5.2 增量同步&lt;/h4&gt;

&lt;p&gt;采用master异步发送output buffer方式，与现有策略保持一致。&lt;/p&gt;

&lt;h3 id=&#34;4-6-集合类型处理方式&#34;&gt;4.6 集合类型处理方式&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;按单key处理&lt;/li&gt;
&lt;/ul&gt;

&lt;ol&gt;
&lt;li&gt;对集合类型value进行dump操作，生成二进制数据。&lt;/li&gt;
&lt;li&gt;将key和二进制value数据写入RocksDB。&lt;/li&gt;
&lt;li&gt;加载过程相反，读取二进制value，执行restore操作，加载到内存。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;置换逻辑采用和普通key value同样策略，可以复用持久化部分逻辑，对于大集合key不友好，客户端阻塞。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;按item处理&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;将不同的数据结构编码为kv结构， 按item存储。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;在内存达到maxhotmemory上限，执行置换策略，如果key是集合，计算将部分item数据置换到RocksDB。&lt;/li&gt;
&lt;li&gt;在一个集合中，key中保存所有item索引，置换到RocksDB的item做上特殊标记。&lt;/li&gt;
&lt;li&gt;访问到特定item，判断item是否在内存中，若不在，RocksDB查询数据加载的内存。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;置换逻辑复杂，各种数据结构单独持久化编码需要实现。&lt;/p&gt;

&lt;p&gt;一期考虑采用单key处理方式，可以增加配置策略，对于大集合不会自动触发数据冷热迁移。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;参考&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://dzone.com/articles/hybrid-memory-using-ram-amp-flash-in-redis&#34;&gt;Running Out of RAM on Redis? No More OOM With Hybrid Memory (RAM and Flash) - DZone Performance&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://redislabs.com/redis-enterprise-documentation/concepts-architecture/memory-architecture/redis-flash/&#34;&gt;Redis on Flash Overview - Redis Enterprise Software | Redis Labs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://dzone.com/articles/your-database-is-wasting-the-ephemeral-drive&#34;&gt;Is Your Database Wasting the Ephemeral Drive? - DZone Database&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.slideshare.net/RedisLabs/redisconf17-building-large-high-performance-redis-databases-with-redis-enterprise&#34;&gt;RedisConf17 - Building Large High Performance Redis Databases with Re…&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://kereno.com/rocksdb-rof.pdf&#34;&gt;Optimization of RocksDB for Redis on Flash&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=xbR0epinnqo&#34;&gt;RocksDB: Key-Value Store Optimized for Flash-Based SSD&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://daim.idi.ntnu.no/masteroppgaver/008/8885/masteroppgave.pdf&#34;&gt;Evaluation of High Performance
Key-Value Stores&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/pdf/1809.00089.pdf&#34;&gt;Anna Cluster Paper&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/Qihoo360/pika&#34;&gt;Pika is a nosql compatible with redis&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://medium.com/netflix-techblog/application-data-caching-using-ssds-5bf25df851ef&#34;&gt;Application data caching using SSDs – Netflix TechBlog – Medium&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://yq.aliyun.com/articles/582418&#34;&gt;Redis混合存储产品与架构介绍-博客-云栖社区-阿里云&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/facebook/rocksdb/wiki/Checkpoints&#34;&gt;Checkpoints · facebook/rocksdb Wiki&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
      
    </item>
    
    <item>
      <title>Anna伯克利高性能可扩展的kv存储系统论文</title>
      <link>https://xiking.win/2018/09/10/anna-fast-scalable-cost-save-key-value-storage/</link>
      <pubDate>Mon, 10 Sep 2018 18:59:03 +0000</pubDate>
      
      <guid>https://xiking.win/2018/09/10/anna-fast-scalable-cost-save-key-value-storage/</guid>
      
        <description>

&lt;p&gt;昨天被朋友圈的一片软文刷屏了，&lt;a href=&#34;https://mp.weixin.qq.com/s/XZYxHEUx0AJozQ2oM5fTrw&#34;&gt;秒杀Redis的KVS上云了！伯克利重磅开源Anna 1.0&lt;/a&gt;
什么秒杀，吊打。。。这种小编是标题骗点击，着实无语。&lt;/p&gt;

&lt;p&gt;做技术都应该抱着敬畏的心态，不同的系统都是在特定的应用场景下诞生的，每一个系统都可能是某一种应用场景下的&lt;code&gt;No.1&lt;/code&gt;, 任何系统，特别是存储类系统，没有一个能够普适的系统完美应对各种应用场景。&lt;/p&gt;

&lt;p&gt;一直对一句话非常赞同：“通用的结果就是通通不能用”。&lt;/p&gt;

&lt;p&gt;在半年之前就看到过HN上关于Anna的消息，也是很多人看到论文中关于和Cassandra、Elasticache、MessTree等对比的argue。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Claims in the blog post (orders of magnitude faster than the current state of the art systems, universal linear universal scalability from threads to many nodes, dimissing Dean&amp;rsquo;s rule of redesign after x10 scale) seem overblown to me.
What have they really built: a purely in-memory KV store that doesn&amp;rsquo;t support synchronous secondary writes for durability. So, any comparisons with ACID KV stores, either disk based (Cassandra, Mongo) or in-memory, are not apples-to-apples comparisons from the beginning. What could be production applications of such system, other than cache?&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;这次发表的论文主要是对Anna集群化的一些工作，描述了如何实现分布式系统的扩展性、低成本和热点问题。&lt;/p&gt;

&lt;p&gt;简单过了一下Anna kvs的集群化上云的论文，简单记录了一下比较关心的点。&lt;/p&gt;

&lt;h3 id=&#34;anna特性&#34;&gt;Anna特性：&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;水平无限扩展&lt;/li&gt;
&lt;li&gt;数据分层移动，冷热数据分离，降低成本&lt;/li&gt;
&lt;li&gt;热点数据流量动态调整&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;部署-架构&#34;&gt;部署&amp;amp;架构&lt;/h3&gt;

&lt;p&gt;基于aws云组件构建，存储节点有内存和亚马逊块存储挂载盘。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/yongman/i/img/picgo/jXFN7Tn.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;监控系统组件，无状态&lt;/li&gt;
&lt;li&gt;策略系统组件，无状态，完成一些数据部署放置策略、数据冷热分离策略、热点key策略&lt;/li&gt;
&lt;li&gt;路由组件，无状态，路由的实现不同于proxy，用户请求流量不经过路由组件，路由组件只提供客户端key的信息，客户端可以对路由信息进行缓存，当数据分布更新后，路由服务会自动更新其缓存的路由信息，供客户端查询。集群的数据迁移，数据分层的变化，通过路由服务进行屏蔽了底层细节，它能够准确的返回给客户端数据的所在的节点和层次。&lt;/li&gt;
&lt;li&gt;存储组件，存储节点根据后端的存储介质区分所在的层次，是单纯的key value引擎，使用gossip协议数据异步复制，支持多master写入，采用&lt;code&gt;last update win&lt;/code&gt;策略解决数据冲突，多线程模式&lt;code&gt;shared-nothing&lt;/code&gt;数据架构。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/yongman/i/img/picgo/Vy99gQs.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Anna的数据分布采用一致性hash，中间加了一层虚拟节点，类似redis cluster中的slot，虚拟节点就是key的子集，一个物理节点负责多个虚拟节点。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;数据和分布解耦&lt;/li&gt;
&lt;li&gt;数据运维单位粒度更小&lt;/li&gt;
&lt;li&gt;物理节点异构&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;存储层&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;为了性能，采用了多work线程架构，支持多master写入，数据的更新直接更新本地，数据的复制依靠后台gossip协议分发。多master所带来的问题就是不能简单对写入的数据进行转发，同时在不同节点更新同一个数据，采用CRDT数据结构来处理数据冲突。&lt;/p&gt;

&lt;p&gt;数据迁移过程中客户端读取数据可能不准确，会读到旧数据，感觉这个完全通过一定策略来避免。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/yongman/i/img/picgo/ajdoKE9.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;数据冷热变化后在不同层次之间的移动所采用的方式比较优雅，就是通过只key对应的meta信息中的replication vector实现数据的移动，异步由gossip协议来进行数据的迁移过程&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;元数据&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Global hash ring：保存key到node的映射&lt;/li&gt;
&lt;li&gt;Local hash ring：保存key到一个node节点内部worker thread的映射&lt;/li&gt;
&lt;li&gt;Replication vector：[&lt;R1,...RN&gt;,&lt;T1,...TN&gt;]，保存的是每个key所对应的复制集节点和worker thread&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;和大部分集中化配置的分布式系统不同，上述元数据不需要保存类似zk、etcd等系统中，直接保存在底层的kv存储，不依赖外部系统。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;策略&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Anna可以配置三种SLO策略维度：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;延迟&lt;/li&gt;
&lt;li&gt;预算&lt;/li&gt;
&lt;li&gt;可用性&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;集群规模的变更会导致数据的迁移，数据迁移过程中为了避免影响服务，Anna也不得不加入&lt;code&gt;grace periods&lt;/code&gt;，在这个时间段内，系统存在一定的降级策略，key的冷热数据管理、热点key复制和扩展性的功能都是不可用的。&lt;/p&gt;

&lt;h3 id=&#34;总结&#34;&gt;总结&lt;/h3&gt;

&lt;p&gt;Anna中实现的这几个特性是比较有需求的，特别是冷热数据分离和热点key的处理，提升单实例的性能一般也会采用多线程方式。&lt;/p&gt;

&lt;p&gt;冷热数据分离就像上一篇提到的，要尽量做到用户无感知的情况下达到节省成本的目标，Anna论文中在futrue work中提到了，当前的策略，采用的是根据当前系统状态或统计信息，来做下一步的操作，比如读取冷数据，对于客户端而言，肯定能感知到延时的增加。所以后续可能通过预测的方式来使系统变的更智能，那样，冷数据会提前变为热数据，达到对客户端透明。&lt;/p&gt;

&lt;p&gt;热点key的数据方式依赖了多master架构，数据的冲突解决采用类似CRDT数据结构来处理冲突，保证数据最终一致，这样的实现方式可能会带来客户端读取到旧数据，或者幻读的问题。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;参考&lt;/strong&gt;
1. &lt;a href=&#34;https://arxiv.org/pdf/1809.00089.pdf&#34;&gt;Anna Cluster Paper&lt;/a&gt;
2. &lt;a href=&#34;https://news.ycombinator.com/item?id=16551072&#34;&gt;Anna: A Fast, Scalable, Flexibly Consistent Key-Value Store | Hacker News&lt;/a&gt;
2. &lt;a href=&#34;http://christophermeiklejohn.com/crdt/2014/07/22/readings-in-crdts.html&#34;&gt;Readings in conflict-free replicated data types&lt;/a&gt;
3. &lt;a href=&#34;http://db.cs.berkeley.edu/papers/UCB-lattice-tr.pdf&#34;&gt;Logic and Lattices for Distributed Programming&lt;/a&gt;
4. &lt;a href=&#34;https://mp.weixin.qq.com/s/XZYxHEUx0AJozQ2oM5fTrw&#34;&gt;秒杀Redis的KVS上云了！伯克利重磅开源Anna 1.0&lt;/a&gt;&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>对数据冷热分离存储的思考</title>
      <link>https://xiking.win/2018/09/06/hot-and-cold-data-separation-storage/</link>
      <pubDate>Thu, 06 Sep 2018 23:54:21 +0000</pubDate>
      
      <guid>https://xiking.win/2018/09/06/hot-and-cold-data-separation-storage/</guid>
      
        <description>&lt;p&gt;对于冷热数据分层存储的最直接的目的就是节省成本，计算机结构里，内存-&amp;gt;nvme ssd-&amp;gt;ssd-&amp;gt;机械盘，访问速度依次降低，单位成本依次降低，存储密度依次增大。
&lt;img src=&#34;https://raw.githubusercontent.com/yongman/i/img/picgo/CFkzyQJ.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;对于像&lt;code&gt;redis&lt;/code&gt;这种天生为高速大并发设计的高性能系统，数据存储也理应放在内存。&lt;/p&gt;

&lt;p&gt;但是我们大多数的使用&lt;code&gt;redis&lt;/code&gt;的场景可能并不是所有数据冷热度是相同的，有些时候我们的系统中也实在用不到100%的redis性能，能满足场景需求的前提下，节省成本就成了开发者或者云平台要考虑的事情了。&lt;/p&gt;

&lt;p&gt;冷热数据分层存储概念也很容易理解，因为计算机系统中到处都是分层的例子，内存的出现也是因为磁盘速度太慢了，cpu如果直接在磁盘上操作，那一个命令估计要等上几秒钟了，cpu中还有L1 cache和L2 cache，都是为了不同组件之间的速度的匹配。&lt;/p&gt;

&lt;p&gt;对于&lt;code&gt;redis&lt;/code&gt;的应用场景来说，完全可以通过一定的算法，对访问进行统计，将冷数据落盘存储，在访问内存中的索引，发生了&lt;code&gt;缺页中断&lt;/code&gt;时，需要将持久化的数据再load到内存。这样实现的是对内存的扩充，而不是对磁盘的cache。
&lt;img src=&#34;https://raw.githubusercontent.com/yongman/i/img/picgo/sC1Fwjj.png&#34; alt=&#34;&#34; /&gt;
都是高速+低速设备，两者的不同在：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;对内存的扩充：所有的数据读写都在内存，不需要每次写入都更新磁盘，而是在数据按一定策略需要置换出去的时候才进行落盘，所以大部分场景，性能影响不大。&lt;/li&gt;
&lt;li&gt;内存用作cache的场景：读写都先请求cache，读不到就访问磁盘，然后回填内存，写入的话必须要保证每次都写入磁盘，适合读多写少的场景。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;对于&lt;code&gt;redis&lt;/code&gt;的冷热分离，redislabs在几年前就推出了&lt;code&gt;Redis On Flash&lt;/code&gt;，阿里云也针对&lt;code&gt;Redis&lt;/code&gt;做了类似的混合存储，实现冷热分离，无一例外，他们都使用了&lt;code&gt;RocksDB&lt;/code&gt;用作磁盘的存储。可以在保持成本低和性能差距不大的前提下，获得更大存储容量。
&lt;img src=&#34;https://raw.githubusercontent.com/yongman/i/img/picgo/AUbxmS9.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;对于&lt;code&gt;缺页中断&lt;/code&gt;的处理肯定会影响连接的吞吐，这个需要努力做的是尽量减少&lt;code&gt;缺页中断&lt;/code&gt;处理的时间，可以采用nvme ssd新硬件，实现用户态IO来避免用户态和内核态切换开销。&lt;/p&gt;

&lt;p&gt;当然难点还是有的，在完全兼容社区redis的前提下，对于单节点存储上百G的数据，对于故障处理或者网络中断等情况的数据恢复如何高效实现等、&lt;code&gt;缺页中断&lt;/code&gt;处理如何能使用户无感知、对于集合类的大key如何实现高效的冷热存储等。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;参考&lt;/strong&gt;
1. &lt;a href=&#34;https://dzone.com/articles/hybrid-memory-using-ram-amp-flash-in-redis&#34;&gt;Running Out of RAM on Redis? No More OOM With Hybrid Memory (RAM and Flash) - DZone Performance&lt;/a&gt;
2. &lt;a href=&#34;https://redislabs.com/redis-enterprise-documentation/concepts-architecture/memory-architecture/redis-flash/&#34;&gt;Redis on Flash Overview - Redis Enterprise Software | Redis Labs&lt;/a&gt;
3. &lt;a href=&#34;https://promotion.aliyun.com/ntms/act/hybridstore.html&#34;&gt;云数据库Redis混合型存储冷热数据分离节约成本&lt;/a&gt;
4. &lt;a href=&#34;https://cloud.tencent.com/developer/article/1020347&#34;&gt;微信 PaxosStore:海量数据冷热分级架构&lt;/a&gt;&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>使用docker-compose一键运行tidis</title>
      <link>https://xiking.win/2018/08/31/tidis-run-with-docker-compose/</link>
      <pubDate>Fri, 31 Aug 2018 15:26:19 +0000</pubDate>
      
      <guid>https://xiking.win/2018/08/31/tidis-run-with-docker-compose/</guid>
      
        <description>&lt;p&gt;&lt;a href=&#34;https://github.com/yongman/tidis&#34;&gt;Tidis&lt;/a&gt;是基于tikv的兼容redis协议持久化存储，得益于分布式kv存储tikv，tidis能够实现水平扩展，数据安全存储和分布式事务支持。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;克隆tidis-docker-compose仓库&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;~ git clone https://github.com/yongman/tidis-docker-compose.git
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;执行docker-compose&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;~ cd tidis-docker-compose/

~ docker-compose up -d
Creating network &amp;quot;docker_default&amp;quot; with the default driver
Creating docker_pd_1 ... done
Creating docker_tikv_1 ... done
Creating docker_tidis_1 ... done
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;验证&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;redis-cli -p 5379
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;停止并删除实例&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;~ docker-compose down
Stopping docker_tidis_1 ... done
Stopping docker_tikv_1  ... done
Stopping docker_pd_1    ... done
Removing docker_tidis_1 ... done
Removing docker_tikv_1  ... done
Removing docker_pd_1    ... done
Removing network docker_default
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
      
    </item>
    
    <item>
      <title>通读PolarFS分布式文件系统论文</title>
      <link>https://xiking.win/2018/08/22/polarfs-distributed-file-system-paper/</link>
      <pubDate>Wed, 22 Aug 2018 19:27:29 +0000</pubDate>
      
      <guid>https://xiking.win/2018/08/22/polarfs-distributed-file-system-paper/</guid>
      
        <description>&lt;p&gt;今天在hn上看到阿里的&lt;a href=&#34;https://news.ycombinator.com/item?id=17814185&#34;&gt;PolarFS&lt;/a&gt;论文，简单读了一下，感觉分布式系统整体架构就是江湖，分久必合，合久必分。&lt;/p&gt;

&lt;p&gt;分布式系统的架构不外乎两种，一种是中心化配置，一种是非中心化配置。&lt;/p&gt;

&lt;p&gt;中心化配置的系统比较多，像GFS/HDFS/集群化MongoDB/TiKV等系统，组件主要是三种，存储节点、控制节点和路由节点。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;存储节点的实现根据系统要解决的问题可以实现为AP或CP，异步数据复制或者类paxos实现一致性复制&lt;/li&gt;
&lt;li&gt;路由节点可以是类似mongos的作用类似proxy，client不需要知晓集群内部细节，客户端更加轻量级；在GFS系统中这部分就集成在client端，client就需要对请求进行路由&lt;/li&gt;
&lt;li&gt;控制节点一般完成的工作包括数据的分布维护、集群中节点状态维护、集群高可用控制、数据的迁移控制等，可能会做一些元信息维护和触发一些周期性任务&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;非中心化配置的像Redis cluster、Cassandra、Scylla、Dynamo，其主要组件主要就是存储和路由控制。&lt;/p&gt;

&lt;p&gt;这些系统中，一般不需要控制节点，集群的状态会通过一些分布式协议如gossip，在集群内部进行传播，集群内部所有节点地位是对等，每个节点都有集群完整的数据分布信息，请求任意节点即可完成交互。系统中可能也不需要路由节点，路由节点功能会集成在数据节点或者智能客户端，客户端动态获取并缓存数据分布状态信息，完成数据定位。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/yongman/i/img/picgo/ZgAfhCx.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;PolarFS整体架构也没有特别之处，和GFS、HDFS非常像，也是集中化配置，其中的PolarCtrl是控制节点、PolarSwitch是路由节点、ChunkServer就是数据节点，其特别之处是通过使用新硬件设备(NVMe)，和技术(实现用户态网络和IO操作，intel的SPDK，RDMA，优化的raft协议等)来压榨硬件性能，尽可能降低分布式系统中最要命的问题&amp;ndash;延时，包括操作系统陷入内核IO操作导致的延时，网络IO延时，数据同步延时。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/yongman/i/img/picgo/pJ7ILQd.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;用户态实现了类似posix语义的操作，这些操作不是标准库的系统调用，不会陷入内核，纯用户态操作，操作指令通过RDMA方式发送给对应chunk server。&lt;/p&gt;

&lt;p&gt;数据复制采用优化过的ParrallelRaft，加快复制，这部分细节没有看。&lt;/p&gt;

&lt;p&gt;PolarCtrl中对于源信息的管理中采用Disk paxos协议和journal file保证元数据信息高可用和安全性。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/yongman/i/img/picgo/COuRH1Z.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Polar通过一种打tag的方式，通过copy on write实现了快照功能。&lt;/p&gt;

&lt;p&gt;最后给出的性能对比中，整体看IO latency能达到和本地文件系统同一数据量级，性能远好于Ceph FS，吞吐量基本上可以和本地ext4持平，远好于Ceph FS。&lt;/p&gt;

&lt;p&gt;PolarFS底层分布式文件系统，在其上构建分布式数据库会更简单，因为采用计算存储分离架构，计算层不需要考虑数据复制和安全性，这些有底层分布式文件系统保证，上层应用只需要关注数据操作逻辑，实现复杂度也极大降低，&lt;a href=&#34;https://github.com/pingcap/tidb&#34;&gt;TiDB&lt;/a&gt;和&lt;a href=&#34;https://github.com/yongman/tidis&#34;&gt;Tidis&lt;/a&gt;的实现的逻辑也是类似，底层实现的分布式kv引擎，完成了数据复制和水平扩展，上层的实现的复杂度极大的降低，当然也存在任何分布式系统都存在的高延时问题，这就需要像PolarFS中努力通过新的技术来压榨新硬件的极限性能。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;参考&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/spdk/spdk&#34;&gt;GitHub - spdk/spdk: Storage Performance Development Kit&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://news.ycombinator.com/item?id=17814185&#34;&gt;PolarFS: Alibaba Distributed File System for Shared Storage Cloud Database | Hacker News&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Journaling_file_system&#34;&gt;Journaling file system - Wikipedia&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.linuxtopia.org/HowToGuides/ext3JournalingFilesystem.html&#34;&gt;What exactly is an ext3 Journaled Filesystem?&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
      
    </item>
    
    <item>
      <title>计算二进制中比特位1的个数</title>
      <link>https://xiking.win/2018/08/17/calculate-bit-one-count/</link>
      <pubDate>Fri, 17 Aug 2018 09:36:39 +0000</pubDate>
      
      <guid>https://xiking.win/2018/08/17/calculate-bit-one-count/</guid>
      
        <description>&lt;p&gt;比如一个32位的无符号整型，如果要统计其中二进制中1的个数，直接从最低位遍历，不管二进制中1的个数有多少，时间复杂度是一样的。&lt;/p&gt;

&lt;p&gt;还有比较快速的计算方式：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;int countOneBit(unsigned int num) {
  int count;
  for (count=0;num&amp;gt;0;count++) {
    num &amp;amp;= num - 1;
  }
  return count;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;每次位与运算都会将其中最后一位比特1置0，直到所有位都是0结束。&lt;/p&gt;

&lt;p&gt;对应优化在&lt;a href=&#34;https://github.com/yongman/tidis&#34;&gt;Tidis&lt;/a&gt;中bitcount命令，commit &lt;a href=&#34;https://github.com/yongman/tidis/commit/6f1f7e920d3987decd2f1afc238c0fa54399de4f&#34;&gt;6f1f7e9&lt;/a&gt;&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>函数隐式声明 implicit declaration of function</title>
      <link>https://xiking.win/2018/08/14/implicit-declaration-of-function/</link>
      <pubDate>Tue, 14 Aug 2018 16:58:36 +0000</pubDate>
      
      <guid>https://xiking.win/2018/08/14/implicit-declaration-of-function/</guid>
      
        <description>&lt;p&gt;默认函数声明&lt;code&gt;Implicit declaration function&lt;/code&gt;引发的血案&lt;/p&gt;

&lt;p&gt;文件1中定义了函数，并malloc了一段内存，返回指针&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;char *func1(char *arg){
    char *c = (char*)malloc(size);
    return c;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在文件2中直接调用该函数，前提是没有显示的声明func1&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    ...
    new_addr = func1(&amp;quot;foo&amp;quot;);
    print(*new_addr);// coredump
    ...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在func1中分配的内存地址是&lt;code&gt;0x7fd370c11008&lt;/code&gt;， 指针new_addr为&lt;code&gt;0x70c11008&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;C99文档中有说明：&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;If an attempt is made to modify the result of a function call or to access it after the next sequence point, the behavior is undefined.
If the expression that denotes the called function has a type that does not include a prototype, the integer promotions are performed on each argument, and arguments that have type float are promoted to double.
These are called the default argument promotions.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;在64位机器上，指针的长度是8字节，隐式的函数声明会默认截断成32位，4字节，导致丢失字节，返回了非法的内存地址，引发coredump。&lt;/p&gt;

&lt;p&gt;编译参数要添加选项&lt;code&gt;-Wmissing-prototypes&lt;/code&gt;，当出现未声明的函数，会发出warning
&lt;code&gt;warning: no previous prototype for *** [-Wmissing-prototypes]&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;参考&lt;/strong&gt;
1. &lt;a href=&#34;https://stackoverflow.com/questions/6488429/implicit-declaration-of-function&#34;&gt;c - implicit declaration of function - Stack Overflow&lt;/a&gt;
2. &lt;a href=&#34;http://c0x.coding-guidelines.com/6.5.2.2.html&#34;&gt;The New C Standard: 6.5.2.2&lt;/a&gt;&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>Leto - A key value storage example powered by hashicorp raft and BadgerDB</title>
      <link>https://xiking.win/leto/</link>
      <pubDate>Fri, 10 Aug 2018 14:07:58 +0000</pubDate>
      
      <guid>https://xiking.win/leto/</guid>
      
        <description>

&lt;h2 id=&#34;0-what-is-leto-mean&#34;&gt;0. What is Leto mean?&lt;/h2&gt;

&lt;p&gt;In Greek mythology, &lt;a href=&#34;https://en.wikipedia.org/wiki/Leto&#34;&gt;Leto&lt;/a&gt; (/ˈliːtoʊ/) is a daughter of the Titans Coeus and Phoebe, the sister of Asteria.&lt;/p&gt;

&lt;h2 id=&#34;1-what-is-leto&#34;&gt;1. What is Leto?&lt;/h2&gt;

&lt;p&gt;Leto is another reference example use of &lt;a href=&#34;https://github.com/hashicorp/raft&#34;&gt;Hashicorp Raft&lt;/a&gt;. The API is &lt;a href=&#34;https://redis.io/topics/protocol&#34;&gt;redis protocol&lt;/a&gt; compatiable.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://raft.github.io/&#34;&gt;Raft&lt;/a&gt;  is a consensus algorithm that is designed to be easy to understand. It&amp;rsquo;s equivalent to Paxos in fault-tolerance and performance. The difference is that it&amp;rsquo;s decomposed into relatively independent subproblems, and it cleanly addresses all major pieces needed for practical systems. We hope Raft will make consensus available to a wider audience, and that this wider audience will be able to develop a variety of higher quality consensus-based systems than are available today.&lt;/p&gt;

&lt;h2 id=&#34;2-why-do-this&#34;&gt;2. Why do this?&lt;/h2&gt;

&lt;p&gt;You can have better comprehension about how &lt;code&gt;raft protocal&lt;/code&gt; works if you use it. This helps me a lot.&lt;/p&gt;

&lt;h2 id=&#34;3-run-sample&#34;&gt;3. Run sample&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;3.1 show helps&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;bin/leto -h
Usage of bin/leto:
  -id string
        node id
  -join string
        join to already exist cluster
  -listen string
        server listen address (default &amp;quot;:5379&amp;quot;)
  -raftbind string
        raft bus transport bind address (default &amp;quot;:15379&amp;quot;)
  -raftdir string
        raft data directory (default &amp;quot;./&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;3.2 Start first node&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;bin/leto -id id1 -raftdir ./id1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;the first node will be listen user request and node join request in port &lt;code&gt;5379&lt;/code&gt;, and use port &lt;code&gt;15379&lt;/code&gt; for raft transport.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;3.3 Start second node&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;bin/leto -id id2 -raftdir ./id2 -listen &amp;quot;:6379&amp;quot; -raftbind &amp;quot;:16379&amp;quot; -join &amp;quot;127.0.0.1:5379&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;3.4 Start third node&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;bin/leto -id id3 -raftdir ./id3 -listen &amp;quot;:7379&amp;quot; -raftbind &amp;quot;:17379&amp;quot; -join &amp;quot;127.0.0.1:5379&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;3.5 Test&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Requst first node&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;redis-cli -p 5379
127.0.0.1:5379&amp;gt; set a b
OK
127.0.0.1:5379&amp;gt; get a
b
127.0.0.1:5379&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Write to second node, data has been replicated to this node. And it will return &lt;code&gt;not leader error&lt;/code&gt; if write to it.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;redis-cli -p 6379
127.0.0.1:6379&amp;gt; get a
b
127.0.0.1:6379&amp;gt; set a b
(error) not leader
127.0.0.1:6379&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now, we  &lt;code&gt;shutdown&lt;/code&gt; the first node, the second node voted to be leader.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;redis-cli -p 6379
127.0.0.1:6379&amp;gt; get a
b
127.0.0.1:6379&amp;gt; set a b
OK
127.0.0.1:6379&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;4-support-commands&#34;&gt;4. Support commands&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;GET&lt;/li&gt;
&lt;li&gt;SET&lt;/li&gt;
&lt;li&gt;DELETE&lt;/li&gt;
&lt;li&gt;JOIN (communicate with peer when start node)&lt;/li&gt;
&lt;li&gt;LEAVE (remove dead node from raft group)&lt;/li&gt;
&lt;li&gt;PING&lt;/li&gt;
&lt;li&gt;SNAPSHOT (trigger snapshot mannually)&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
    <item>
      <title>Tidis - Distributed transactional NoSQL database, Redis protocol compatible using tikv as backend</title>
      <link>https://xiking.win/tidis/</link>
      <pubDate>Fri, 10 Aug 2018 13:58:30 +0000</pubDate>
      
      <guid>https://xiking.win/tidis/</guid>
      
        <description>

&lt;p&gt;Github repo: &lt;a href=&#34;https://github.com/yongman/tidis&#34;&gt;https://github.com/yongman/tidis&lt;/a&gt;
&lt;a class=&#34;github-button&#34; href=&#34;https://github.com/yongman/tidis&#34; data-icon=&#34;octicon-star&#34; data-size=&#34;large&#34; data-show-count=&#34;true&#34; aria-label=&#34;Star yongman/tidis on GitHub&#34;&gt;Star&lt;/a&gt;
&lt;script async defer src=&#34;https://buttons.github.io/buttons.js&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;h1 id=&#34;what-is-tidis&#34;&gt;What is Tidis?&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/yongman/tidis&#34;&gt;Tidis&lt;/a&gt; is a Distributed NoSQL database, providing a Redis protocol API (string, list, hash, set, sorted set), written in Go.&lt;/p&gt;

&lt;p&gt;Tidis is like &lt;a href=&#34;https://github.com/pingcap/tidb&#34;&gt;TiDB&lt;/a&gt; layer, providing protocol transform and data structure compute, powered by &lt;a href=&#34;https://github.com/pingcap/tikv&#34;&gt;TiKV&lt;/a&gt; backend distributed storage which use Raft for data replication and 2PC for distributed transaction.&lt;/p&gt;

&lt;h2 id=&#34;features&#34;&gt;Features&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Redis protocol compatible&lt;/li&gt;
&lt;li&gt;Linear scale-out ability&lt;/li&gt;
&lt;li&gt;Storage and computation separation&lt;/li&gt;
&lt;li&gt;Data safety, no data loss, Raft replication&lt;/li&gt;
&lt;li&gt;Transaction support&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Any pull requests are welcomed.&lt;/p&gt;

&lt;h2 id=&#34;architecture&#34;&gt;Architecture&lt;/h2&gt;

&lt;p&gt;&lt;em&gt;Architechture of tidis&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/yongman/tidis/master/docs/tidis-arch.png&#34; alt=&#34;architecture&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Architechture of tikv&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://pingcap.com/images/blog/TiKV_%20Architecture.png&#34; alt=&#34;&#34; /&gt;
- Placement Driver (PD): PD is the brain of the TiKV system which manages the metadata about Nodes, Stores, Regions mapping, and makes decisions for data placement and load balancing. PD periodically checks replication constraints to balance load and data automatically.
- Node: A physical node in the cluster. Within each node, there are one or more Stores. Within each Store, there are many Regions.
- Store: There is a RocksDB within each Store and it stores data in local disks.
- Region: Region is the basic unit of Key-Value data movement and corresponds to a data range in a Store. Each Region is replicated to multiple Nodes. These multiple replicas form a Raft group. A replica of a Region is called a Peer.&lt;/p&gt;

&lt;h2 id=&#34;1-run-tidis-server-with-docker-compose-in-one-command&#34;&gt;1. Run tidis server with docker-compose in one command&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;git clone https://github.com/yongman/tidis-docker-compose.git
cd tidis-docker-compose/
docker-compose up -d
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Or follow &lt;a href=&#34;https://github.com/yongman/tidis-docker-compose&#34;&gt;tidis-docker-compose&lt;/a&gt; guide to run with &lt;code&gt;docker-compose&lt;/code&gt;&lt;/p&gt;

&lt;h2 id=&#34;2-build-or-docker-mannualy&#34;&gt;2. Build or Docker mannualy&lt;/h2&gt;

&lt;h3 id=&#34;build-from-source&#34;&gt;Build from source&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;git clone https://github.com/yongman/tidis.git
cd tidis &amp;amp;&amp;amp; make
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;pull-from-docker&#34;&gt;Pull from docker&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;docker pull yongman/tidis
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;run-tikv-cluster-for-test&#34;&gt;Run TiKV cluster for test&lt;/h3&gt;

&lt;p&gt;Use &lt;code&gt;docker run tikv&lt;/code&gt; for test, just follow &lt;a href=&#34;https://github.com/pingcap/docs/blob/master/op-guide/docker-deployment.md&#34;&gt;PingCAP official guide&lt;/a&gt;, you just need to deploy PD and TiKV servers, Tidis will take the role of TiDB.&lt;/p&gt;

&lt;h3 id=&#34;run-tidis-or-docker&#34;&gt;Run Tidis or docker&lt;/h3&gt;

&lt;h4 id=&#34;run-tidis-from-executable-file&#34;&gt;Run tidis from executable file&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;bin/tidis-server -conf config.toml
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;run-tidis-from-docker&#34;&gt;Run tidis from docker&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;docker run  -d --name tidis -p 5379:5379 -v {your_config_dir}:/data yongman/tidis -conf=&amp;quot;/data/config.toml&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;3-client-request&#34;&gt;3. Client request&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;redis-cli -p 5379
127.0.0.1:5379&amp;gt; get a
&amp;quot;1&amp;quot;
127.0.0.1:5379&amp;gt; lrange l 0 -1
1) &amp;quot;6&amp;quot;
2) &amp;quot;5&amp;quot;
3) &amp;quot;4&amp;quot;
127.0.0.1:5379&amp;gt; zadd zzz 1 1 2 2 3 3 4 4
(integer) 4
127.0.0.1:5379&amp;gt; zcard zzz
(integer) 4
127.0.0.1:5379&amp;gt; zincrby zzz 10 1
(integer) 11
127.0.0.1:5379&amp;gt; zrange zzz 0 -1 withscores
1) &amp;quot;2&amp;quot;
2) &amp;quot;2&amp;quot;
3) &amp;quot;3&amp;quot;
4) &amp;quot;3&amp;quot;
5) &amp;quot;4&amp;quot;
6) &amp;quot;4&amp;quot;
7) &amp;quot;1&amp;quot;
8) &amp;quot;11&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;already-supported-commands&#34;&gt;Already supported commands&lt;/h2&gt;

&lt;h3 id=&#34;string&#34;&gt;string&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;+-----------+----------------------------------+
|  command  |              format              |
+-----------+----------------------------------+
|    get    | get key                          |
+-----------+----------------------------------+
|    set    | set key value                    |
+-----------+----------------------------------+
|   getbit  | getbit key offset                |
+-----------+----------------------------------+
|   setbit  | setbit key offset value          |
+-----------+----------------------------------+
|    del    | del key1 key2 ...                |
+-----------+----------------------------------+
|    mget   | mget key1 key2 ...               |
+-----------+----------------------------------+
|    mset   | mset key1 value1 key2 value2 ... |
+-----------+----------------------------------+
|    incr   | incr key                         |
+-----------+----------------------------------+
|   incrby  | incr key step                    |
+-----------+----------------------------------+
|    decr   | decr key                         |
+-----------+----------------------------------+
|   decrby  | decrby key step                  |
+-----------+----------------------------------+
|   strlen  | strlen key                       |
+-----------+----------------------------------+
|  pexpire  | pexpire key int                  |
+-----------+----------------------------------+
| pexpireat | pexpireat key timestamp(ms)      |
+-----------+----------------------------------+
|   expire  | expire key int                   |
+-----------+----------------------------------+
|  expireat | expireat key timestamp(s)        |
+-----------+----------------------------------+
|    pttl   | pttl key                         |
+-----------+----------------------------------+
|    ttl    | ttl key                          |
+-----------+----------------------------------+
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;hash&#34;&gt;hash&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;+------------+------------------------------------------+
|  Commands  | Format                                   |
+------------+------------------------------------------+
|    hget    | hget key field                           |
+------------+------------------------------------------+
|   hstrlen  | hstrlen key                              |
+------------+------------------------------------------+
|   hexists  | hexists key                              |
+------------+------------------------------------------+
|    hlen    | hlen key                                 |
+------------+------------------------------------------+
|    hmget   | hmget key field1 field2 field3...        |
+------------+------------------------------------------+
|    hdel    | hdel key field1 field2 field3...         |
+------------+------------------------------------------+
|    hset    | hset key field value                     |
+------------+------------------------------------------+
|   hsetnx   | hsetnx key field value                   |
+------------+------------------------------------------+
|    hmset   | hmset key field1 value1 field2 value2... |
+------------+------------------------------------------+
|    hkeys   | hkeys key                                |
+------------+------------------------------------------+
|    hvals   | hvals key                                |
+------------+------------------------------------------+
|   hgetall  | hgetall key                              |
+------------+------------------------------------------+
|   hclear   | hclear key                               |
+------------+------------------------------------------+
|  hpexpire  | hpexpire key int                         |
+------------+------------------------------------------+
| hpexpireat | hpexpireat key ts                        |
+------------+------------------------------------------+
|   hexpire  | hexpire key int                          |
+------------+------------------------------------------+
|  hexpireat | hexpireat key ts                         |
+------------+------------------------------------------+
|    hpttl   | hpttl key                                |
+------------+------------------------------------------+
|    httl    | httl key                                 |
+------------+------------------------------------------+
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;list&#34;&gt;list&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;+------------+-----------------------+
|  commands  |         format        |
+------------+-----------------------+
|    lpop    | lpop key              |
+------------+-----------------------+
|    rpush   | rpush key             |
+------------+-----------------------+
|    rpop    | rpop key              |
+------------+-----------------------+
|    llen    | llen key              |
+------------+-----------------------+
|   lindex   | lindex key index      |
+------------+-----------------------+
|   lrange   | lrange key start stop |
+------------+-----------------------+
|    lset    | lset key index value  |
+------------+-----------------------+
|    ltrim   | ltrim key start stop  |
+------------+-----------------------+
|    ldel    | ldel key              |
+------------+-----------------------+
|  lpexipre  | lpexpire key int      |
+------------+-----------------------+
| lpexipreat | lpexpireat key ts     |
+------------+-----------------------+
|   lexpire  | lexpire key int       |
+------------+-----------------------+
|  lexpireat | lexpireat key ts      |
+------------+-----------------------+
|    lpttl   | lpttl key             |
+------------+-----------------------+
|    lttl    | lttl key              |
+------------+-----------------------+
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;set&#34;&gt;set&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;+-------------+--------------------------------+
|   commands  |             format             |
+-------------+--------------------------------+
|     sadd    | sadd key member1 [member2 ...] |
+-------------+--------------------------------+
|    scard    | scard key                      |
+-------------+--------------------------------+
|  sismember  | sismember key member           |
+-------------+--------------------------------+
|   smembers  | smembers key                   |
+-------------+--------------------------------+
|     srem    | srem key member                |
+-------------+--------------------------------+
|    sdiff    | sdiff key1 key2                |
+-------------+--------------------------------+
|    sunion   | sunion key1 key2               |
+-------------+--------------------------------+
|    sinter   | sinter key1 key2               |
+-------------+--------------------------------+
|  sdiffstore | sdiffstore key1 key2 key3      |
+-------------+--------------------------------+
| sunionstore | sunionstore key1 key2 key3     |
+-------------+--------------------------------+
| sinterstore | sinterstore key1 key2 key3     |
+-------------+--------------------------------+
|    sclear   | sclear key                     |
+-------------+--------------------------------+
|   spexpire  | spexpire key int               |
+-------------+--------------------------------+
|  spexpireat | spexpireat key ts              |
+-------------+--------------------------------+
|   sexpire   | sexpire key int                |
+-------------+--------------------------------+
|  sexpireat  | sexpireat key ts               |
+-------------+--------------------------------+
|    spttl    | spttl key                      |
+-------------+--------------------------------+
|     sttl    | sttl key                       |
+-------------+--------------------------------+
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;sorted-set&#34;&gt;sorted set&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;+------------------+---------------------------------------------------------------+
|     commands     |                             format                            |
+------------------+---------------------------------------------------------------+
|       zadd       | zadd key member1 score1 [member2 score2 ...]                  |
+------------------+---------------------------------------------------------------+
|       zcard      | zcard key                                                     |
+------------------+---------------------------------------------------------------+
|      zrange      | zrange key start stop [WITHSCORES]                            |
+------------------+---------------------------------------------------------------+
|     zrevrange    | zrevrange key start stop [WITHSCORES]                         |
+------------------+---------------------------------------------------------------+
|   zrangebyscore  | zrangebyscore key min max [WITHSCORES][LIMIT offset count]    |
+------------------+---------------------------------------------------------------+
| zrevrangebyscore | zrevrangebyscore key max min [WITHSCORES][LIMIT offset count] |
+------------------+---------------------------------------------------------------+
| zremrangebyscore | zremrangebyscore key min max                                  |
+------------------+---------------------------------------------------------------+
|    zrangebylex   | zrangebylex key min max [LIMIT offset count]                  |
+------------------+---------------------------------------------------------------+
|  zrevrangebylex  | zrevrangebylex key max min [LIMIT offset count]               |
+------------------+---------------------------------------------------------------+
|  zremrangebylex  | zremrangebylex key min max                                    |
+------------------+---------------------------------------------------------------+
|      zcount      | zcount key                                                    |
+------------------+---------------------------------------------------------------+
|     zlexcount    | zlexcount key                                                 |
+------------------+---------------------------------------------------------------+
|      zscore      | zscore key member                                             |
+------------------+---------------------------------------------------------------+
|       zrem       | zrem key member1 [member2 ...]                                |
+------------------+---------------------------------------------------------------+
|      zclear      | zclear key                                                    |
+------------------+---------------------------------------------------------------+
|      zincrby     | zincrby key increment member                                  |
+------------------+---------------------------------------------------------------+
|     zpexpire     | zpexpire key int                                              |
+------------------+---------------------------------------------------------------+
|    zpexpireat    | zpexpireat key ts                                             |
+------------------+---------------------------------------------------------------+
|      zexpire     | zexpire key int                                               |
+------------------+---------------------------------------------------------------+
|     zexpireat    | zexpireat key ts                                              |
+------------------+---------------------------------------------------------------+
|       zpttl      | zpttl key                                                     |
+------------------+---------------------------------------------------------------+
|       zttl       | zttl key                                                      |
+------------------+---------------------------------------------------------------+
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;transaction&#34;&gt;Transaction&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;+---------+---------+
| command | support |
+---------+---------+
|  multi  | Yes     |
+---------+---------+
|   exec  | Yes     |
+---------+---------+
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;benchmark&#34;&gt;Benchmark&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/yongman/tidis/wiki/Tidis-base-benchmark&#34;&gt;base benchmark&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;environment&#34;&gt;Environment&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;OS: Debian 8.6&lt;/li&gt;
&lt;li&gt;Kernel: 3.16&lt;/li&gt;
&lt;li&gt;Memory: 250GB&lt;/li&gt;
&lt;li&gt;Processor: Intel&amp;reg; Xeon&amp;reg; CPU E5-2670 v3 @ 2.30GHz * 48&lt;/li&gt;
&lt;li&gt;Disk: SATA (SSD is recommended)&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;configuration&#34;&gt;Configuration&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;One pd server (run with docker)&lt;/li&gt;

&lt;li&gt;&lt;p&gt;One tikv server (run with docker), configuration as follows tikv.conf&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;log-level = &amp;quot;info&amp;quot;
[server]
addr = &amp;quot;ip:20160&amp;quot;
[storage]
data-dir = &amp;quot;tikv&amp;quot;
[pd]
endpoints = [&amp;quot;ip:2379&amp;quot;]
[metric]
interval = &amp;quot;1500s&amp;quot;
address = &amp;quot;&amp;quot;
job = &amp;quot;tikv&amp;quot;
[raftstore]
sync-log = false
region-max-size = &amp;quot;384MB&amp;quot;
region-split-size = &amp;quot;256MB&amp;quot;
region-split-check-diff = &amp;quot;32MB&amp;quot;
[rocksdb]
max-manifest-file-size = &amp;quot;20MB&amp;quot;
[rocksdb.defaultcf]
block-size = &amp;quot;64KB&amp;quot;
compression-per-level = [&amp;quot;no&amp;quot;, &amp;quot;no&amp;quot;, &amp;quot;lz4&amp;quot;, &amp;quot;lz4&amp;quot;, &amp;quot;lz4&amp;quot;, &amp;quot;zstd&amp;quot;, &amp;quot;zstd&amp;quot;]
write-buffer-size = &amp;quot;128MB&amp;quot;
max-write-buffer-number = 5
level0-slowdown-writes-trigger = 20
level0-stop-writes-trigger = 36
max-bytes-for-level-base = &amp;quot;512MB&amp;quot;
target-file-size-base = &amp;quot;32MB&amp;quot;
[rocksdb.writecf]
compression-per-level = [&amp;quot;no&amp;quot;, &amp;quot;no&amp;quot;, &amp;quot;lz4&amp;quot;, &amp;quot;lz4&amp;quot;, &amp;quot;lz4&amp;quot;, &amp;quot;zstd&amp;quot;, &amp;quot;zstd&amp;quot;]
write-buffer-size = &amp;quot;128MB&amp;quot;
max-write-buffer-number = 5
min-write-buffer-number-to-merge = 1
max-bytes-for-level-base = &amp;quot;512MB&amp;quot;
target-file-size-base = &amp;quot;32MB&amp;quot;
[raftdb]
compaction-readahead-size = &amp;quot;2MB&amp;quot;
[raftdb.defaultcf]
compression-per-level = [&amp;quot;no&amp;quot;, &amp;quot;no&amp;quot;, &amp;quot;lz4&amp;quot;, &amp;quot;lz4&amp;quot;, &amp;quot;lz4&amp;quot;, &amp;quot;zstd&amp;quot;, &amp;quot;zstd&amp;quot;]
write-buffer-size = &amp;quot;128MB&amp;quot;
max-write-buffer-number = 5
min-write-buffer-number-to-merge = 1
max-bytes-for-level-base = &amp;quot;512MB&amp;quot;
target-file-size-base = &amp;quot;32MB&amp;quot;
block-cache-size = &amp;quot;256MB&amp;quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;One tidis server with default configuration&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;bin/tidis-server -backend ip:2379
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;use-redis-benchmark-with-transaction-support&#34;&gt;Use redis-benchmark with transaction support&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;Let&amp;rsquo;s start with one client concurrency&lt;/li&gt;
&lt;/ol&gt;

&lt;ul&gt;
&lt;li&gt;GET&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;code&gt;redis-benchmark -p 7379 -t GET -r 100000000 -n 10000 -c 1&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;====== GET ======
  10000 requests completed in 5.64 seconds
  1 parallel clients
  3 bytes payload
  keep alive: 1

99.76% &amp;lt;= 1 milliseconds
100.00% &amp;lt;= 2 milliseconds
1773.05 requests per second
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;SET&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;code&gt;redis-benchmark -p 7379 -t SET -r 100000000 -n 1000 -c 1&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;====== SET ======
  1000 requests completed in 2.23 seconds
  1 parallel clients
  3 bytes payload
  keep alive: 1

0.10% &amp;lt;= 1 milliseconds
12.80% &amp;lt;= 2 milliseconds
99.30% &amp;lt;= 3 milliseconds
99.90% &amp;lt;= 4 milliseconds
100.00% &amp;lt;= 8 milliseconds
448.83 requests per second
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If you do this, you will find tidis is &lt;em&gt;quite slow&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;Why? The biggest reason is every write would create a transaction, and the transaction timestamp must be obtain from pd servers, and the request must be encoded/decoded and make a rpc request to tikv server and tikv server use raft for replication and twe-phase commit for distributed transaction, which cause the latancy higher. So throughput of one connection seems quit small.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Start with 50 concurrency&lt;/li&gt;
&lt;/ol&gt;

&lt;ul&gt;
&lt;li&gt;GET&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;code&gt;redis-benchmark -p 7379 -t GET -r 100000000 -n 10000 -c 50&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;====== GET ======
  10000 requests completed in 0.52 seconds
  50 parallel clients
  3 bytes payload
  keep alive: 1

28.86% &amp;lt;= 1 milliseconds
43.97% &amp;lt;= 2 milliseconds
67.82% &amp;lt;= 3 milliseconds
82.37% &amp;lt;= 4 milliseconds
88.53% &amp;lt;= 5 milliseconds
93.77% &amp;lt;= 6 milliseconds
96.76% &amp;lt;= 7 milliseconds
98.05% &amp;lt;= 8 milliseconds
98.98% &amp;lt;= 9 milliseconds
99.44% &amp;lt;= 10 milliseconds
99.71% &amp;lt;= 11 milliseconds
99.87% &amp;lt;= 12 milliseconds
99.93% &amp;lt;= 13 milliseconds
99.99% &amp;lt;= 14 milliseconds
100.00% &amp;lt;= 15 milliseconds
19379.85 requests per second
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;SET&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;code&gt;redis-benchmark -p 7379 -t SET -r 100000000 -n 10000 -c 50&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;====== SET ======
  10000 requests completed in 1.21 seconds
  50 parallel clients
  3 bytes payload
  keep alive: 1

0.01% &amp;lt;= 1 milliseconds
0.03% &amp;lt;= 2 milliseconds
0.70% &amp;lt;= 3 milliseconds
9.10% &amp;lt;= 4 milliseconds
31.07% &amp;lt;= 5 milliseconds
57.32% &amp;lt;= 6 milliseconds
77.68% &amp;lt;= 7 milliseconds
89.09% &amp;lt;= 8 milliseconds
94.78% &amp;lt;= 9 milliseconds
97.63% &amp;lt;= 10 milliseconds
98.49% &amp;lt;= 11 milliseconds
98.86% &amp;lt;= 12 milliseconds
99.05% &amp;lt;= 13 milliseconds
99.09% &amp;lt;= 14 milliseconds
99.12% &amp;lt;= 15 milliseconds
99.23% &amp;lt;= 16 milliseconds
99.29% &amp;lt;= 17 milliseconds
99.45% &amp;lt;= 18 milliseconds
99.60% &amp;lt;= 19 milliseconds
99.80% &amp;lt;= 20 milliseconds
99.93% &amp;lt;= 21 milliseconds
99.99% &amp;lt;= 22 milliseconds
100.00% &amp;lt;= 24 milliseconds
8271.30 requests per second
&lt;/code&gt;&lt;/pre&gt;

&lt;ol&gt;
&lt;li&gt;Let&amp;rsquo;s write batch in one transaction&lt;/li&gt;
&lt;/ol&gt;

&lt;ul&gt;
&lt;li&gt;One client with batch 10 writes in one transaction&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;code&gt;redis-benchmark -p 7379 -t SET -r 100000000 -n 10000 -c 1 -T 10&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;====== SET ======
  10000 requests completed in 2.54 seconds
  1 parallel clients
  3 bytes payload
  keep alive: 1

3933.91 requests per second
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;50 concurrent clients with batch 10 writes in one transaction&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;code&gt;redis-benchmark -p 7379 -t SET -r 100000000 -n 100000 -c 50 -T 10&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;====== SET ======
  100000 requests completed in 1.55 seconds
  50 parallel clients
  3 bytes payload
  keep alive: 1

64516.13 requests per second
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;1000 concurrent clients with batch 100 writes in one transaction&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;code&gt;redis-benchmark -p 7379 -t SET -r 100000000 -n 1000000 -c 1000 -T 100&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;====== SET ======
  1000000 requests completed in 10.19 seconds
  1000 parallel clients
  3 bytes payload
  keep alive: 1

89.90% &amp;lt;= 1 milliseconds
89.94% &amp;lt;= 4 milliseconds
89.96% &amp;lt;= 5 milliseconds
89.99% &amp;lt;= 7 milliseconds
90.00% &amp;lt;= 21 milliseconds
90.01% &amp;lt;= 23 milliseconds
90.02% &amp;lt;= 24 milliseconds
90.03% &amp;lt;= 25 milliseconds
90.06% &amp;lt;= 26 milliseconds
90.15% &amp;lt;= 27 milliseconds
90.29% &amp;lt;= 28 milliseconds
90.52% &amp;lt;= 29 milliseconds
90.95% &amp;lt;= 30 milliseconds
91.53% &amp;lt;= 31 milliseconds
92.44% &amp;lt;= 32 milliseconds
94.50% &amp;lt;= 33 milliseconds
96.27% &amp;lt;= 34 milliseconds
97.32% &amp;lt;= 35 milliseconds
98.27% &amp;lt;= 36 milliseconds
98.87% &amp;lt;= 37 milliseconds
99.16% &amp;lt;= 38 milliseconds
99.31% &amp;lt;= 39 milliseconds
99.51% &amp;lt;= 40 milliseconds
99.58% &amp;lt;= 41 milliseconds
99.64% &amp;lt;= 42 milliseconds
99.73% &amp;lt;= 43 milliseconds
99.83% &amp;lt;= 44 milliseconds
99.90% &amp;lt;= 45 milliseconds
99.92% &amp;lt;= 46 milliseconds
99.94% &amp;lt;= 47 milliseconds
99.95% &amp;lt;= 48 milliseconds
99.98% &amp;lt;= 49 milliseconds
99.99% &amp;lt;= 50 milliseconds
100.00% &amp;lt;= 50 milliseconds
98183.60 requests per second
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This is a base benchmark for now, more scenarios bench data need be added.&lt;/p&gt;

&lt;h2 id=&#34;license&#34;&gt;License&lt;/h2&gt;

&lt;p&gt;Tidis is under the MIT license. See the &lt;a href=&#34;https://github.com/yongman/tidis/blob/master/LICENSE&#34;&gt;LICENSE&lt;/a&gt; file for details.&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>HyperLogLog - 基数统计算法</title>
      <link>https://xiking.win/2018/08/09/hyperloglog/</link>
      <pubDate>Thu, 09 Aug 2018 19:29:22 +0000</pubDate>
      
      <guid>https://xiking.win/2018/08/09/hyperloglog/</guid>
      
        <description>

&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/yongman/i/img/picgo/mjiCDPY.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;如果有一个需求，就是要统计一个全球性活跃网站的访问UV，根据用户ip识别。&lt;/p&gt;

&lt;p&gt;当然可以是要set数据结构，把所有的ip都塞到set数据结构中，最后取一下set的大小。
但是如果只是想要做一些大数据统计，而不关心具体单个的用户信息，如果有上亿用户，这个统计可能需要高达&lt;code&gt;2G&lt;/code&gt;的内存，有必要保存每个用户的ip地址？没有。&lt;/p&gt;

&lt;h2 id=&#34;基数估计&#34;&gt;基数估计&lt;/h2&gt;

&lt;p&gt;HyperLogLog是一种基数统计算法，算法的神奇之处是充分发挥数学之美，在保证相对误差的前提下，用极少的内存完成了同样的工作。redis实现中，&lt;code&gt;12KB&lt;/code&gt;内存就可以完成&lt;code&gt;2^64&lt;/code&gt;个数据的统计。&lt;/p&gt;

&lt;p&gt;HyperLogLog实现的原理基本思想是利用数字的bit信息中第一个&lt;code&gt;1&lt;/code&gt;出现的位置预估整体基数，并采用分桶的方式来减少误差。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;antirez&lt;/code&gt;举了个形象的例子：&lt;/p&gt;

&lt;p&gt;基数估计是如何工作的&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Here I’ll cover only the basic idea using a very clever example found at [3]. Imagine you tell me you spent your day flipping a coin, counting how many times you encountered a non interrupted run of heads. If you tell me that the maximum run was of 3 heads, I can imagine that you did not really flipped the coin a lot of times. If instead your longest run was 13, you probably spent a lot of time flipping the coin.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;如何减少估算的误差&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;However if you get lucky and the first time you get 10 heads, an event that is unlikely but possible, and then stop flipping your coin, I’ll provide you a very wrong approximation of the time you spent flipping the coin. So I may ask you to repeat the experiment, but this time using 10 coins, and 10 different piece of papers, one per coin, where you record the longest run of heads. This time since I can observe more data, my estimation will be better.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;实现原理&#34;&gt;实现原理&lt;/h2&gt;

&lt;p&gt;数据的存储的结构如上图（*该实例并非redis中的实现*）
&lt;img src=&#34;https://raw.githubusercontent.com/yongman/i/img/picgo/Zi5nEEV.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;对于输入，计算hash&lt;/li&gt;
&lt;li&gt;去hash后的二进制比特最右6bit来进行分桶，桶的个数是2^6=64个，对应的桶是6&lt;/li&gt;
&lt;li&gt;计算的hash值左侧的18位用来进行比特统计，从右侧数第一个1bit位的位置为3&lt;/li&gt;
&lt;li&gt;设置第6个register的值为6（由于原来是0，6大于0，所以更新。如果原来的值比6大，则不更新）&lt;/li&gt;
&lt;li&gt;完成元素添加&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;读取的过程需要进行基数估算和修正，当然返回的结果是有误差率的。&lt;/p&gt;

&lt;p&gt;不行，看到数据公式有点头大，先休息会吧。 :-)。&lt;/p&gt;

&lt;p&gt;图示地址：&lt;a href=&#34;http://content.research.neustar.biz/blog/hll.html&#34;&gt;HyperLogLog&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;参考&#34;&gt;参考&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;http://antirez.com/news/75&#34;&gt;Redis new data structure: the HyperLogLog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.yoonper.com/post.php?id=79&#34;&gt;HyperLogLog算法详解 - YoonPer&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://research.neustar.biz/2012/10/25/sketch-of-the-day-hyperloglog-cornerstone-of-a-big-data-infrastructure/&#34;&gt;HyperLogLog — Cornerstone of a Big Data Infrastructure&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
      
    </item>
    
    <item>
      <title>正向代理和反向代理</title>
      <link>https://xiking.win/2018/08/06/forward-proxy-and-reverse-proxy/</link>
      <pubDate>Mon, 06 Aug 2018 11:29:59 +0000</pubDate>
      
      <guid>https://xiking.win/2018/08/06/forward-proxy-and-reverse-proxy/</guid>
      
        <description>

&lt;p&gt;虽然经常使用nginx或者科学上网搭建代理，对于代理分类具体含义还是需要解析下。&lt;/p&gt;

&lt;h2 id=&#34;正向代理&#34;&gt;正向代理&lt;/h2&gt;

&lt;p&gt;正向代理就是一个位于客户端和目标服务器的代理服务器，对于客户端不透明，如果使用正向代理，客户端一般需要经过一些配置，就像我们科学上网，一般客户端会经过配置，直接访问代理服务器，通过代理服务器来访问目标资源。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/yongman/i/img/picgo/dunEUb7.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;反向代理&#34;&gt;反向代理&lt;/h2&gt;

&lt;p&gt;反向代理就是目标服务器，客户端任务它就是目标服务器，就像nginx的proxy_pass配置，用户访问时访问反向代理服务器，并不知道反向代理后面的资源在哪里。这种方式对用户透明，客户端不需要修改配置。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/yongman/i/img/picgo/pCN6p8i.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;区别&#34;&gt;区别&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;用途&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;正向代理：典型就是应用在跨越防火墙来访问互联网，（自己在防火墙内，访问不了互联网）。
反向代理：典型就是将防火墙后面的计算资源提供给用户，（后端服务在防火墙内，用户访问不了，但是可以通过一个网关或者代理入口，如nginx）。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;安全性&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;正向代理：允许客户端访问目标端并且隐藏自身的存在，需要一些必要鉴权措施保证自身的安全。
反向代理：对用户透明。&lt;/p&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://www.jscape.com/blog/bid/87783/Forward-Proxy-vs-Reverse-Proxy&#34;&gt;Forward Proxy vs Reverse Proxy&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
      
    </item>
    
    <item>
      <title>LevelDB中snapshot和compaction</title>
      <link>https://xiking.win/2018/08/03/leveldb-key-snapshot-compaction/</link>
      <pubDate>Fri, 03 Aug 2018 19:23:54 +0000</pubDate>
      
      <guid>https://xiking.win/2018/08/03/leveldb-key-snapshot-compaction/</guid>
      
        <description>

&lt;p&gt;本文简单记录了leveldb中有关key的种类、memtable的操作、snapshot的原理和Compaction。&lt;/p&gt;

&lt;h3 id=&#34;key&#34;&gt;Key&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;LookupKey: &lt;code&gt;klength|UserKey|tag&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;InternalKey: &lt;code&gt;UserKey|tag&lt;/code&gt;，其中tag部分包括&lt;code&gt;SequenceNumber&lt;/code&gt;和&lt;code&gt;ValueType&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;ParsedInternalKey: 包含&lt;code&gt;UserKey&lt;/code&gt;、&lt;code&gt;SequenceNumber&lt;/code&gt;和&lt;code&gt;ValueType&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;UserKey：用户存储的原始key&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;code&gt;userkey添加tag信息=&amp;gt;InternalKey 增加key长度=&amp;gt;LookupKey&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&#34;memtable&#34;&gt;Memtable&lt;/h3&gt;

&lt;p&gt;Memtable只提供了Get和Add，因为LevelDB的更新操作全部是追加写，包括delete操作。&lt;/p&gt;

&lt;p&gt;Add操作的流程是先根据userKey和sequenceNumber生成InternalKey，然后插入skiplist。&lt;/p&gt;

&lt;p&gt;Get操作流程是先根据传入的lookupKey从skiplist查找，查找到读取对应的value并解析tag，是&lt;code&gt;kTypeValue&lt;/code&gt;就返回对应的value，是&lt;code&gt;kTypeDeletion&lt;/code&gt;就返回NotFound。&lt;/p&gt;

&lt;h3 id=&#34;snapshot&#34;&gt;Snapshot&lt;/h3&gt;

&lt;p&gt;snapshot在LevelDB中的存在形式就是一个严格递增的SequenceNumber，LevelDB中最新的snapshot保存在
&lt;code&gt;versions_-&amp;gt;LastSequence()&lt;/code&gt;中。&lt;/p&gt;

&lt;p&gt;userKey编码成Internalkey时，在userkey后面跟着sequenceNumber，同一个userKey的多个版本数据天然按新旧进行排序，当查看指定的snapshot版本的数据时，生成带有sequenceNumber的lookupKey，查找不大于指定snapshot版本的最大数据即可。&lt;/p&gt;

&lt;h3 id=&#34;compaction&#34;&gt;Compaction&lt;/h3&gt;

&lt;p&gt;LevelDB中有两种类型compaction，Minor compaction和Major compaction。Compaction是后台线程来调度，读写线程中更新compaction统计信息，判断是否需要进行compaction，如果需要进行compaction就创建任务，加入任务队列。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Minor compaction&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;后台任务检测到存在immutable memtable时，就会触发CompactMemTable，首先对currentVersion进行加引用，然后由versionSet生成一个新的sst file并dump数据到sst file，然后选择给sst file所放置的level。&lt;/p&gt;

&lt;p&gt;一般情况下memtable dump的sst file都放在0 level，但是当第0层中的所有sst file都不包含memtable中的key的range，这时可以直接将该sst放在更高一层，尽可能的减少major compaction。&lt;/p&gt;

&lt;p&gt;新生成的sst file以及其所在level都会记录在本次的versionEdit对象中，然后将该versionEdit应用在currentVersion生成新的version，最后将该versionEdit持久化到manifest文件。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Major compaction&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;major compaction过程的细节比较多，作者的设计思想也是尽量做有必要的，尽可能优化性能，还需细细研究。&lt;/p&gt;

&lt;p&gt;major compaction也可以手动触发，多数情况还是进行自动触发的。自动触发会根据平时的统计信息来决定什么时候对哪个level的哪个sst file进行comapction操作。&lt;/p&gt;

&lt;p&gt;Level 0的sst file是最特殊的，sst file中的key range可以相互重叠，也就是给定一个key，这个key可能存在sst file中的任意一个或多个中，所以Level 0会做特殊处理。通过pickCompaction创建compaction任务，然后执行compaction。&lt;/p&gt;

&lt;p&gt;LevelDB的简洁得益于它的抽象，比如多个文件的合并操作，在上层只需要创建多个文件的迭代器，就可以按key有序遍历数据，极大简化上层的调用。&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>LevelDB版本管理和读写操作</title>
      <link>https://xiking.win/2018/08/01/leveldb-mvcc-read-write-put-delete/</link>
      <pubDate>Wed, 01 Aug 2018 20:07:32 +0000</pubDate>
      
      <guid>https://xiking.win/2018/08/01/leveldb-mvcc-read-write-put-delete/</guid>
      
        <description>

&lt;p&gt;LevelDB是一个轻量级的key value存储系统，存储结构采用LSM-Tree，对写操作优化，特别是普通的机械盘。&lt;/p&gt;

&lt;p&gt;LevelDB是Bigtable中描述的的key value存储系统的实现，它具有的一些特性：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;二进制安全的kv存储&lt;/li&gt;
&lt;li&gt;数据存储方式按key排序&lt;/li&gt;
&lt;li&gt;支持批量原子操作&lt;/li&gt;
&lt;li&gt;MVCC和快照&lt;/li&gt;
&lt;li&gt;数据遍历&lt;/li&gt;
&lt;li&gt;支持数据压缩&lt;/li&gt;
&lt;li&gt;多线程安全&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;lsm和b-tree&#34;&gt;LSM和B+Tree&lt;/h3&gt;

&lt;p&gt;一张图描述B树
&lt;img src=&#34;https://ws4.sinaimg.cn/large/006tKfTcgy1ftt3tnl3m3j30hs07e3yq.jpg&#34; alt=&#34;B树&#34; /&gt;
B树主要用于文件系统&lt;/p&gt;

&lt;p&gt;一张图描述B+树
&lt;img src=&#34;https://ws2.sinaimg.cn/large/006tKfTcgy1ftt40kjr9tj30hs072t8z.jpg&#34; alt=&#34;B+树&#34; /&gt;
常见的磁盘存储引擎通常采用B+树进行索引，B+树是专门对磁盘设计的一个N叉的排序树，数据查找过程中索引的目的就是加快查找速度，减少磁盘IO，一般采用B+树的存储引擎，父节点中的元素都会出现的子节点，叶子节点包含了数据全量元素信息，叶子节点形成了一个有序链表。&lt;/p&gt;

&lt;p&gt;数据存储在B树和B+树的区别
&lt;img src=&#34;https://ws1.sinaimg.cn/large/006tKfTcgy1ftt46ur0p8j30hs08mt96.jpg&#34; alt=&#34;B树&#34; /&gt;
&lt;img src=&#34;https://ws2.sinaimg.cn/large/006tKfTcgy1ftt47thrclj30hs0850t5.jpg&#34; alt=&#34;B+树&#34; /&gt;&lt;/p&gt;

&lt;p&gt;由于B+树的中间节点只存储索引，所以单个节点存储更多的元素，所以同样的数据量，B+树IO次数更少。&lt;/p&gt;

&lt;p&gt;LSM树是一个N阶合并树，数据写入先追加日志，然后更新内存，内存达到一定阈值后dump到磁盘，并周期性进行compaction。由于LSM的特性，将随机写转化为顺序写，防止随机磁盘IO。&lt;/p&gt;

&lt;p&gt;由于LSM的特性和LevelDB的分层，其中的数据经过多次compaction后冷热已经实现了分离(按最后一次更新时间)，由于memtable的存在，看似像是缓存，但行为和缓存是不一样的，普通的缓存的设计思想是当从缓存读取失败后进行填充和主动更新数据后主动更新缓存，它是把经常访问的数据放到离业务更近的位置；而LevelDB是对于新写入的数据会放在memtable，当memtable刷到磁盘后，再读取相关的数据，数据并不会回填到内存，即便一直在读取的热数据，当没有更新时，LevelDB会尽量将数据放到离业务更远的位置。&lt;/p&gt;

&lt;h3 id=&#34;version&#34;&gt;Version&lt;/h3&gt;

&lt;p&gt;Version就是LevelDB中的所有数据的一个版本或者视图的元信息，其中记录了每一层的所有文件和一些compaction相关状态信息。&lt;/p&gt;

&lt;p&gt;VersionSet是用来管理Version的一个集合。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;VersionSet=Version1+Version2+Version3+...+currentVersion
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://ws4.sinaimg.cn/large/006tKfTcly1fttzvz1nfdj30pe0fpabv.jpg&#34; alt=&#34;VersionSet&#34; /&gt;&lt;/p&gt;

&lt;p&gt;VersionEdit可以看做是Version之间变更的增量信息，可以从上一个版本与VersionEdit合并，生成新的版本。在开始启动时，LevelDB会读取Manifest文件，按顺序读取VersionEdit，组成VersionSet，通过Builder生成currentVersion&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Vn=Vn-1+VersionEdit
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://ws4.sinaimg.cn/large/006tKfTcgy1fttzyavx74j30gd04hjrh.jpg&#34; alt=&#34;VersionEdit&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Write/Put/Delete操作&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Write操作流程很简单，但是看LevelDB的代码，感觉写的很奇妙，其实就是一个生产消费者模型，它的实现的区别在生产消费者角色不是固定的，一个生产者线程，后续的操作可能被选择为消费者。当有多个生产者线程写入数据，数据被封装成Writer加入队列，然后判断是否被处理过或者是不是在队列头的第一个任务，如果是处在队列头的第一个任务，那这个Writer的角色转化成消费者，批量将队列任务进行处理，然后标记完成处理过的任务，当再次唤醒对应的生产者线程，任务已经被处理过，直接返回。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;实现简洁，不需要区分生产消费者，生产者就是消费者；&lt;/li&gt;
&lt;li&gt;消费者批量处理生产者请求；&lt;/li&gt;
&lt;li&gt;可以保证同一时刻只有一个消费者，尽量缩小临界区，提升并发度。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Get操作&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;整个Get流程也很清晰，先从memtable中查找，找不到就再次查找immutable memtable中查找，如果immutable memtable中也不存在，最后会在currentVersion中查找，整个查找过程并不是直接查找user key，而是通过user key和sequence number生成的lookup key，增量序列号来支持快照读。&lt;/p&gt;

&lt;p&gt;最后就是更新统计信息，检查是否需要触发compaction。&lt;/p&gt;

&lt;h3 id=&#34;参考内容&#34;&gt;参考内容&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.41.8933&#34;&gt;CiteSeerX — The Design and Implementation of a Log-Structured File System&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://catkang.github.io/2017/02/03/leveldb-version.html&#34;&gt;庖丁解LevelDB之版本控制 | CatKang的博客&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
      
    </item>
    
    <item>
      <title>Leto - 基于raft快速实现一个key-value存储系统</title>
      <link>https://xiking.win/2018/07/30/implement-key-value-store-using-raft/</link>
      <pubDate>Mon, 30 Jul 2018 16:16:17 +0000</pubDate>
      
      <guid>https://xiking.win/2018/07/30/implement-key-value-store-using-raft/</guid>
      
        <description>

&lt;p&gt;&lt;a href=&#34;https://github.com/yongman/leto&#34;&gt;Leto基于raft和redis协议的key value存储系统&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;raft&lt;/code&gt;是一种类似于&lt;code&gt;paxos&lt;/code&gt;的一致性算法，但是相对&lt;code&gt;paxos&lt;/code&gt;，&lt;code&gt;raft&lt;/code&gt;更易于简单，易于理解，所以工程实现也比较多。对于&lt;code&gt;golang&lt;/code&gt;来说，经过工业验证的是hashicorp(consul)的&lt;code&gt;raft&lt;/code&gt;库和etcd中实现的&lt;code&gt;raft&lt;/code&gt;库。&lt;/p&gt;

&lt;h2 id=&#34;raft协议&#34;&gt;raft协议&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;http://thesecretlivesofdata.com/raft/&#34;&gt;raft可视化&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://raft.github.io/&#34;&gt;Raft Consensus Algorithm&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/yongman/leto&#34;&gt;A key value storage example powered by hashicorp raft and BadgerDB&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;raft库选择&#34;&gt;raft库选择&lt;/h2&gt;

&lt;p&gt;大体看了下etcd raft和hashicorp raft的实现，感觉上来说hashicorp的&lt;code&gt;raft&lt;/code&gt;包装更好，后端使用了封装好的&lt;code&gt;boltdb&lt;/code&gt;作为LogStore和StableStore，而etcd的&lt;code&gt;raft&lt;/code&gt;库可定制性更强，封装没有那么完整，读起来也比较费力。作为初次使用&lt;code&gt;raft&lt;/code&gt;，选择hashicorp raft感觉会更容易上手。&lt;/p&gt;

&lt;h2 id=&#34;快速实现一个分布式key-value存储系统&#34;&gt;快速实现一个分布式key value存储系统&lt;/h2&gt;

&lt;p&gt;既然是分布式，其具备的分布式系统的基本特性，该系统取名&lt;a href=&#34;https://zh.wikipedia.org/zh-hans/%E5%8B%92%E6%89%98&#34;&gt;勒托&lt;/a&gt;,来自希腊神话，阿波罗之母。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;Github&lt;/code&gt;地址：
&lt;a href=&#34;https://github.com/yongman/leto&#34;&gt;https://github.com/yongman/leto&lt;/a&gt;。&lt;/p&gt;

&lt;h3 id=&#34;1-特性&#34;&gt;1. 特性&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;容错性&lt;/li&gt;
&lt;li&gt;集群节点动态变化&lt;/li&gt;
&lt;li&gt;数据安全性&lt;/li&gt;
&lt;li&gt;可以支持多种后端引擎&lt;/li&gt;
&lt;li&gt;snapshot支持&lt;/li&gt;
&lt;li&gt;集群线性扩展(待实现)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;2-目的&#34;&gt;2. 目的&lt;/h3&gt;

&lt;p&gt;虽然从零造轮子不是什么好主意，为了更好的学习&lt;code&gt;raft&lt;/code&gt;，在实践中摸索，对于初学者对于加深理解&lt;code&gt;raft&lt;/code&gt;很有帮助。&lt;/p&gt;

&lt;h3 id=&#34;3-具体实现&#34;&gt;3. 具体实现&lt;/h3&gt;

&lt;p&gt;定义一个&lt;code&gt;store&lt;/code&gt;，其中包含了&lt;code&gt;raft&lt;/code&gt;实例和&lt;code&gt;fsm&lt;/code&gt;实例。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;fsm&lt;/code&gt;实例就是&lt;code&gt;raft&lt;/code&gt;中保存状态的组件，它完成了状态机生成快照、恢复快照、和回放&lt;code&gt;raft log&lt;/code&gt;来更新状态机。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;raft&lt;/code&gt;实例就是创建的hashicorp &lt;code&gt;raft&lt;/code&gt;对象，创建时会将上面的&lt;code&gt;fsm&lt;/code&gt;实例传入，用于自定义实现存储的过程。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;生成快照采用了&lt;code&gt;google protobuf&lt;/code&gt;协议序列化数据并打包，数据通过&lt;code&gt;raft.FSMSnapshot&lt;/code&gt;接口的&lt;code&gt;Persist&lt;/code&gt;实现数据打包并持久化磁盘。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Store对象&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type Store struct {
	RaftDir  string
	RaftBind string

	raft *raft.Raft // The consensus mechanism
	fsm  *fsm

	logger *log.Logger
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Store提供的api&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// 生成store对象
func (s *Store) Open(bootstrap bool, localID string) error

// 提供的上层数据操作接口，调用底层raft或者fsm接口
func (s *Store) Get(key string) (string, error)
func (s *Store) Set(key, value string) error
func (s *Store) Delete(key string) error

// 集群成员变更处理接口
// 新成员加入集群
func (s *Store) Join(nodeID, addr string) error
// 成员退出集群
func (s *Store) Leave(nodeID string) error

// 生成快照，用户触发
func (s *Store) Snapshot() error
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;fsm对象&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type fsm struct {
	db DB

	logger *log.Logger
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;fsm提供的api&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// 状态查询
func (f *fsm) Get(key string) (string, error)
// 状态应用
func (f *fsm) Apply(l *raft.Log) interface{}

// 生成快照，这里只是返回了一个实现了FSMSnapshot接口的对象
func (f *fsm) Snapshot() (raft.FSMSnapshot, error)
func (f *fsm) Restore(rc io.ReadCloser) error
func (f *fsm) Close() error
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;FSMSnapshot对象&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type fsmSnapshot struct {
	db     DB
	logger *log.Logger
}

// 具体实现fsm状态持久化逻辑，一般是通过生成db快照，然后遍历db，生成kv对然后序列化
func (f *fsmSnapshot) Persist(sink raft.SnapshotSink) error
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;后端引擎接口&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type DB interface {
	Get(key []byte) ([]byte, error)
	Set(key, value []byte) error
	Delete(key []byte) (bool, error)

	SnapshotItems() &amp;lt;-chan DataItem

	Close()
}

type DataItem interface{}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;server api&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;server api采用redis协议，用户可以使用任何redis客户端来与leto通信。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;组建集群&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;第一个节点启动采用&lt;code&gt;bootstrap&lt;/code&gt;方式&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;bin/leto -id id1 -raftdir ./id1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;后续节点启动后指定第一个节点的&lt;code&gt;server api&lt;/code&gt;地址，将本节点信息通过&lt;code&gt;join&lt;/code&gt;命令发送给&lt;code&gt;bootstrap&lt;/code&gt;节点，&lt;code&gt;bootstrap&lt;/code&gt;节点会将刚启动的节点加入&lt;code&gt;raft&lt;/code&gt;集群。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;bin/leto -id id2 -raftdir ./id2 -listen &amp;quot;:6379&amp;quot; -raftbind &amp;quot;:16379&amp;quot; -join &amp;quot;127.0.0.1:5379&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;启动第三个节点&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;bin/leto -id id3 -raftdir ./id3 -listen &amp;quot;:7379&amp;quot; -raftbind &amp;quot;:17379&amp;quot; -join &amp;quot;127.0.0.1:5379&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;4-目前支持的命令&#34;&gt;4. 目前支持的命令&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;GET&lt;/li&gt;
&lt;li&gt;SET&lt;/li&gt;
&lt;li&gt;DELETE&lt;/li&gt;
&lt;li&gt;JOIN&lt;/li&gt;
&lt;li&gt;LEAVE&lt;/li&gt;
&lt;li&gt;PING&lt;/li&gt;
&lt;li&gt;SNAPSHOT&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
    <item>
      <title>关于我</title>
      <link>https://xiking.win/about/</link>
      <pubDate>Thu, 19 Jul 2018 09:08:30 +0000</pubDate>
      
      <guid>https://xiking.win/about/</guid>
      
        <description>

&lt;p&gt;我，IT界的一名小学生，2015年计算机研究生毕业，标准90后，已婚，有娃。&lt;/p&gt;

&lt;p&gt;目前主要精力在学习&lt;code&gt;分布式系统&lt;/code&gt;、&lt;code&gt;高性能缓存&lt;/code&gt;、&lt;code&gt;存储&lt;/code&gt;等方面知识，欢迎一起学习交流。&lt;/p&gt;

&lt;p&gt;空闲之余，喜欢刷刷&lt;code&gt;Twitter&lt;/code&gt;和&lt;code&gt;Youtube&lt;/code&gt;，喜欢&lt;code&gt;旅行&lt;/code&gt;和&lt;code&gt;摄影&lt;/code&gt;。&lt;/p&gt;

&lt;h4 id=&#34;联系方式&#34;&gt;联系方式&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://twitter.com/YongXMan&#34;&gt;Twitter&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://t.me/yongman&#34;&gt;Telegram&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/yongman&#34;&gt;Github&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;或者，直接留言:-)&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>Mac osx让工作更有效率的桌面控制管理工具</title>
      <link>https://xiking.win/2018/07/18/desktop-automation-tools-for-mac/</link>
      <pubDate>Wed, 18 Jul 2018 10:05:46 +0000</pubDate>
      
      <guid>https://xiking.win/2018/07/18/desktop-automation-tools-for-mac/</guid>
      
        <description>

&lt;h2 id=&#34;1-hammerspoon-高效操作窗口和鼠标&#34;&gt;1. Hammerspoon-高效操作窗口和鼠标&lt;/h2&gt;

&lt;p&gt;自己在工作中一直在使用&lt;code&gt;mac&lt;/code&gt;，并且外接显示器多屏幕，一直在找可以快速将鼠标焦点移动到另外屏幕的工具，之前搜了半天没找到就放弃了。
但是用&lt;code&gt;trackpad&lt;/code&gt;将鼠标在两个屏幕中拖来拖去，手指都酸了。今天发现了一个&lt;code&gt;Hammerspoon&lt;/code&gt;工具，通过自定义lua脚本可以实现
- 窗口复杂的移动，可以指定移动的坐标
- 窗口大小调整
- 多窗口排列
- 监控响应多种事件
- 鼠标控制
- &amp;hellip;其他暂时没有需求&lt;/p&gt;

&lt;p&gt;下面是我使用的lua配置，实现了窗口移动和大小控制，鼠标快速切换&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;-- 一般组合键为 Shift + Command + ?
local hyper = {&#39;shift&#39;, &#39;cmd&#39;}

-- 最大化窗口
-- 快捷键为 Shift + Command + ↑
hs.hotkey.bind(hyper, &#39;up&#39;, function()
    hs.grid.maximizeWindow()
end)

-- 让窗口占据左半边（Windows 下面的向左贴边停靠）
-- 快捷键为 Shift + Command + ←
hs.hotkey.bind(hyper, &amp;quot;Left&amp;quot;, function()
  local win = hs.window.focusedWindow()
    local f = win:frame()
    local screen = win:screen()
    local max = screen:frame()

    f.x = max.x
    f.y = max.y
    f.w = max.w / 2
    f.h = max.h
    win:setFrame(f)
end)

-- 让窗口占据右半边（Windows 下面的向左贴边停靠）
-- 快捷键为 Shift + Command + -&amp;gt;
hs.hotkey.bind(hyper, &amp;quot;Right&amp;quot;, function()
  local win = hs.window.focusedWindow()
    local f = win:frame()
    local screen = win:screen()
    local max = screen:frame()

    f.x = max.x + max.w / 2
    f.y = max.y
    f.w = max.w / 2
    f.h = max.h
    win:setFrame(f)
end)

-- 移动鼠标第n个屏幕
-- 快捷键为 Shift + Command + `
hs.hotkey.bind(hyper, &#39;`&#39;, function()
    local screen = hs.mouse.getCurrentScreen()
    local nextScreen = screen:next()
    local rect = nextScreen:fullFrame()
    local center = hs.geometry.rectMidPoint(rect)
 
    hs.mouse.setAbsolutePosition(center)
end)

-- 将当前窗口移动到第 n 个屏幕
-- 并最大化窗口
-- 快捷键为 Ctrl + Command + 屏幕数字
local hyper2 = {&#39;ctrl&#39;, &#39;cmd&#39;}
moveto = function(win, n)
  local screens = hs.screen.allScreens()
  if n &amp;gt; #screens then
    hs.alert.show(&amp;quot;No enough screens &amp;quot; .. #screens)
  else
    local toWin = hs.screen.allScreens()[n]:name()
    hs.layout.apply({{nil, win:title(), toWin, hs.layout.maximized, nil, nil}})
  end
end

hs.hotkey.bind(hyper2, &amp;quot;1&amp;quot;, function()
  local win = hs.window.focusedWindow()
  moveto(win, 1)
end)
hs.hotkey.bind(hyper2, &amp;quot;2&amp;quot;, function()
  local win = hs.window.focusedWindow()
  moveto(win, 2)
end)

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;更新&lt;/strong&gt;
发现一个更完整的配置，窗口管理更完善，代码风格更好。&lt;a href=&#34;https://github.com/S1ngS1ng/HammerSpoon&#34;&gt;https://github.com/S1ngS1ng/HammerSpoon&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;2-manico-快速切换或打开app&#34;&gt;2. Manico-快速切换或打开app&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;Manico 是一个非常容易使用的 App，您可以在无需任何配置和学习就可以立刻开始使用它。您所做的仅仅是，当您需要切换至一个 App 时，按住 Option 键和对应的目标数字或字母，您将被立马切换至对应的 App。如果这个 App 还没有启动，那么 Manico 会先启动它。&lt;/p&gt;

&lt;p&gt;Manico 的主意最初来自于 Ubuntu Unity 桌面，如果您曾经使用过 Unity 桌面并且习惯于 Super 键切换 App，并且想要在 macOS 里有同样的功能，那么 Manico 就是为您设计的。这也是我最初开发 Manico 的目标，但是它不仅仅是如此。&lt;/p&gt;

&lt;p&gt;在我们的日常电脑使用中，我们每个人都有一些每天都会使用的 App，比如：Finder，Safari（或其他浏览器）或 Terminal。切换并使用他们应该是很直接的，传统的「CMD + Tab」的切换方式应该只用于切换那些使用频率不高的 App。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://www.hammerspoon.org/go/&#34;&gt;Hammerspoon - Getting Started&lt;/a&gt;
&lt;a href=&#34;https://www.jianshu.com/p/3d62c18c0c78&#34;&gt;Mac 多显示器快速移动鼠标 - 简书&lt;/a&gt;
&lt;a href=&#34;https://www.v2ex.com/t/187697&#34;&gt;有没有快速把鼠标移到下一个屏幕窗口的方法? - V2EX&lt;/a&gt;
&lt;a href=&#34;https://manico.im/&#34;&gt;Manico - macOS 下的快速 App 切换器&lt;/a&gt;&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>Tidis - 基于tikv实现兼容redis协议分布式事务存储</title>
      <link>https://xiking.win/2018/07/17/tidis-distributed-transactional-redis-protocol-disk-storage/</link>
      <pubDate>Tue, 17 Jul 2018 09:40:27 +0000</pubDate>
      
      <guid>https://xiking.win/2018/07/17/tidis-distributed-transactional-redis-protocol-disk-storage/</guid>
      
        <description>

&lt;h2 id=&#34;1-背景&#34;&gt;1. 背景&lt;/h2&gt;

&lt;p&gt;redis本身的定位是高速缓存，有多种数据结构支持，全量内存，使用成本高，当数据量达到一定规模后，用户不得不考虑将部分冷数据从redis中迁移到其他存储，节省成本。也有很多应用场景，用户使用redis的目的很大一部分是由于redis api使用简单，数据结构丰富，快速实现业务功能，而真正线上服务的qps远远达不到需要使用redis的场景，造成资源浪费严重。&lt;/p&gt;

&lt;h2 id=&#34;2-相似项目调研&#34;&gt;2. 相似项目调研&lt;/h2&gt;

&lt;p&gt;redis定位高性能高速缓存，低容量，低延时，当容量达到一定规模，成本可能成为限制数据规模的因素。当用户的应用场景是想使用redis的数据结构，作为可靠的存储、对数据安全性要求高、数据量大，数据存储介质就需要从昂贵的ram存储到磁盘或ssd。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;基于单机key-value引擎，增加数据结构和协议支持&lt;/li&gt;
&lt;/ol&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;1.1 &lt;strong&gt;SSDB&lt;/strong&gt;
&lt;img src=&#34;https://camo.githubusercontent.com/6f3243b32deae6f762859f3ee91eeeb36f291518/687474703a2f2f737364622e696f2f737364622e706e67&#34; alt=&#34;SSDB架构图&#34; /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/ideawu/ssdb&#34;&gt;repo&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;底层存储引擎采用leveldb单机引擎，实现zset、map、queue数据结构&lt;/li&gt;
&lt;li&gt;基于master-slave复制、&lt;/li&gt;
&lt;li&gt;全量复制和flush操作速度慢&lt;/li&gt;
&lt;li&gt;本身无集群化方案，类似于redis2.8&lt;/li&gt;
&lt;li&gt;主从复制效率低，全局锁竞争严重&lt;/li&gt;
&lt;li&gt;数据结构的一些操作效率低，很多操作基于遍历&lt;/li&gt;
&lt;li&gt;c++实现&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;1.2 &lt;strong&gt;LedisDB&lt;/strong&gt;
实现架构类似ssdb&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/siddontang/ledisdb&#34;&gt;repo&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;golang实现&lt;/li&gt;
&lt;li&gt;底层引擎采用可替换引擎，leveldb、rocksdb、goleveldb等，实现kv、list、set、zset、hash等数据结构&lt;/li&gt;
&lt;li&gt;采用leveldb或rocksdb会存在cgo性能损失&lt;/li&gt;
&lt;li&gt;基于master-slave复制&lt;/li&gt;
&lt;li&gt;采用类似codis的集群化方案xcodis&lt;/li&gt;
&lt;li&gt;未经线上多规模验证&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;1.3 &lt;strong&gt;RedisDB&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/ksarch-saas/ssdb&#34;&gt;repo&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;基于SSDB二次开发(c++)&lt;/li&gt;
&lt;li&gt;优化主从复制&lt;/li&gt;
&lt;li&gt;增加数据多版本&lt;/li&gt;
&lt;li&gt;支持所有数据自动过期&lt;/li&gt;
&lt;li&gt;支持数据迁移&lt;/li&gt;
&lt;li&gt;采用修改过的codis集群化方案(golang)&lt;/li&gt;
&lt;li&gt;未大规模线上验证&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;1.4 &lt;strong&gt;swapdb&lt;/strong&gt;
&lt;img src=&#34;https://github.com/JingchengLi/swapdb/raw/master/docs/fundamental.jpg&#34; alt=&#34;swapdb&#34; /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/JingchengLi/swapdb&#34;&gt;repo&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;深度定制的redis和优化过的ssdb整合&lt;/li&gt;
&lt;li&gt;京东金融开源&lt;/li&gt;
&lt;li&gt;高度兼容redis api&lt;/li&gt;
&lt;li&gt;冷热数据分离，热数据在redis，冷数据存储到ssdb&lt;/li&gt;
&lt;li&gt;可以实现原生的redis cluster集群&lt;/li&gt;
&lt;li&gt;无数据可靠性保证，定位还是缓存&lt;/li&gt;
&lt;li&gt;开源后没看到社区应用案例&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;1.5 &lt;strong&gt;Tidis&lt;/strong&gt;
&lt;img src=&#34;https://github.com/yongman/tidis/raw/master/docs/tidis-arch.png&#34; alt=&#34;tidis架构图&#34; /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/yongman/tidis&#34;&gt;repo&lt;/a&gt;，欢迎star&lt;/li&gt;
&lt;li&gt;golang实现&lt;/li&gt;
&lt;li&gt;目前状态为demo实现，还处于功能开发阶段，仅供测试&lt;/li&gt;
&lt;li&gt;实现采用分布式key value引擎TiKV， 可以对比FoundationDB&lt;/li&gt;
&lt;li&gt;Tidis类似TiDB层，无状态&lt;/li&gt;
&lt;li&gt;采用存储计算分离架构&lt;/li&gt;
&lt;li&gt;无限水平扩展&lt;/li&gt;
&lt;li&gt;自动数据均衡&lt;/li&gt;
&lt;li&gt;Raft副本复制，确保数据不丢&lt;/li&gt;
&lt;li&gt;TiKV采用rust语言，底层引擎为rocksdb&lt;/li&gt;
&lt;li&gt;支持分布式事务&lt;/li&gt;
&lt;li&gt;事务采用乐观锁，事务提交冲突可配重试次数&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;3-对比&#34;&gt;3. 对比&lt;/h2&gt;

&lt;p&gt;上面列出的5种存储方案中SSDB/ledisdb/redisdb是同一类型，基于单机的kv引擎实现的类redis协议的存储，数据可靠性采用异步副本复制，集群化都需要额外的工作，集群化后需要实现数据动态迁移功能，如果要保证数据安全性，需要采用raft等同步协议，复杂度较高。
* 优势：属于传统实现方式，实现单机存储引擎，性能好，大部分取决于磁盘、底层使用的存储引擎和数据组织方式，网络性能损耗小。
* 劣势：
  - 不支持事务，自己实现集群化方案和数据复制和迁移，复杂度高。
  - 采用悲观锁，适合有很多热点写入的数据场景&lt;/p&gt;

&lt;p&gt;swapdb的实现方式很美好，由存储端完成冷热数据的区分，不需要用户关心，用户只需要像使用redis一样来访问，冷数据会落盘，不占用内存，达到节省成本的目的。swapdb虽然支持原生的cluster方式，把内存数据和磁盘数据来一起运维，两种数据是一个整体，原来的cluster特性会由于ssdb数据部分操作缓慢导致运维上的不可控等因素。
* 优势：屏蔽用户使用场景，冷热数据自动分离存储。
* 劣势：快速和慢速数据同时存放，运维难度大&lt;/p&gt;

&lt;p&gt;Tidis采用计算存储分离设计，底层采用分布式kv存储，分布式事务实现方式为2pc，所有的写入操作都需要起事务，事务时间戳从PD节点获取，同时对相同的key进行写入，事务提交会产生冲突导致事务重试，并且事务都是2pc，两次网络交互会增加请求latency，优势是极大简化了计算层的逻辑，存储层实现了分布式事务，实现了raft数据复制，实现了数据动态迁移和节点高可用切换，而计算层需要做的就是专注于数据结构实现效率和异常处理等逻辑。
* 优势：存储计算分离，存储引擎保证了分布式事务，实现了数据复制和自动均衡，计算层不需要实现分布式的逻辑。
* 劣势：
  - latency比较高，一次写入可能需要三次网络交互，1次从pd获取时间戳，2次阶段提交
  - 采用事务乐观锁，正常的写入不会进行加锁，commit时检测事务是否存在冲突，进行重试，不适合很多热点数据写入的数据场景
  - 写密集型场景容易发生写冲突，导致事务commit失败重试&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pingcap/tikv/master/images/tikv_stack.png&#34; alt=&#34;tikv&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;4-实现&#34;&gt;4. 实现&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;已经实现的命令&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&#34;4-1-string&#34;&gt;4.1 string&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;+-----------+----------------------------------+
|  command  |              format              |
+-----------+----------------------------------+
|    get    | get key                          |
+-----------+----------------------------------+
|    set    | set key value                    |
+-----------+----------------------------------+
|    del    | del key1 key2 ...                |
+-----------+----------------------------------+
|    mget   | mget key1 key2 ...               |
+-----------+----------------------------------+
|    mset   | mset key1 value1 key2 value2 ... |
+-----------+----------------------------------+
|    incr   | incr key                         |
+-----------+----------------------------------+
|   incrby  | incr key step                    |
+-----------+----------------------------------+
|    decr   | decr key                         |
+-----------+----------------------------------+
|   decrby  | decrby key step                  |
+-----------+----------------------------------+
|   strlen  | strlen key                       |
+-----------+----------------------------------+
|  pexpire  | pexpire key int                  |
+-----------+----------------------------------+
| pexpireat | pexpireat key timestamp(ms)      |
+-----------+----------------------------------+
|   expire  | expire key int                   |
+-----------+----------------------------------+
|  expireat | expireat key timestamp(s)        |
+-----------+----------------------------------+
|    pttl   | pttl key                         |
+-----------+----------------------------------+
|    ttl    | ttl key                          |
+-----------+----------------------------------+
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;4-2-hash&#34;&gt;4.2 hash&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;+------------+------------------------------------------+
|  Commands  | Format                                   |
+------------+------------------------------------------+
|    hget    | hget key field                           |
+------------+------------------------------------------+
|   hstrlen  | hstrlen key                              |
+------------+------------------------------------------+
|   hexists  | hexists key                              |
+------------+------------------------------------------+
|    hlen    | hlen key                                 |
+------------+------------------------------------------+
|    hmget   | hmget key field1 field2 field3...        |
+------------+------------------------------------------+
|    hdel    | hdel key field1 field2 field3...         |
+------------+------------------------------------------+
|    hset    | hset key field value                     |
+------------+------------------------------------------+
|   hsetnx   | hsetnx key field value                   |
+------------+------------------------------------------+
|    hmset   | hmset key field1 value1 field2 value2... |
+------------+------------------------------------------+
|    hkeys   | hkeys key                                |
+------------+------------------------------------------+
|    hvals   | hvals key                                |
+------------+------------------------------------------+
|   hgetall  | hgetall key                              |
+------------+------------------------------------------+
|   hclear   | hclear key                               |
+------------+------------------------------------------+
|  hpexpire  | hpexpire key int                         |
+------------+------------------------------------------+
| hpexpireat | hpexpireat key ts                        |
+------------+------------------------------------------+
|   hexpire  | hexpire key int                          |
+------------+------------------------------------------+
|  hexpireat | hexpireat key ts                         |
+------------+------------------------------------------+
|    hpttl   | hpttl key                                |
+------------+------------------------------------------+
|    httl    | httl key                                 |
+------------+------------------------------------------+
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;4-3-list&#34;&gt;4.3 list&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;+------------+-----------------------+
|  commands  |         format        |
+------------+-----------------------+
|    lpop    | lpop key              |
+------------+-----------------------+
|    rpush   | rpush key             |
+------------+-----------------------+
|    rpop    | rpop key              |
+------------+-----------------------+
|    llen    | llen key              |
+------------+-----------------------+
|   lindex   | lindex key index      |
+------------+-----------------------+
|   lrange   | lrange key start stop |
+------------+-----------------------+
|    lset    | lset key index value  |
+------------+-----------------------+
|    ltrim   | ltrim key start stop  |
+------------+-----------------------+
|    ldel    | ldel key              |
+------------+-----------------------+
|  lpexipre  | lpexpire key int      |
+------------+-----------------------+
| lpexipreat | lpexpireat key ts     |
+------------+-----------------------+
|   lexpire  | lexpire key int       |
+------------+-----------------------+
|  lexpireat | lexpireat key ts      |
+------------+-----------------------+
|    lpttl   | lpttl key             |
+------------+-----------------------+
|    lttl    | lttl key              |
+------------+-----------------------+
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;4-4-set&#34;&gt;4.4 set&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;+-------------+--------------------------------+
|   commands  |             format             |
+-------------+--------------------------------+
|     sadd    | sadd key member1 [member2 ...] |
+-------------+--------------------------------+
|    scard    | scard key                      |
+-------------+--------------------------------+
|  sismember  | sismember key member           |
+-------------+--------------------------------+
|   smembers  | smembers key                   |
+-------------+--------------------------------+
|     srem    | srem key member                |
+-------------+--------------------------------+
|    sdiff    | sdiff key1 key2                |
+-------------+--------------------------------+
|    sunion   | sunion key1 key2               |
+-------------+--------------------------------+
|    sinter   | sinter key1 key2               |
+-------------+--------------------------------+
|  sdiffstore | sdiffstore key1 key2 key3      |
+-------------+--------------------------------+
| sunionstore | sunionstore key1 key2 key3     |
+-------------+--------------------------------+
| sinterstore | sinterstore key1 key2 key3     |
+-------------+--------------------------------+
|    sclear   | sclear key                     |
+-------------+--------------------------------+
|   spexpire  | spexpire key int               |
+-------------+--------------------------------+
|  spexpireat | spexpireat key ts              |
+-------------+--------------------------------+
|   sexpire   | sexpire key int                |
+-------------+--------------------------------+
|  sexpireat  | sexpireat key ts               |
+-------------+--------------------------------+
|    spttl    | spttl key                      |
+-------------+--------------------------------+
|     sttl    | sttl key                       |
+-------------+--------------------------------+
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;4-5-sorted-set&#34;&gt;4.5 sorted set&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;+------------------+---------------------------------------------------------------+
|     commands     |                             format                            |
+------------------+---------------------------------------------------------------+
|       zadd       | zadd key member1 score1 [member2 score2 ...]                  |
+------------------+---------------------------------------------------------------+
|       zcard      | zcard key                                                     |
+------------------+---------------------------------------------------------------+
|      zrange      | zrange key start stop [WITHSCORES]                            |
+------------------+---------------------------------------------------------------+
|     zrevrange    | zrevrange key start stop [WITHSCORES]                         |
+------------------+---------------------------------------------------------------+
|   zrangebyscore  | zrangebyscore key min max [WITHSCORES][LIMIT offset count]    |
+------------------+---------------------------------------------------------------+
| zrevrangebyscore | zrevrangebyscore key max min [WITHSCORES][LIMIT offset count] |
+------------------+---------------------------------------------------------------+
| zremrangebyscore | zremrangebyscore key min max                                  |
+------------------+---------------------------------------------------------------+
|    zrangebylex   | zrangebylex key min max [LIMIT offset count]                  |
+------------------+---------------------------------------------------------------+
|  zrevrangebylex  | zrevrangebylex key max min [LIMIT offset count]               |
+------------------+---------------------------------------------------------------+
|  zremrangebylex  | zremrangebylex key min max                                    |
+------------------+---------------------------------------------------------------+
|      zcount      | zcount key                                                    |
+------------------+---------------------------------------------------------------+
|     zlexcount    | zlexcount key                                                 |
+------------------+---------------------------------------------------------------+
|      zscore      | zscore key member                                             |
+------------------+---------------------------------------------------------------+
|       zrem       | zrem key member1 [member2 ...]                                |
+------------------+---------------------------------------------------------------+
|      zclear      | zclear key                                                    |
+------------------+---------------------------------------------------------------+
|      zincrby     | zincrby key increment member                                  |
+------------------+---------------------------------------------------------------+
|     zpexpire     | zpexpire key int                                              |
+------------------+---------------------------------------------------------------+
|    zpexpireat    | zpexpireat key ts                                             |
+------------------+---------------------------------------------------------------+
|      zexpire     | zexpire key int                                               |
+------------------+---------------------------------------------------------------+
|     zexpireat    | zexpireat key ts                                              |
+------------------+---------------------------------------------------------------+
|       zpttl      | zpttl key                                                     |
+------------------+---------------------------------------------------------------+
|       zttl       | zttl key                                                      |
+------------------+---------------------------------------------------------------+
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;4-6-transaction&#34;&gt;4.6 Transaction&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;+---------+---------+
| command | support |
+---------+---------+
|  multi  | Yes     |
+---------+---------+
|   exec  | Yes     |
+---------+---------+
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;4-7-benchmark&#34;&gt;4.7 Benchmark&lt;/h3&gt;

&lt;p&gt;基础benchmark数据，可以查看项目&lt;a href=&#34;https://github.com/yongman/tidis/wiki/Tidis-base-benchmark&#34;&gt;wiki页面&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;5-参考&#34;&gt;5. 参考&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/ideawu/ssdb&#34;&gt;GitHub - ideawu/ssdb: SSDB - A fast NoSQL database, an alternative to Redis&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/siddontang/ledisdb&#34;&gt;GitHub - siddontang/ledisdb: a high performance NoSQL powered by Go&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/ksarch-saas/ssdb&#34;&gt;GitHub - ksarch-saas/ssdb: SSDB - A fast NoSQL database, an alternative to Redis&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/yongman/tidis&#34;&gt;GitHub - yongman/tidis: Distributed NoSQL database, Redis protocol compatible using tikv as backend&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/JingchengLi/swapdb&#34;&gt;GitHub - JingchengLi/swapdb: https://github.com/JingchengLi/swapdb/wiki&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/pingcap/tidb&#34;&gt;GitHub - pingcap/tidb: TiDB is a distributed HTAP database compatible with the MySQL protocol&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/pingcap/tikv&#34;&gt;GitHub - pingcap/tikv: Distributed transactional key value database powered by Rust and Raft&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://godoc.org/github.com/pingcap/tidb/store/tikv&#34;&gt;tikv - GoDoc&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/apple/foundationdb&#34;&gt;GitHub - apple/foundationdb: FoundationDB - the open source, distributed, transactional key-value store&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.foundationdb.org/&#34;&gt;FoundationDB | Home&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://apple.github.io/foundationdb/benchmarking.html&#34;&gt;Benchmarking — FoundationDB 5.1&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
      
    </item>
    
    <item>
      <title>SSH tunnel隧道网络穿透</title>
      <link>https://xiking.win/2018/07/13/ssh-tunnel-proxy-and-port-forwarding/</link>
      <pubDate>Fri, 13 Jul 2018 14:47:05 +0000</pubDate>
      
      <guid>https://xiking.win/2018/07/13/ssh-tunnel-proxy-and-port-forwarding/</guid>
      
        <description>

&lt;p&gt;SSH是一种安全的传输协议，ssh命令也是linux和mac上最常用的远程登录命令。出了远程登录，ssh还有一些其他的功能。比如隧道网络穿透。&lt;/p&gt;

&lt;h4 id=&#34;什么是网络穿透&#34;&gt;什么是网络穿透？&lt;/h4&gt;

&lt;p&gt;其实网络穿透就是一种网络代理，比如在内网中有一台机器A，这台机器无法访问互联网，但是局域网内有一台其他机器B可以访问外网权限，所以我们可以把A的请求通过SSH隧道转发到机器B，机器B和互联网交互，数据再通过SSH隧道转发给机器A，这样机器A就可以通过可以连接外网的机器B来访问互联网了。&lt;/p&gt;

&lt;p&gt;SSH中有两种端口转发模式：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;本地端口转发(Local Port Forwarding)&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;从ssh client机器执行命令, ssh client没有直接访问host的权限，通过ssh_server来转发，ssh_server提供转发服务：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ssh -L bind_addr:port:host:hostport user@ssh_server
&lt;/code&gt;&lt;/pre&gt;

&lt;ol&gt;
&lt;li&gt;远程端口转发(Remote Port Forwarding)&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;从ssh client机器执行命令， ssh client有访问host权限，而ssh_server无访问权限，也就是ssh client要代理远程的访问，提供转发服务。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ssh -R bind_addr:port:host:hostport user@ssh_server
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;远程端口转发需要注意的是，命令需要早ssh server上监听端口，一些情况下可能需要root权限，所以普通用户可能登录ssh_server会无法监听端口。&lt;/p&gt;

&lt;p&gt;&lt;em&gt;没有什么是一张图说明不了的。&lt;/em&gt;
&lt;img src=&#34;http://www.dirk-loss.de/ssh-port-forwarding.png&#34; alt=&#34;ssh-port-forwarding.png&#34; /&gt;&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>清理git历史中的敏感信息</title>
      <link>https://xiking.win/2018/07/05/clean-github-sensitive-data-from-history/</link>
      <pubDate>Thu, 05 Jul 2018 14:44:15 +0000</pubDate>
      
      <guid>https://xiking.win/2018/07/05/clean-github-sensitive-data-from-history/</guid>
      
        <description>

&lt;p&gt;由于使用的编辑器带有代码头自动填充，或者不小心把密码明文写进了代码，并且不小心push到了github，当你发现的时候一般的补救措施是起不到作用的，除非&amp;hellip;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;删除你的整个repo，这个对于维护了一段时间的项目肯定是无法接受的，删除后会导致repo中所有的数据丢失，包括issue和wiki，当然fork、star和watch也全部丢失了。&lt;/li&gt;
&lt;li&gt;修改密码，这个似乎不是在解决问题，而是在逃避问题。当然如果密码无法修改，那本方法也无效。&lt;/li&gt;
&lt;li&gt;重写历史。
对于这种方式官方提供两种方式。两种方式对于历史提交的SHAs都会更改，SHAs的修改对于活跃的社区项目可能会影响到其他开发者的pull request。所以建议在进行重写历史之前merge或者close掉待处理的pr。&lt;/li&gt;
&lt;/ol&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;BFG&lt;/p&gt;

&lt;p&gt;bfg是一个jar包，其使用方式如下：&lt;/p&gt;

&lt;p&gt;直接将带有泄露信息的文件以及历史全部删除&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$java -jar bfg.jar --delete-files file_path_you_want_to_clean
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;将泄露的信息进行文本替换成&lt;code&gt;***REMOVED***&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$java -jar bfg.jar --replace-text sensitive_text_you_want_to_clean
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;历史提交更新后，相应的信息在本地还没有彻底删除，执行下面的命令进行垃圾回收&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;git reflog expire --expire=now --all &amp;amp;&amp;amp; git gc --prune=now --aggressive
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;最后执行&lt;code&gt;git push --force&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;git filter-branch&lt;/p&gt;

&lt;p&gt;在使用git filter-branch之前先把事前stash保存的工作pop出来，否则会导致无法恢复。这种方式似乎只能删除文件，不能直接进行文本替换&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;git filter-branch --force --index-filter \
&#39;git rm --cached --ignore-unmatch PATH-TO-YOUR-FILE-WITH-SENSITIVE-DATA&#39; \
--prune-empty --tag-name-filter cat -- --all

git push origin --force --all

git for-each-ref --format=&#39;delete %(refname)&#39; refs/original | git update-ref --stdin

git reflog expire --expire=now --all
git gc --prune=now
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;参考&#34;&gt;参考&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://help.github.com/articles/removing-sensitive-data-from-a-repository/&#34;&gt;Removing sensitive data from a repository - User Documentation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://rtyley.github.io/bfg-repo-cleaner/&#34;&gt;BFG Repo-Cleaner by rtyley&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
    <item>
      <title>Percolator论文学习</title>
      <link>https://xiking.win/2018/06/22/percolator-paper/</link>
      <pubDate>Fri, 22 Jun 2018 14:44:15 +0000</pubDate>
      
      <guid>https://xiking.win/2018/06/22/percolator-paper/</guid>
      
        <description>

&lt;p&gt;Percolator是Google为了解决搜索引擎中增量索引，替代原先的MR系统，可以实现增量更新索引，使得新的网页更快的被用户搜索到。&lt;/p&gt;

&lt;p&gt;离线的处理方式可以很好的实现索引的相关计算，MR吞吐量在一定周期内也可以完成整个索引库的更新，但是对于只重新抓取了一小部分页面时，对于MR来说效率很低，为了少量的增量更新能够被索引，全量数据需要全部计算一遍。&lt;/p&gt;

&lt;p&gt;理想的情况就是索引可以被流式增量处理，任何新的更新可以在一个大型的文档库中实时进行小的更新。&lt;/p&gt;

&lt;p&gt;Percolator提供在PB级别存储库中随机访问的能力。随机访问允许我们单独的处理文档，避免全局的扫描(未优化的MR往往需要全局扫描)。为了提升吞吐量，percolator实现高并发事务。&lt;/p&gt;

&lt;p&gt;论文中主要介绍了分布式事务的实现和通知机制，这里注重关注分布式事务。&lt;/p&gt;

&lt;h3 id=&#34;分布式事务&#34;&gt;分布式事务&lt;/h3&gt;

&lt;p&gt;Percolator运行于BigTable之上，支持快照隔离，采用MVCC维护数据多版本。在分布式系统中，要保证事务的正确性，需要有一个严格递增的版本号，percolator中使用timestamp oracle来生成全局严格递增的时间戳，每个事务需要获取两次时间戳，第一次是事务开始时，获取事务开始时间戳，第二次是事务提交时，用作提交时间戳。&lt;/p&gt;

&lt;p&gt;对于任何一列数据C，在bigtable中存储格式会分为：
* C:data 用于存储真正的数据
* C:lock 用于存储事务的锁信息
* C:write 用于存储数据的提交版本&lt;/p&gt;

&lt;p&gt;以论文中转账的例子来进行说明
&lt;img src=&#34;http://ww1.sinaimg.cn/large/6d6b007fly1fsoph426dij20gs0cujt4.jpg&#34; alt=&#34;1.jpg&#34; /&gt;
&lt;img src=&#34;http://ww1.sinaimg.cn/large/6d6b007fly1fsoph44m3hj20ge0j877u.jpg&#34; alt=&#34;2.jpg&#34; /&gt;
&lt;img src=&#34;http://ww1.sinaimg.cn/large/6d6b007fly1fsoph43k62j20hl0b9wg5.jpg&#34; alt=&#34;3.jpg&#34; /&gt;
&lt;img src=&#34;http://ww1.sinaimg.cn/large/6d6b007fly1fsoph45dc9j20ie0ljdjy.jpg&#34; alt=&#34;4.jpg&#34; /&gt;&lt;/p&gt;

&lt;p&gt;事务分两个阶段，prepare阶段和commit阶段。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Prepare阶段：&lt;/li&gt;
&lt;/ul&gt;

&lt;ol&gt;
&lt;li&gt;启动事务T1，获取时间戳7&lt;/li&gt;
&lt;li&gt;选择Bob:lock为primary lock，写入lock列，然后将新的数据写入C:data列&lt;/li&gt;
&lt;li&gt;事务使用同一个时间戳写入Joe:lock列，值为事务的primary key，指向Bob,并将新的数据写入Joe:data列&lt;/li&gt;
&lt;/ol&gt;

&lt;ul&gt;
&lt;li&gt;Commit阶段：&lt;/li&gt;
&lt;/ul&gt;

&lt;ol&gt;
&lt;li&gt;准备提交，首先获取时间戳8&lt;/li&gt;
&lt;li&gt;清理Bob的lock列，以新时间戳写入一条数据8， 向Bob write列以时间戳8写入一条数据，数据中包含指向最新的数据指针，指向事务开始时间戳7中对应的数据&lt;/li&gt;
&lt;li&gt;清理Joe中的lock列，以新时间戳写入一条数据8，向Joe write列写入一条数据，指向事务开始时间戳中对应的数据&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;事务冲突&#34;&gt;事务冲突&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;写写冲突&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;事务开始时间戳之后，write列有更新的时间戳记录，说明已经有事务在本事务开始之后还未提交之前已经提交，发生冲突。或者lock列中存在锁，也直接取消。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;读写冲突&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Get操作会先进行检查(0,开始时间戳)检查锁，如果存在锁，说明前面的事务还未完成，读事务等待锁释放。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;锁清理&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;事务处理过程中，prewrite阶段，客户端故障，会导致事务锁残留在系统中，采用lazy方式来进行锁清理，当事务A发现锁，并能确定该锁被事务B遗弃，事务A会将锁进行清理。&lt;/p&gt;

&lt;p&gt;commit阶段客户端故障，如果已经提交过一个写记录，并且还有未提交的记录，执行roll-forward，primary已经被替换为一条写记录，事务必须被提交，否则应该roll-back。&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>新的开始</title>
      <link>https://xiking.win/2018/06/01/a-new-start/</link>
      <pubDate>Fri, 01 Jun 2018 10:16:44 +0000</pubDate>
      
      <guid>https://xiking.win/2018/06/01/a-new-start/</guid>
      
        <description>&lt;p&gt;刚开始接触blog还是在学校，把平时的一些学习记录在当时比较流行的CSDN上，后来感觉上面广告太多，当时就考虑购买了云主机环境，自己搭建了wordpress，其中很大一部分时间在定制主题，安装各种插件，当时的兴趣也许根本不在内容上，慢慢的激情退却，似乎遗忘了这个很久没有更新的blog。就连云主机到期也没有想要迁移blog数据，也许是自己感觉上面确实没有值得备份的内容吧。&lt;/p&gt;

&lt;p&gt;一直到现在，已经有几年没有记录的习惯了，也没有时间来思考一些东西，有点浑浑噩噩的感觉。&lt;/p&gt;

&lt;p&gt;所以，一切归于至简。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;不要广告&lt;/li&gt;
&lt;li&gt;只关注内容&lt;/li&gt;
&lt;li&gt;ui简洁&lt;/li&gt;
&lt;li&gt;无需维护&lt;/li&gt;
&lt;li&gt;免费&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;所以github pages就是最好的选择。&lt;/p&gt;

&lt;p&gt;也许这就是&lt;a href=&#34;http://www.ruanyifeng.com/blog/&#34;&gt;阮一峰&lt;/a&gt;说的blog的三个阶段吧。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;第一阶段，刚接触Blog，觉得很新鲜，试着选择一个免费空间来写。
第二阶段，发现免费空间限制太多，就自己购买域名和空间，搭建独立博客。
第三阶段，觉得独立博客的管理太麻烦，最好在保留控制权的前提下，让别人来管，自己只负责写文章。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;决定使用hexo来管理，并定制了&lt;a href=&#34;https://github.com/drunkevil/dacman&#34;&gt;dacman主题&lt;/a&gt;(模仿的阮一峰的风格)，可以让人聚焦到内容。&lt;/p&gt;

&lt;p&gt;当有时间静下心来思考一下，就打开terminal，输入&lt;code&gt;hexo new &amp;quot;a new start&amp;quot;&lt;/code&gt;。&lt;/p&gt;
</description>
      
    </item>
    
  </channel>
</rss>
